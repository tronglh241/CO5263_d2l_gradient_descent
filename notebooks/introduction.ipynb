{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb525dec-a9af-4d99-a38f-a390976cd8ca",
   "metadata": {},
   "source": [
    "# Giới thiệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdfc60d-09d5-4be8-9f35-92936b14131a",
   "metadata": {},
   "source": [
    "## Bài toán"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8be8fc-eb89-490b-9b71-48ca44785602",
   "metadata": {},
   "source": [
    "Nhiều bài toán tối ưu trong khoa học máy tính và học máy liên quan đến việc tối thiểu hóa một hàm mất mát (loss function), hàm này đo lường sự khác biệt giữa dự đoán của mô hình và giá trị thực tế. Các bài toán này thường có dạng tối thiểu tổng của nhiều hàm khả vi, chẳng hạn như:\n",
    "$$\n",
    "\\min_{\\mathbf{w}} \\frac{1}{n} \\sum_{i=1}^n f_i(\\mathbf{w}),\n",
    "$$\n",
    "trong đó mỗi $f_i$ tương ứng với giá trị mất mát của điểm dữ liệu thứ $i$. Việc tối thiểu hóa trực tiếp hàm mất mát này có thể rất tốn kém về tính toán khi tập dữ liệu lớn, do đó các thuật toán tối ưu hiệu quả là rất cần thiết. Phương pháp Gradient Descent và các biến thể của nó như Stochastic Gradient Descent (SGD) và Mini-batch SGD là một trong những phương pháp tối ưu được sử dụng khá rộng rãi để giải quyết các bài toán như vậy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d46ec90-2b92-4bb3-b3b3-1e579db7f44a",
   "metadata": {},
   "source": [
    "## Ứng dụng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a91e0f-2d95-420b-869b-711909a38ea9",
   "metadata": {},
   "source": [
    "Gradient Descent (GD), Stochastic Gradient Descent (SGD) và Mini-batch SGD là các kỹ thuật tối ưu hóa cơ bản với nhiều ứng dụng rộng rãi, đặc biệt trong lĩnh vực học máy. Trong đó, **deep learning (học sâu)** là lĩnh vực nổi bật nhất mà các phương pháp này đã chứng tỏ hiệu quả vượt trội. Việc huấn luyện các mạng nơ-ron sâu đòi hỏi phải tối ưu các hàm mất mát phi lồi với hàng triệu đến hàng tỷ tham số - một nhiệm vụ gần như bất khả thi nếu không có các thuật toán tối ưu hóa hiệu quả như SGD và các biến thể của nó.\n",
    "\n",
    "Các phương pháp này được sử dụng để huấn luyện những mô hình hiện đại nhất trong các bài toán như **nhận diện hình ảnh, xử lý ngôn ngữ tự nhiên, nhận dạng giọng nói, và các mô hình sinh như GAN hoặc các mô hình ngôn ngữ lớn (LLM)**. Mini-batch SGD đặc biệt hữu ích khi cân bằng giữa tính nhiễu của SGD thuần túy và chi phí tính toán cao của GD toàn bộ, nhờ đó trở thành lựa chọn tiêu chuẩn trong hầu hết các framework học sâu hiện nay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8242908-b3a8-47a2-a268-03dd1032d133",
   "metadata": {},
   "source": [
    "## Một số bài toán khoa học máy tính đã được giải bằng các phương pháp này"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17220e0e-66d1-4616-9d8c-540774029dc3",
   "metadata": {},
   "source": [
    "Gradient Descent và các biến thể của nó không chỉ là công cụ tối ưu hóa mà còn đóng vai trò trung tâm trong việc giải quyết nhiều bài toán quan trọng trong khoa học máy tính. Một số ví dụ tiêu biểu kể đến như:\n",
    "\n",
    "- **Huấn luyện mạng nơ-ron sâu (Deep Neural Networks):** Các mô hình như ResNet, BERT, GPT,… đều được huấn luyện bằng mini-batch SGD hoặc các biến thể nâng cao của nó như Adam, RMSProp. Những mô hình này đạt hiệu suất vượt trội trong các tác vụ như phân loại ảnh, dịch máy, và tạo sinh văn bản.\n",
    "\n",
    "- **Hệ thống gợi ý (Recommendation Systems):** Tối ưu hóa hàm mất mát trong mô hình ma trận tiềm ẩn hoặc mô hình học sâu gợi ý (Deep Recommender Systems) đều cần đến các thuật toán tối ưu như SGD.\n",
    "\n",
    "- **Thị giác máy tính (Computer Vision):** Trong các bài toán như phát hiện đối tượng, phân đoạn ảnh, và tạo ảnh, mini-batch SGD được dùng để tối ưu các mô hình học sâu phức tạp với dữ liệu ảnh quy mô lớn.\n",
    "\n",
    "- **Học tăng cường (Reinforcement Learning):** Các thuật toán như Policy Gradient, Deep Q-Learning sử dụng SGD để cập nhật chính sách hoặc hàm giá trị dựa trên trải nghiệm từ môi trường.\n",
    "\n",
    "Những ví dụ trên cho thấy tầm quan trọng rộng khắp của GD, SGD và Mini-batch SGD trong việc giải quyết các bài toán cốt lõi của khoa học máy tính hiện đại, đặc biệt khi dữ liệu và mô hình ngày càng lớn và phức tạp."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
