{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb525dec-a9af-4d99-a38f-a390976cd8ca",
   "metadata": {},
   "source": [
    "# 01. Giới thiệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdfc60d-09d5-4be8-9f35-92936b14131a",
   "metadata": {},
   "source": [
    "## Bài toán"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8be8fc-eb89-490b-9b71-48ca44785602",
   "metadata": {},
   "source": [
    "Nhiều bài toán tối ưu trong khoa học máy tính và học máy liên quan đến việc tối thiểu hóa một hàm mất mát (loss function), hàm này đo lường sự khác biệt giữa dự đoán của mô hình và giá trị thực tế. Các bài toán này thường có dạng tối thiểu tổng của nhiều hàm khả vi, chẳng hạn như:\n",
    "$$\n",
    "\\min_{\\mathbf{w}} \\frac{1}{n} \\sum_{i=1}^n f_i(\\mathbf{w}),\n",
    "$$\n",
    "trong đó mỗi $f_i$ tương ứng với giá trị mất mát của điểm dữ liệu thứ $i$. Việc tối thiểu hóa trực tiếp hàm mất mát này có thể rất tốn kém về tính toán khi tập dữ liệu lớn, do đó các thuật toán tối ưu hiệu quả là rất cần thiết. Phương pháp Gradient Descent và các biến thể của nó như Stochastic Gradient Descent (SGD) và Mini-batch SGD là một trong những phương pháp tối ưu được sử dụng khá rộng rãi để giải quyết các bài toán như vậy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d46ec90-2b92-4bb3-b3b3-1e579db7f44a",
   "metadata": {},
   "source": [
    "## Ứng dụng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a91e0f-2d95-420b-869b-711909a38ea9",
   "metadata": {},
   "source": [
    "Gradient Descent (GD), Stochastic Gradient Descent (SGD) và Mini-batch SGD là các kỹ thuật tối ưu hóa cơ bản với nhiều ứng dụng rộng rãi, đặc biệt trong lĩnh vực học máy. Trong đó, **deep learning (học sâu)** là lĩnh vực nổi bật nhất mà các phương pháp này đã chứng tỏ hiệu quả vượt trội. Việc huấn luyện các mạng nơ-ron sâu đòi hỏi phải tối ưu các hàm mất mát phi lồi với hàng triệu đến hàng tỷ tham số - một nhiệm vụ gần như bất khả thi nếu không có các thuật toán tối ưu hóa hiệu quả như SGD và các biến thể của nó.\n",
    "\n",
    "Các phương pháp này được sử dụng để huấn luyện những mô hình hiện đại nhất trong các bài toán như **nhận diện hình ảnh, xử lý ngôn ngữ tự nhiên, nhận dạng giọng nói, và các mô hình sinh như GAN hoặc các mô hình ngôn ngữ lớn (LLM)**. Mini-batch SGD đặc biệt hữu ích khi cân bằng giữa tính nhiễu của SGD thuần túy và chi phí tính toán cao của GD toàn bộ, nhờ đó trở thành lựa chọn tiêu chuẩn trong hầu hết các framework học sâu hiện nay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8242908-b3a8-47a2-a268-03dd1032d133",
   "metadata": {},
   "source": [
    "## Một số bài toán khoa học máy tính đã được giải bằng các phương pháp này"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17220e0e-66d1-4616-9d8c-540774029dc3",
   "metadata": {},
   "source": [
    "Gradient Descent và các biến thể của nó không chỉ là công cụ tối ưu hóa mà còn đóng vai trò trung tâm trong việc giải quyết nhiều bài toán quan trọng trong khoa học máy tính. Một số ví dụ tiêu biểu kể đến như:\n",
    "\n",
    "- **Huấn luyện mạng nơ-ron sâu (Deep Neural Networks):** Các mô hình như ResNet, BERT, GPT,… đều được huấn luyện bằng mini-batch SGD hoặc các biến thể nâng cao của nó như Adam, RMSProp. Những mô hình này đạt hiệu suất vượt trội trong các tác vụ như phân loại ảnh, dịch máy, và tạo sinh văn bản.\n",
    "\n",
    "- **Hệ thống gợi ý (Recommendation Systems):** Tối ưu hóa hàm mất mát trong mô hình ma trận tiềm ẩn hoặc mô hình học sâu gợi ý (Deep Recommender Systems) đều cần đến các thuật toán tối ưu như SGD.\n",
    "\n",
    "- **Thị giác máy tính (Computer Vision):** Trong các bài toán như phát hiện đối tượng, phân đoạn ảnh, và tạo ảnh, mini-batch SGD được dùng để tối ưu các mô hình học sâu phức tạp với dữ liệu ảnh quy mô lớn.\n",
    "\n",
    "- **Học tăng cường (Reinforcement Learning):** Các thuật toán như Policy Gradient, Deep Q-Learning sử dụng SGD để cập nhật chính sách hoặc hàm giá trị dựa trên trải nghiệm từ môi trường.\n",
    "\n",
    "Những ví dụ trên cho thấy tầm quan trọng rộng khắp của GD, SGD và Mini-batch SGD trong việc giải quyết các bài toán cốt lõi của khoa học máy tính hiện đại, đặc biệt khi dữ liệu và mô hình ngày càng lớn và phức tạp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dbf639-4c63-4693-8946-139fbc148da6",
   "metadata": {},
   "source": [
    "# 02. Gradient Descent\n",
    "Gradient descent là một thuật toán tối ưu hóa thường được sử dụng để đào tạo các mô hình học máy và mạng nơ-ron. Nó đào tạo các mô hình học máy bằng cách giảm thiểu lỗi giữa kết quả dự đoán và kết quả thực tế.\n",
    "Thuật toán hoạt động bằng cách điều chỉnh liên tục các tham số của mô hình (như trọng số và độ lệch) theo hướng làm giảm chi phí nhiều nhất. Hướng này được xác định bằng cách tính toán độ dốc (hướng đến mức tăng chi phí nhiều nhất) của hàm chi phí liên quan đến các tham số, sau đó di chuyển các tham số theo hướng ngược lại.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bf1d29-f160-4a3a-854b-3a8748e13307",
   "metadata": {},
   "source": [
    "## One-Dimensional Gradient Descent\n",
    "Xét một hàm thực khả vi liên tục $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ . Sử dụng khai triển Taylor:\n",
    "$$f(x+\\epsilon)=f(x)+\\epsilon f^{\\prime}(x)+O\\left(\\epsilon^2\\right). \\tag{1}$$ \n",
    "Tức là, trong xấp xỉ bậc một, $f(x+\\epsilon)$ được xác định bởi giá trị hàm $f(x)$ và đạo hàm bậc một $f^{\\prime}(x)$ tại $x$. Có thể giả định rằng với $\\epsilon$ nhỏ, việc di chuyển theo hướng gradient âm sẽ giảm $f$. Chọn một kích thước bước cố định $\\eta>0$ và chọn $\\epsilon=-\\eta f^{\\prime}(x)$. Thay vào khai triển Taylor ở trên:\n",
    "$$f\\left(x-\\eta f^{\\prime}(x)\\right)=f(x)-\\eta f^{\\prime 2}(x)+O\\left(\\eta^2 f^{\\prime 2}(x)\\right).\\tag{2}$$\n",
    "Nếu đạo hàm $f^{\\prime}(x) \\neq 0$ không tiêu biến, ta đạt được bước tiến tới điểm tối ưu vì $\\eta f^{\\prime 2}(x)>0$. Hơn nữa, ta luôn có thể chọn $\\eta$ đủ nhỏ để các hạng bậc cao trở nên không đáng kể. Do đó:\n",
    "$$f\\left(x-\\eta f^{\\prime}(x)\\right) \\lessapprox f(x). \\tag{3}$$\n",
    "Điều này có nghĩa là, nếu ta sử dụng:\n",
    "$$x \\leftarrow x-\\eta f^{\\prime}(x). \\tag{4}$$\n",
    "để lặp $x$, giá trị của hàm $f(x)$ có thể giảm. Do đó, trong gradient descent, ta đầu tiên chọn một giá trị ban đầu $x$ và một hằng số $\\eta>0$, sau đó sử dụng chúng để lặp $x$ liên tục cho đến khi đạt điều kiện dừng, ví dụ, khi độ lớn của gradient $\\left|f^{\\prime}(x)\\right|$ đủ nhỏ hoặc số lần lặp đạt một giá trị nhất định.\n",
    "### Ví dụ minh họa\n",
    "Ta chọn hàm mục tiêu $f(x)=x^2 +5sin(x)$ để minh họa cách thực hiện gradient descent. Đạo hàm: $f^{\\prime}(x) =2x + 5cos(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5239bff-4d53-470c-98d1-8115d76c38e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import d2l\n",
    "def f(x):  # objective function\n",
    "    return x**2 + 5 * np.sin(x)\n",
    "\n",
    "def f_grad(x):  # Gradient (derivative) of the objective function\n",
    "    return 2*x + 5 * np.cos(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4f83e0",
   "metadata": {},
   "source": [
    "Tiếp theo, ta sử dụng $x=-5$ làm giá trị ban đầu và giả sử $\\eta=0.1$. Sử dụng gradient descent để lặp $x$ 15 lần, ta có thể thấy rằng x xuất phát từ bên trái và cuối cùng, giá trị của $x$ tiến gần đến nghiệm tối ưu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a12d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(eta, f_grad, start_x, step):\n",
    "    x = start_x\n",
    "    results = [x]\n",
    "    for i in range(step):\n",
    "        x -= eta * f_grad(x)\n",
    "        results.append(x)\n",
    "    print(f'epoch 11, x: {x:.6f}')\n",
    "    return results\n",
    "\n",
    "results = gd(0.1, f_grad,-5,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73410907",
   "metadata": {},
   "source": [
    "Tiến trình tối ưu hóa $x$ có thể được vẽ như sau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_trace(results, f):\n",
    "    n = max(abs(min(results)), abs(max(results)))\n",
    "    f_line = np.arange(-n, n, 0.01)\n",
    "    d2l.set_figsize()\n",
    "    d2l.plot([f_line, results], [[f(x) for x in f_line], [f(x) for x in results]], 'x', 'f(x)', fmts=['-', '-o'])\n",
    "show_trace(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd86e155-23d6-4686-ba20-e5492cd75f5e",
   "metadata": {},
   "source": [
    "Ta sử dụng $x=4$ làm giá trị ban đầu và giả sử $\\eta=0.1$. Sử dụng gradient descent để lặp $x$ 30 lần, ta có thể thấy rằng x xuất phát từ bên phải và đi dần tới nghiệm tối ưu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9c8e2c-b80d-4786-9d64-b1418b7de522",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = gd(0.1, f_grad,4,25)\n",
    "show_trace(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54fea95",
   "metadata": {},
   "source": [
    "### Learning Rate\n",
    "Tốc độ học (learning rate) 𝜂 có thể được thiết lập bởi người thiết kế thuật toán. Nếu chúng ta sử dụng một tốc độ học quá nhỏ, nó sẽ khiến `𝑥` cập nhật rất chậm, đòi hỏi nhiều vòng lặp hơn để thu được nghiệm tốt hơn. Để minh họa điều xảy ra trong trường hợp như vậy, hãy xem xét tiến trình trong cùng bài toán tối ưu với 𝜂 = 0.02. Như ta có thể thấy, ngay cả sau 10 bước lặp, chúng ta vẫn còn cách xa nghiệm tối ưu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefdea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_trace(gd(0.02, f_grad,-5,10), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d3615",
   "metadata": {},
   "source": [
    "Ngược lại, nếu chúng ta sử dụng tốc độ học quá lớn, giá trị `|𝜂 𝑓'(𝑥)|` có thể trở nên quá lớn đối với công thức khai triển Taylor bậc nhất. Nghĩa là, số hạng `O (𝜂² 𝑓'²(𝑥))` trong công thức (2) có thể trở nên đáng kể. Trong trường hợp này, chúng ta không thể đảm bảo rằng quá trình cập nhật lặp của `𝑥` sẽ làm giảm giá trị của hàm `𝑓(𝑥)`. Ví dụ, khi chúng ta đặt tốc độ học `𝜂 = 1.1`, `𝑥` vượt quá (overshoots) nghiệm tối ưu `𝑥 = 0` và dần dần phân kỳ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9891feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_trace(gd(1.1, f_grad,-5,10), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c64e8b",
   "metadata": {},
   "source": [
    "### Local Minima\n",
    "Để minh họa điều gì xảy ra với các hàm không lồi, hãy xem xét trường hợp $f(x) = 0.25x^4 - \\frac{1}{3}x^3 - 1.5x^2 + 2x$ . Hàm này có  cực tiểu cục bộ tại $x = 2$, với $f(2) \\approx -0.67$ và cực tiểu toàn cục nằm tại $x \\approx -1.618$, với $f(-1.618) \\approx -4.04$. Tùy thuộc vào lựa chọn tốc độ học và mức độ điều kiện của bài toán, ta có thể đạt được một trong nhiều nghiệm. Ví dụ dưới đây minh họa cách một tốc độ học cao sẽ dẫn đến một cực tiểu cục bộ kém. Với tốc độ học 0.08 giá trị của x bắt đầu tại -4 và đi về phía bên phải và vượt qua cực tiểu toàn cục rồi đi tới cực tiểu cục bộ tại $x=2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc6408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):  # Objective function\n",
    "    return 0.25*x**4 - (1/3)*x**3 - 1.5*x**2 + 2*x\n",
    "\n",
    "def f_grad(x):  # Gradient of the objective function\n",
    "    return x**3 -x**2-3*x+2\n",
    "\n",
    "show_trace(gd(0.08, f_grad,-4,20), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c54212-5549-40c3-a71a-0f979d29431c",
   "metadata": {},
   "source": [
    "## Multivariate Gradient Descent\n",
    "Xem xét tình huống mà $\\mathbf{x}=\\left[x_1, x_2, \\ldots, x_d\\right]^{\\top}$. Tức là, hàm mục tiêu $f: \\mathbb{R}^d \\rightarrow \\mathbb{R}$ ánh xạ các vector thành số thực. Gradient của nó cũng là đa biến, là một vector gồm $d$ đạo hàm riêng:\n",
    "$$\\nabla f(\\mathbf{x})=\\left[\\frac{\\partial f(\\mathbf{x})}{\\partial x_1}, \\frac{\\partial f(\\mathbf{x})}{\\partial x_2}, \\ldots, \\frac{\\partial f(\\mathbf{x})}{\\partial x_d}\\right]^{\\top}. \\tag{5}$$\n",
    "Mỗi phần tử đạo hàm riêng $\\partial f(\\mathbf{x}) / \\partial x_i$ trong gradient biểu thị tốc độ thay đổi của $f$ tại $\\mathbf{x}$ theo đầu vào $x_i$. Như trong trường hợp một biến, ta có thể sử dụng xấp xỉ Taylor đa biến để có ý tưởng về việc nên làm gì. Cụ thể, ta có:\n",
    "$$f(\\mathbf{x}+\\boldsymbol{\\epsilon})=f(\\mathbf{x})+\\boldsymbol{\\epsilon}^{\\top} \\nabla f(\\mathbf{x})+O\\left(|\\boldsymbol{\\epsilon}|^2\\right). \\tag{6}$$\n",
    "Nói cách khác, đến các hạng bậc hai trong $\\epsilon$, hướng giảm nhanh nhất được cho bởi gradient âm $-\\nabla f(\\mathbf{x})$. Chọn một tốc độ học phù hợp $\\eta>0$ cho ra thuật toán gradient descent nguyên mẫu:\n",
    "$$\\mathbf{x} \\leftarrow \\mathbf{x}-\\eta \\nabla f(\\mathbf{x}). \\tag{7}$$\n",
    "Lấy ví dụ hàm mục tiêu $f(\\mathbf{x})=x_1^2+10x_2^2$ với vector hai chiều $\\mathbf{x}=\\left[x_1, x_2\\right]^{\\top}$ làm đầu vào và một số thực làm đầu ra. Gradient được cho bởi $\\nabla f(\\mathbf{x})=\\left[2x_1, 20x_2\\right]^{\\top}$. Ta sẽ quan sát quỹ đạo của $\\mathbf{x}$ bằng gradient descent từ vị trí ban đầu $[-5, -2]$.\n",
    "Cần hai hàm hỗ trợ, hàm đầu tiên sử dụng một hàm cập nhật và áp dụng nó 20 lần cho giá trị ban đầu. Hàm hỗ trợ thứ hai trực quan hóa quỹ đạo của $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f95578-6a5b-4d14-839c-c2b3618aba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_2d(trainer, steps=20, f_grad=None):  # save\n",
    "    \"\"\"Optimize a 2D objective function with a customized trainer.\"\"\"\n",
    "    # s1 and s2 are internal state variables that will be used in Momentum,\n",
    "    # Adagrad, RMSProp\n",
    "    x1, x2, s1, s2 = -5, -2, 0, 0\n",
    "    results = [(x1, x2)]\n",
    "    for i in range(steps):\n",
    "        if f_grad:\n",
    "            x1, x2, s1, s2 = trainer(x1, x2, s1, s2, f_grad)\n",
    "        else:\n",
    "            x1, x2, s1, s2 = trainer(x1, x2, s1, s2)\n",
    "        results.append((x1, x2))\n",
    "    print(f'epoch {i + 1}, x1: {float(x1):f}, x2: {float(x2):f}')\n",
    "    return results\n",
    "\n",
    "def show_trace_2d(f, results):  # save\n",
    "    \"\"\"Show the trace of 2D variables during optimization.\"\"\"\n",
    "    d2l.set_figsize()\n",
    "    d2l.plt.plot(*zip(*results), '-o', color='#ff7f0e')\n",
    "    x1, x2 = torch.meshgrid(torch.arange(-10, 1.0, 0.1),\n",
    "                            torch.arange(-3.0, 1.0, 0.1), indexing='ij')\n",
    "    d2l.plt.contour(x1, x2, f(x1, x2), colors='#1f77b4')\n",
    "    d2l.plt.xlabel('x1')\n",
    "    d2l.plt.ylabel('x2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ce2ad",
   "metadata": {},
   "source": [
    "Tiếp theo, ta quan sát quỹ đạo của biến tối ưu $\\mathbf{x}$ với tốc độ học $\\eta=0.1$. Ta thấy rằng sau 20 bước, giá trị của $\\mathbf{x}$ tiến gần đến cực tiểu tại $[0, 0]$. Tiến trình khá ổn định mặc dù khá chậm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fe7f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_2d(x1, x2): # Objective function\n",
    "    return x1 ** 2 + 10 * x2 ** 2\n",
    "def f_2d_grad(x1, x2): # Gradient of the objective function\n",
    "    return (2 * x1, 20 * x2)\n",
    "def gd_2d(x1, x2, s1, s2, f_grad):\n",
    "    g1, g2 = f_grad(x1, x2)\n",
    "    return (x1 - eta * g1, x2 - eta * g2, 0, 0)\n",
    "eta = 0.02\n",
    "show_trace_2d(f_2d, train_2d(gd_2d, f_grad=f_2d_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9b8123-eec4-40cf-921c-a9e71351ced9",
   "metadata": {},
   "source": [
    "## Adaptive Methods\n",
    "Việc chọn tốc độ học $\\eta$ \"vừa đúng\" là một việc khó khăn. Nếu chọn quá nhỏ, tiến bộ rất ít. Nếu chọn quá lớn, nghiệm sẽ dao động và trong trường hợp xấu nhất, có thể phân kỳ. Các phương pháp bậc hai, không chỉ xem xét giá trị và gradient của hàm mục tiêu mà còn xem xét độ cong của nó, có giúp ích trong trường hợp này. Mặc dù các phương pháp này không thể áp dụng trực tiếp cho deep learning do chi phí tính toán, chúng cung cấp trực giác hữu ích để thiết kế các thuật toán tối ưu hóa nâng cao, mô phỏng nhiều đặc tính mong muốn của các thuật toán được trình bày dưới đây.\n",
    "### Phương Pháp Newton\n",
    "Xem lại khai triển Taylor của hàm $f: \\mathbb{R}^d \\rightarrow \\mathbb{R}$, không cần dừng lại sau hạng đầu tiên:\n",
    "$$f(\\mathbf{x}+\\boldsymbol{\\epsilon})=f(\\mathbf{x})+\\boldsymbol{\\epsilon}^{\\top} \\nabla f(\\mathbf{x})+\\frac{1}{2} \\boldsymbol{\\epsilon}^{\\top} \\nabla^2 f(\\mathbf{x}) \\boldsymbol{\\epsilon}+O\\left(|\\boldsymbol{\\epsilon}|^3\\right).\\tag{8}$$\n",
    "Để tránh ký hiệu phức tạp, ta định nghĩa $\\mathbf{H} \\stackrel{\\text{def}}{=} \\nabla^2 f(\\mathbf{x})$ là ma trận Hessian của $f$, một ma trận $d \\times d$.\n",
    "Sau cùng, cực tiểu của $f$ thỏa mãn $\\nabla f=0$. Bằng cách lấy đạo hàm của (8) theo $\\epsilon$ và bỏ qua các hạng bậc cao:\n",
    "\n",
    "1. **Số hạng đầu tiên: $ f(x) $**  \n",
    "   Hàm $ f(x) $ là hằng số đối với $\\epsilon$ bởi vì $ x $ là cố định. Cho nên:\n",
    "\n",
    "   $$\n",
    "   \\nabla_{\\epsilon} f(x) = 0\n",
    "   $$\n",
    "\n",
    "2. **Số hạng thứ 2: $ \\epsilon^T \\nabla f(x) $**\n",
    "\n",
    "    $$ \\boldsymbol{\\epsilon}^\\top \\nabla f(\\mathbf{x})\n",
    "    = \\epsilon_1 \\frac{\\partial f(\\mathbf{x})}{\\partial x_1}\n",
    "    + \\epsilon_2 \\frac{\\partial f(\\mathbf{x})}{\\partial x_2}\n",
    "    + \\cdots\n",
    "    + \\epsilon_d \\frac{\\partial f(\\mathbf{x})}{\\partial x_d}\n",
    "    = \\sum_{i=1}^{d} \\epsilon_i \\frac{\\partial f(\\mathbf{x})}{\\partial x_i} $$\n",
    "    \n",
    "    Với\n",
    "    \n",
    "    $$\n",
    "    \\nabla f(\\mathbf{x}) =\n",
    "    \\left[\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_1}, \\dots, \\frac{\\partial f(\\mathbf{x})}{\\partial x_d}\n",
    "    \\right]^\\top\n",
    "    $$\n",
    "    \n",
    "    là gradient của  $f$ tại $\\mathbf{x}$. Suy ra\n",
    "\n",
    "   $$\n",
    "   \\epsilon^T \\nabla f(x) = \\sum_{i=1}^d \\epsilon_i \\frac{\\partial f(x)}{\\partial x_i}\n",
    "   $$\n",
    "    \n",
    "   Tính toán đạo hàm riêng với $\\epsilon_j$:\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial}{\\partial \\epsilon_j} \\left( \\sum_{i=1}^d \\epsilon_i \\frac{\\partial f(x)}{\\partial x_i} \\right) = \\frac{\\partial f(x)}{\\partial x_j}\n",
    "   $$\n",
    "\n",
    "   Gradient là:\n",
    "\n",
    "   $$\n",
    "   \\nabla_{\\epsilon} (\\epsilon^T \\nabla f(x)) = \\nabla f(x) = \\begin{bmatrix} \\frac{\\partial f(x)}{\\partial x_1} \\\\ \\vdots \\\\ \\frac{\\partial f(x)}{\\partial x_d} \\end{bmatrix}\n",
    "   $$\n",
    "\n",
    "4. **Số hạng thứ 3: $ \\frac{1}{2} \\epsilon^T \\nabla^2 f(x) \\epsilon $**  \n",
    "   $$\n",
    "   \\frac{1}{2} \\epsilon^T \\nabla^2 f(x) \\epsilon = \\frac{1}{2} \\sum_{i=1}^d \\sum_{j=1}^d \\epsilon_i \\epsilon_j \\frac{\\partial^2 f(x)}{\\partial x_i \\partial x_j}\n",
    "   $$\n",
    "\n",
    "   Đạo hàm riêng đối với $\\epsilon_k$:\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial}{\\partial \\epsilon_k} \\left( \\frac{1}{2} \\sum_{i=1}^d \\sum_{j=1}^d \\epsilon_i \\epsilon_j \\frac{\\partial^2 f(x)}{\\partial x_i \\partial x_j} \\right) = \\frac{1}{2} \\left( \\sum_{j=1}^d \\epsilon_j \\frac{\\partial^2 f(x)}{\\partial x_k \\partial x_j} + \\sum_{i=1}^d \\epsilon_i \\frac{\\partial^2 f(x)}{\\partial x_i \\partial x_k} \\right)\n",
    "   $$\n",
    "\n",
    "   Bởi vì $\\nabla^2 f(x)$ đối xứng nên hai tổng bằng nhau nên:\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial}{\\partial \\epsilon_k} = \\sum_{j=1}^d \\epsilon_j \\frac{\\partial^2 f(x)}{\\partial x_k \\partial x_j} = \\left[ \\nabla^2 f(x) \\epsilon \\right]_k\n",
    "   $$\n",
    "\n",
    "   Gradient là:\n",
    "\n",
    "   $$\n",
    "   \\nabla_{\\epsilon} \\left( \\frac{1}{2} \\epsilon^T \\nabla^2 f(x) \\epsilon \\right) = \\nabla^2 f(x) \\epsilon\n",
    "   $$\n",
    "\n",
    "5. **Kết hợp với nhau và bỏ qua $ O(\\|\\epsilon\\|^3) $**  \n",
    "   $$\n",
    "   \\nabla_{\\epsilon} f(x + \\epsilon) = 0 + \\nabla f(x) + \\nabla^2 f(x) \\epsilon\n",
    "   $$\n",
    "\n",
    "Như đã định nghĩa trước đó $\\mathbf{H} \\stackrel{\\text{def}}{=} \\nabla^2 f(\\mathbf{x})$ nên $\\nabla_{\\epsilon} f(x + \\epsilon) = \\nabla f(x) + \\mathbf{H} \\epsilon$ và ta cần tìm giá trị $\\nabla_{\\epsilon} f(x + \\epsilon)=0$: $$\\nabla f(\\mathbf{x}) + H \\boldsymbol{\\epsilon} = 0$$và do đó $$\\boldsymbol{\\epsilon} = -H^{-1} \\nabla f(\\mathbf{x})$$ \n",
    "Ví dụ với hàm hyperbolic cosine lồi $f(x)=\\cosh(cx)$ với một hằng số $c$, cực tiểu toàn cục tại $x=0$ được đạt sau vài lần lặp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25253aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.tensor(0.5)\n",
    "\n",
    "def f(x):  # objective function\n",
    "    return torch.cosh(c * x)\n",
    "\n",
    "def f_grad(x):  # Gradient of the objective function\n",
    "    return c * torch.sinh(c * x)\n",
    "\n",
    "def f_hess(x):  # Hessian of the objective function\n",
    "    return c ** 2 * torch.cosh(c * x)\n",
    "\n",
    "def newton(x,step,eta=1):\n",
    "    results = [x]\n",
    "    for i in range(step):\n",
    "        x -= eta * f_grad(x) / f_hess(x)\n",
    "        results.append(float(x))\n",
    "    print('epoch 10, x:', x)\n",
    "    return results\n",
    "\n",
    "show_trace(newton(10.0,10), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c9babe",
   "metadata": {},
   "source": [
    "Xét hàm $f(x)=x \\cos(cx)$ với một hằng số $c$. Trong phương pháp Newton, ta chia cho Hessian. Điều này có nghĩa là nếu đạo hàm bậc hai âm, ta có thể đi theo hướng làm tăng giá trị của $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b6d17d-6adb-4733-8fba-3da795c64a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.tensor(0.15 * np.pi)\n",
    "\n",
    "def f(x):  # Objective function\n",
    "    return x * torch.cos(c * x)\n",
    "\n",
    "def f_grad(x):  # Gradient of the objective function\n",
    "    return torch.cos(c * x) - c * x * torch.sin(c * x)\n",
    "\n",
    "def f_hess(x):  # Hessian of the objective function\n",
    "    return -2 * c * torch.sin(c * x) - c ** 2 * x * torch.cos(c * x)\n",
    "\n",
    "show_trace(newton(10,10), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853bf0ca",
   "metadata": {},
   "source": [
    "Hàm số không di chuyển về cực tiểu do đạo hàm bậc 2 âm. Một phương pháp là lấy Hessian bằng cách lấy giá trị tuyệt đối của nó. Một chiến lược khác là đưa lại tốc độ học. Có thông tin bậc hai cho phép thận trọng bất cứ khi nào độ cong lớn và thực hiện các bước dài hơn bất cứ khi nào hàm mục tiêu phẳng hơn. Với tốc độ học nhỏ hơn một chút, chẳng hạn $\\eta=0.5$, thuật toán hoạt động hiệu quả hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd52349",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_trace(newton(10,10,0.5), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b2802-a726-4387-9290-a3539b963903",
   "metadata": {},
   "source": [
    "### Ví dụ minh họa\n",
    "Lấy thêm một ví dụ minh họa với $f(x) = x \\log(x)$. Với phương pháp gradient descent thông thường và phương pháp Newton ta có thể thấy phương pháp Newton tiến về điểm tối ưu nhanh hơn với cùng tốc độ học $\\eta=0.2$ và cùng số bước là 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79316d51-ac51-4378-b725-98eef0c89840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x * np.log(x)\n",
    "\n",
    "def f_grad(x):\n",
    "    x=torch.tensor([x])\n",
    "    return (torch.log(x) + 1).item()\n",
    "\n",
    "def f_hess(x):\n",
    "    return 1 / x\n",
    "def show_trace(results, f):\n",
    "    n = max(abs(min(results)), abs(max(results)))\n",
    "    f_line = np.arange(0.01, n, 0.01)\n",
    "    d2l.set_figsize()\n",
    "    d2l.plot([f_line, results], [[f(x) for x in f_line], [f(x) for x in results]], 'x', 'f(x)', fmts=['-', '-o'])\n",
    "show_trace(newton(5,10,0.2), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d85337-d0f6-4f4b-8510-a759b3478b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(eta, f_grad, start_x, step):\n",
    "    x = start_x\n",
    "    results = [x]\n",
    "    for i in range(step):\n",
    "        x -= eta * f_grad(x)\n",
    "        results.append(x)\n",
    "    print(f'epoch 11, x: {x:.6f}')\n",
    "    return results\n",
    "\n",
    "results = gd(0.2, f_grad,5,10)\n",
    "show_trace(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca31d0ef",
   "metadata": {},
   "source": [
    "### Phân Tích Hội Tụ\n",
    "Ta chỉ phân tích tốc độ hội tụ của phương pháp Newton cho một hàm mục tiêu lồi và khả vi ba lần, trong đó đạo hàm bậc hai khác không, tức là $f^{\\prime\\prime}>0$.\n",
    "Gọi $x^{(k)}$ là giá trị của $x$ tại lần lặp thứ $k$ và đặt $e^{(k)} \\stackrel{\\text{def}}{=} x^{(k)}-x^*$ là khoảng cách từ điểm tối ưu tại lần lặp thứ $k$. Bằng khai triển Taylor, ta có điều kiện $f^{\\prime}\\left(x^{(*)}\\right)=0$ có thể được viết là:\n",
    "$$0=f^{\\prime}\\left(x^{(k)}-e^{(k)}\\right)=f^{\\prime}\\left(x^{(k)}\\right)-e^{(k)} f^{\\prime\\prime}\\left(x^{(k)}\\right)+\\frac{1}{2}\\left(e^{(k)}\\right)^2 f^{\\prime\\prime\\prime}\\left(\\xi^{(k)}\\right),\\tag{9}$$\n",
    "điều này đúng với một $\\xi^{(k)} \\in \\left[x^{(k)}-e^{(k)}, x^{(k)}\\right]$. Chia khai triển trên cho $f^{\\prime\\prime}\\left(x^{(k)}\\right)$, ta được:\n",
    "$$e^{(k)}-\\frac{f^{\\prime}\\left(x^{(k)}\\right)}{f^{\\prime\\prime}\\left(x^{(k)}\\right)}=\\frac{1}{2}\\left(e^{(k)}\\right)^2 \\frac{f^{\\prime\\prime\\prime}\\left(\\xi^{(k)}\\right)}{f^{\\prime\\prime}\\left(x^{(k)}\\right)} .\\tag{10}$$\n",
    "Nhớ rằng ta có cập nhật $x^{(k+1)}=x^{(k)}-f^{\\prime}\\left(x^{(k)}\\right) / f^{\\prime\\prime}\\left(x^{(k)}\\right)$ (phương pháp Newton). Thay vào phương trình cập nhật này và lấy giá trị tuyệt đối của cả hai vế, ta có:\n",
    "$$\n",
    "e^{(k+1)}=x^{(k+1)} - x^*\n",
    "         =x^{(k)}-f^{\\prime}\\left(x^{(k)}\\right) / f^{\\prime\\prime}\\left(x^{(k)}\\right)- x^* = e^{(k)}-f^{\\prime}\\left(x^{(k)}\\right) / f^{\\prime\\prime}\\left(x^{(k)}\\right)= \\frac{1}{2}\\left(e^{(k)}\\right)^2 \\frac{f^{\\prime\\prime\\prime}\\left(\\xi^{(k)}\\right)}{f^{\\prime\\prime}\\left(x^{(k)}\\right)}\n",
    "$$\n",
    "Lấy trị tuyệt đối 2 vế:\n",
    "$$\\left|e^{(k+1)}\\right|=\\frac{1}{2}\\left(e^{(k)}\\right)^2 \\frac{\\left|f^{\\prime\\prime\\prime}\\left(\\xi^{(k)}\\right)\\right|}{f^{\\prime\\prime}\\left(x^{(k)}\\right)} .\\tag{11}$$\n",
    "Do đó, bất cứ khi nào ta ở trong một vùng có $\\left|f^{\\prime\\prime\\prime}\\left(\\xi^{(k)}\\right)\\right| /\\left(2 f^{\\prime\\prime}\\left(x^{(k)}\\right)\\right) \\leq c$, ta có sai số giảm bậc hai:\n",
    "$$\\left|e^{(k+1)}\\right| \\leq c\\left(e^{(k)}\\right)^2 .\\tag{12}$$\n",
    "Lưu ý rằng các nhà nghiên cứu tối ưu hóa gọi đây là hội tụ tuyến tính, trong khi một điều kiện như $\\left|e^{(k+1)}\\right| \\leq \\alpha\\left|e^{(k)}\\right|$ được gọi là tốc độ hội tụ hằng số. Phân tích này đi kèm với một số lưu ý. Thứ nhất, không thực sự có đảm bảo khi nào sẽ đạt được vùng hội tụ nhanh. Thay vào đó chỉ biết rằng một khi đạt được, hội tụ sẽ rất nhanh. Thứ hai, phân tích này yêu cầu $f$ có tính chất tốt đến các đạo hàm bậc cao. Nó phụ thuộc vào việc đảm bảo rằng $f$ không có bất kỳ đặc tính \"bất ngờ\" nào về cách nó có thể thay đổi giá trị."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e920ef",
   "metadata": {},
   "source": [
    "### Tiền Điều Kiện Hóa\n",
    "Không ngạc nhiên khi việc tính toán và lưu trữ toàn bộ Hessian rất tốn kém. Một cách để cải thiện là tiền điều kiện hóa. Nó tránh tính toán toàn bộ Hessian mà chỉ tính các phần tử đường chéo. Điều này dẫn đến các thuật toán cập nhật dạng:\n",
    "$$\\mathbf{x} \\leftarrow \\mathbf{x}-\\eta \\operatorname{diag}(\\mathbf{H})^{-1} \\nabla f(\\mathbf{x}) .$$\n",
    "Mặc dù điều này không tốt bằng phương pháp Newton đầy đủ, nó vẫn tốt hơn nhiều so với việc không sử dụng. Để thấy tại sao đây là ý tưởng tốt, hãy xem xét một tình huống mà một biến biểu thị chiều cao tính bằng milimet và một biến khác biểu thị chiều cao tính bằng kilômét. Giả sử rằng với cả hai, tỷ lệ tự nhiên là mét, ta có sự không khớp lớn trong tham số hóa. May mắn thay, việc sử dụng tiền điều kiện hóa sẽ loại bỏ điều này. Hiệu quả, tiền điều kiện hóa với gradient descent tương đương với việc chọn một tốc độ học khác nhau cho mỗi biến (tọa độ của vector $\\mathbf{x}$). Như ta sẽ thấy sau, tiền điều kiện hóa thúc đẩy một số cải tiến trong các thuật toán tối ưu hóa gradient descent ngẫu nhiên.\n",
    "### Gradient descent với Tìm Kiếm Tuyến\n",
    "Một trong những vấn đề chính trong hạ gradient là ta có thể vượt quá mục tiêu hoặc tiến bộ không đủ. Một cách sửa đơn giản là sử dụng tìm kiếm tuyến kết hợp với gradient descent. Tức là, ta sử dụng hướng được cho bởi $\\nabla f(\\mathbf{x})$ và sau đó thực hiện tìm kiếm nhị phân để xác định tốc độ học $\\eta$ nào tối ưu hóa $f(\\mathbf{x}-\\eta \\nabla f(\\mathbf{x}))$.\n",
    "Thuật toán này hội tụ nhanh chóng. Tuy nhiên, đối với mục đích học sâu, điều này không thực sự khả thi, vì mỗi bước của tìm kiếm tuyến sẽ yêu cầu đánh giá hàm mục tiêu trên toàn bộ tập dữ liệu. Điều này quá tốn kém để thực hiện."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1022be34-d4b4-4a4f-9aa2-7564b660f378",
   "metadata": {},
   "source": [
    "## Excercises\n",
    "### 1. Thử nghiệm với các tốc độ học và hàm mục tiêu khác nhau để giảm dần độ dốc.\n",
    "Đã thực hiện trong quá trình tìm hiểu\n",
    "### 2. Triển khai tìm kiếm tuyến để giảm thiểu một hàm lồi trong khoảng [𝑎, 𝑏].\n",
    "#### 1. Bạn có cần đạo hàm cho tìm kiếm nhị phân không, tức là để quyết định chọn $[𝑎, (𝑎 +\n",
    "𝑏)/2]$ hay $[(𝑎 + 𝑏)/2, 𝑏]$.\n",
    "Không thực sự cần đạo hàm cho tìm kiếm nhị phân, nhưng tìm kiếm nhị phân đơn giản trên x sẽ không hoạt động trực tiếp nếu không có thêm thông tin.\n",
    "- Nếu hàm đơn điệu trên khoảng $[a,b]$ thì thực hiện tìm kiếm nhị phân cho $f(x)=0$ sẽ có hiệu quả và không cần sử dụng tới đạo hàm\n",
    "- Nếu hàm không đơn điệu trong khoảng $[a,b]$, để tối thiểu hóa $f(x)$. Nếu chỉ đánh giá $f((a+b)/2)$ thì sẽ không xác định được điểm cực tiểu nằm ở trong khoảng $[(a+b)/2,b]$ hay $[a,(a+b)/2]$. Giả sử $f((a+b)/2)<f(a)$ ta sẽ không biết được điểm cực tiểu nằm trong khoảng $[(a+b)/2,b]$ hay $[a,(a+b)/2]$ \n",
    "##### Phương pháp không sử dụng đạo hàm để quyết định chọn khoảng trong trường hợp hàm lồi.\n",
    "-Chọn 2 điểm $x_1$, $x_2$:\n",
    "  - Nếu $f(x_1)<f(x_2)$ điểm cực tiểu sẽ nằm trong khoảng $[a,x_2]$\n",
    "  - Nếu $f(x_1)>f(x_2)$ điểm cực tiểu sẽ nằm trong khoảng $[x_1,b]$\n",
    "##### Phương pháp sử dụng đạo hàm để quyết định chọn khoảng trong trường hợp hàm lồi.\n",
    "- Đánh giá đạo hàm $f^{\\prime}((a+b)/2)$\n",
    "  - Nếu $f^{\\prime}((a+b)/2)<0$ hàm số đang giảm tại điểm $(a+b)/2$ nên cực tiểu nằm trong khoảng $[(a+b)/2, b]$\n",
    "  - Nếu $f^{\\prime}((a+b)/2)>0$ hàm số đang tăng tại điểm $(a+b)/2$ nên cực tiểu nằm trong khoảng $[a,(a+b)/2]$\n",
    "#### 2. Tốc độ hội tụ của thuật toán nhanh như thế nào?\n",
    "- Tốc độ hội tụ là **tuyến tính**. Độ rộng của khoảng được giảm theo một hệ số không đổi sau mỗi bước lặp, hệ số này là $ \\frac{1}{\\varphi} \\approx 0{,}618$ (với $\\varphi$, xấp xỉ $1{,}618 $.Điều này có nghĩa là, để đạt được **một chữ số thập phân chính xác hơn** (tức là giảm độ rộng khoảng tìm kiếm đi 10 lần), ta cần khoảng:$\\frac{\\log(10)}{\\log(\\varphi)} \\approx 4{,}78$ bước lặp.\n",
    "- Nếu đạo hàm của hàm $f(x)$ có sẵn, ta có thể thực hiện **tìm kiếm nhị phân trên $f'(x)$**. Phương pháp này cũng có **tốc độ hội tụ tuyến tính**, nhưng hệ số giảm độ rộng khoảng tại mỗi bước là $0{,}5$ (tức là chia đôi khoảng). Điều này nhanh hơn so với phương pháp **Tìm kiếm theo Tỷ lệ Vàng** (Golden Section Search).Để đạt được **một chữ số thập phân chính xác hơn** (tức là giảm độ rộng khoảng đi 10 lần), cần khoảng:$\\frac{\\log(10)}{\\log(2)} \\approx 3{,}32$ bước lặp.\n",
    "#### 3. Triển khai thuật toán và áp dụng nó để tối thiểu log(exp(𝑥) + exp(−2𝑥 − 3))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f5d854-c7fc-4bb1-9863-3c53935973c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Function to minimize: f(x) = log(exp(x) + exp(-2x - 3))\"\"\"\n",
    "    return np.log(np.exp(x) + np.exp(-2 * x - 3))\n",
    "\n",
    "def f_prime(x):\n",
    "    \"\"\"Derivative of f(x)\"\"\"\n",
    "    return (np.exp(x) - 2 * np.exp(-2 * x - 3)) / (np.exp(x) + np.exp(-2 * x - 3))\n",
    "\n",
    "def binary_search_derivative(f_prime, a, b, tol=1e-5):\n",
    "    \"\"\"\n",
    "    Find the root of f'(x) = 0 in [a, b] using binary search, assuming f'(a) and f'(b) have opposite signs.\n",
    "    Returns the approximate minimum point x, number of iterations, and list of midpoints.\n",
    "    \"\"\"\n",
    "    if f_prime(a) * f_prime(b) >= 0:\n",
    "        raise ValueError(\"f'(a) and f'(b) must have opposite signs\")\n",
    "    \n",
    "    iterations = 0\n",
    "    midpoints = []\n",
    "    \n",
    "    while (b - a) > tol:\n",
    "        m = (a + b) / 2\n",
    "        fm = f_prime(m)\n",
    "        midpoints.append(m)\n",
    "        iterations += 1\n",
    "        \n",
    "        if abs(fm) < tol:  # If derivative is close to zero, stop\n",
    "            break\n",
    "        elif fm > 0:\n",
    "            b = m  # Root is in [a, m]\n",
    "        else:\n",
    "            a = m  # Root is in [m, b]\n",
    "    \n",
    "    x_min = (a + b) / 2\n",
    "    return x_min, iterations, midpoints\n",
    "\n",
    "# Run Binary Search\n",
    "a, b = -1, 0\n",
    "tol = 1e-5\n",
    "x_min, iterations, midpoints = binary_search_derivative(f_prime, a, b, tol)\n",
    "\n",
    "# Print results\n",
    "print(f\"Approximate minimum at x = {x_min:.6f}\")\n",
    "print(f\"Function value f(x) = {f(x_min):.6f}\")\n",
    "print(f\"Number of iterations: {iterations}\")\n",
    "\n",
    "# Plot the function and search progress\n",
    "x = np.linspace(-2, 1, 1000)\n",
    "y = f(x)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(x, y, '-', label='f(x) = log(exp(x) + exp(-2x - 3))')\n",
    "\n",
    "# Plot the midpoints from the first few iterations\n",
    "plt.plot(-1, f(-1), 'o', color='black', label='a')\n",
    "plt.plot(0, f(0), 'o', color='black', label='b')\n",
    "for i, m in enumerate(midpoints[:5]):  # Show first 5 iterations\n",
    "    plt.plot(m, f(m), 'o', label=f'Iteration {i+1}' if i < 5 else '')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Binary Search on Derivative')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5088a08-ba48-4c94-af3d-5134c2897506",
   "metadata": {},
   "source": [
    "### 3. Thiết kế một hàm mục tiêu xác định trên $\\mathbb{R}^2$ mà gradient descent rất chậm.\n",
    "#### Hàm $f(x_1, x_2)= x_1^2 + Sx_2^2$\n",
    "Tại sao hàm $f(x_1, x_2)= x_1^2 + Sx_2^2$ lại hội tụ chậm:\n",
    "- Cực tiểu toàn cục của hàm này rõ ràng nằm tại $(x_1, x_2) = (0, 0)$, với $f(0, 0) = 0$.\n",
    "- $\\nabla f(x_1, x_2) = [2x_1,\\ 2Sx_2]$\n",
    "- $H = \\begin{bmatrix}\n",
    "\\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} \\\\\n",
    "\\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2}\n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix}\n",
    "2 & 0 \\\\\n",
    "0 & 2S\n",
    "\\end{bmatrix}$\n",
    "\n",
    "### Số điều kiện (Condition Number):\n",
    "\n",
    "Các giá trị riêng của ma trận Hessian là:\n",
    "\n",
    "- $\\lambda_1 = 2$\n",
    "- $\\lambda_2 = 2S$\n",
    "\n",
    "Vậy số điều kiện của Hessian là:\n",
    "$$\n",
    "\\kappa(H) = \\frac{\\lambda_{\\text{max}}}{\\lambda_{\\text{min}}} = \\frac{2S}{2} = S\n",
    "$$\n",
    "Nếu $S$ lớn (ví dụ $S = 100$), số điều kiện là 100. Khi $S$ lớn, các ellipse sẽ bị kéo dãn mạnh. Nếu $S > 1$, chúng bị kéo dãn theo trục $x_1$ (nghĩa là \"thung lũng\" sẽ hẹp theo phương $x_2$ và dài theo phương $x_1$). Hàm tăng rất nhanh theo hướng $x_2$ so với hướng $x_1$.\n",
    "\n",
    "### Hành vi của Gradient Descent:\n",
    "\n",
    "Gradient $\\nabla f = [2x_1,\\ 2Sx_2]$ sẽ có thành phần lớn hơn nhiều ở hướng $x_2$ (do hệ số $2S$) khi $x_2 \\ne 0$.\n",
    "\n",
    "Khi Gradient Descent cập nhật:\n",
    "\n",
    "$$\n",
    "x_{\\text{new}} = x_{\\text{old}} - \\alpha \\nabla f\n",
    "$$\n",
    "\n",
    "thì thay đổi của $x_2$ sẽ lớn hơn đáng kể so với $x_1$.\n",
    "\n",
    "Điều này khiến thuật toán dao động (zig-zag) qua lại nhanh trong phần hẹp của thung lũng (hướng $x_2$), trong khi tiến triển dọc theo phần bằng phẳng (hướng $x_1$) rất chậm.\n",
    "\n",
    "Để tránh sai lệch do thành phần gradient $x_2$ quá lớn, tốc độ học $\\alpha$ phải được giữ rất nhỏ, điều này càng làm chậm bước đi theo hướng $x_1$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43993998-f94f-4aa0-baf3-6cd77062543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "S = 100  # Scaling factor\n",
    "\n",
    "def f(x1, x2):\n",
    "  return x1**2 + S * x2**2\n",
    "\n",
    "def grad_f(x1, x2):\n",
    "  return np.array([2 * x1, 2 * S * x2])\n",
    "\n",
    "# --- Gradient Descent Implementation ---\n",
    "def gradient_descent(grad_f, start_point, learning_rate, iterations):\n",
    "    x = np.array(start_point, dtype=float)\n",
    "    path = [x.copy()] # Store the path\n",
    "    for i in range(iterations):\n",
    "        grad = grad_f(x[0], x[1])\n",
    "        x = x - learning_rate * grad\n",
    "        path.append(x.copy())\n",
    "        # Optional: Check for divergence or convergence\n",
    "        if np.linalg.norm(grad) < 1e-6:\n",
    "            print(f\"Converged at iteration {i+1}\")\n",
    "            break\n",
    "        if np.any(np.abs(x) > 1e5): # Crude divergence check\n",
    "            print(f\"Diverged at iteration {i+1}\")\n",
    "            break\n",
    "    return np.array(path)\n",
    "\n",
    "# --- Parameters ---\n",
    "start_x = np.array([10.0, 1.0])   \n",
    "learning_rate_eta = 0.01\n",
    "num_iterations = 100\n",
    "\n",
    "# --- Run Gradient Descent ---\n",
    "path = gradient_descent(\n",
    "    grad_f,\n",
    "    start_x,\n",
    "    learning_rate_eta,\n",
    "    num_iterations\n",
    ")\n",
    "def draw_function(path):\n",
    "    \n",
    "    x1_vals = np.linspace(min(path[:, 0].min(), -10) - 1, max(path[:, 0].max(), 10) + 1, 200)\n",
    "    x2_vals = np.linspace(min(path[:, 1].min(), -1.5) - 0.2, max(path[:, 1].max(), 1.5) + 0.2, 200)\n",
    "    X1, X2 = np.meshgrid(x1_vals, x2_vals)\n",
    "    Z = f(X1, X2)\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    levels = np.logspace(0, np.log10(Z.max() if Z.max() > 0 else 1), 30) if Z.max() > 0 else 10\n",
    "    contour = plt.contour(X1, X2, Z, levels=levels, cmap='viridis')\n",
    "    plt.colorbar(contour, label='f(x₁, x₂)')\n",
    "    \n",
    "    # Plot the path of gradient descent\n",
    "    plt.plot(path[:, 0], path[:, 1], 'r-o', markersize=3, linewidth=1, label=f'GD Path (η={learning_rate_eta})')\n",
    "    \n",
    "    plt.scatter(0, 0, color='black', marker='*', s=150, label='Minimum (0,0)', zorder=5)\n",
    "    plt.scatter(start_x[0], start_x[1], color='blue', s=100, label='Start Point', zorder=4)\n",
    "    \n",
    "    plt.title(f'Gradient Descent on f(x₁, x₂) = x₁² + {S}x₂²')\n",
    "    plt.xlabel('x₁')\n",
    "    plt.ylabel('x₂')\n",
    "    plt.legend()\n",
    "    plt.axis('equal') \n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "draw_function(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8604d6-d4b5-4724-aca1-197ec6e127f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters ---\n",
    "start_x = np.array([10.0, 1.0])   \n",
    "learning_rate_eta = 0.005\n",
    "num_iterations = 100\n",
    "\n",
    "# --- Run Gradient Descent ---\n",
    "path = gradient_descent(\n",
    "    grad_f,\n",
    "    start_x,\n",
    "    learning_rate_eta,\n",
    "    num_iterations\n",
    ")\n",
    "draw_function(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaefcc5d-c02f-4f5d-8dd2-821bdc7f926b",
   "metadata": {},
   "source": [
    "### 4. Triển khai phiên bản của phương pháp Newton bằng cách sử dụng tiền điều kiện hóa.\n",
    "Tiền điều kiện chéo (Diagonal Preconditioner) $M$:\n",
    "\n",
    "Ta lấy các phần tử trên đường chéo chính của Hessian: $\\text{diag}(H) = [2,\\ 2S]$.\n",
    "\n",
    "Dùng giá trị tuyệt đối (mặc dù trong trường hợp này với $S > 0$, chúng đã là số dương): \n",
    "\n",
    "$$\n",
    "M_{\\text{diag}} = [|2|,\\ |2S|] = [2,\\ 2S]\n",
    "$$\n",
    "\n",
    "Ma trận tiền điều kiện $M$ (nếu viết đầy đủ, dù ta chỉ cần phần tử đường chéo để tính $M^{-1} \\nabla f$):\n",
    "\n",
    "$$\n",
    "M = \\begin{bmatrix}\n",
    "2 & 0 \\\\\n",
    "0 & 2S\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Nghịch đảo của tiền điều kiện chéo $M^{-1}$ (áp dụng từng phần tử):\n",
    "\n",
    "Nếu $M$ là ma trận chéo với phần tử $m_{ii}$, thì $M^{-1}$ cũng là chéo với phần tử $1/m_{ii}$.\n",
    "\n",
    "Vì vậy, tiền điều kiện có tác dụng **chia từng thành phần của gradient cho phần tử tương ứng trên đường chéo của Hessian**.\n",
    "\n",
    "---\n",
    "\n",
    "### Quy tắc cập nhật:\n",
    "\n",
    "Gradient descent có tiền điều kiện chuẩn là:\n",
    "\n",
    "$$\n",
    "x_{\\text{new}} = x_{\\text{old}} - \\eta \\cdot M^{-1} \\nabla f\n",
    "$$\n",
    "\n",
    "Với $M$ là ma trận chéo, ta có:\n",
    "\n",
    "- $x_1^{\\text{new}} = x_1^{\\text{old}} - \\eta \\cdot \\left( \\frac{\\partial f / \\partial x_1}{|H_{11}|} \\right)$  \n",
    "- $x_2^{\\text{new}} = x_2^{\\text{old}} - \\eta \\cdot \\left( \\frac{\\partial f / \\partial x_2}{|H_{22}|} \\right)$\n",
    "\n",
    "---\n",
    "\n",
    "### Thay các giá trị cụ thể vào:\n",
    "\n",
    "- $x_1^{\\text{new}} = x_1^{\\text{old}} - \\eta \\cdot \\left( \\frac{2x_1^{\\text{old}}}{|2|} \\right) = x_1^{\\text{old}} - \\eta \\cdot x_1^{\\text{old}} = x_1^{\\text{old}} (1 - \\eta)$\n",
    "\n",
    "- $x_2^{\\text{new}} = x_2^{\\text{old}} - \\eta \\cdot \\left( \\frac{2Sx_2^{\\text{old}}}{|2S|} \\right) = x_2^{\\text{old}} - \\eta \\cdot x_2^{\\text{old}} = x_2^{\\text{old}} (1 - \\eta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f01d3c8-59dd-45f5-b550-a0d550707fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def diag_hessian_abs_f(x1, x2):\n",
    "\n",
    "  h11 = 2.0\n",
    "  h22 = 2.0 * S\n",
    "  epsilon = 1e-8\n",
    "  return np.array([abs(h11) + epsilon, abs(h22) + epsilon])\n",
    "\n",
    "def preconditioned_gradient_descent(\n",
    "    grad_f, diag_hess_abs_f, start_point, learning_rate_eta, iterations\n",
    "):\n",
    "    x = np.array(start_point, dtype=float)\n",
    "    path = [x.copy()] # Store the path\n",
    "\n",
    "    for i in range(iterations):\n",
    "        grad = grad_f(x[0], x[1])\n",
    "        diag_H_abs = diag_hess_abs_f(x[0], x[1])\n",
    "\n",
    "        # Element-wise division for preconditioning\n",
    "        preconditioned_grad = grad / diag_H_abs\n",
    "\n",
    "        x = x - learning_rate_eta * preconditioned_grad\n",
    "        path.append(x.copy())\n",
    "\n",
    "        # Check for convergence or divergence\n",
    "        if np.linalg.norm(grad) < 1e-7: # Check original gradient for convergence\n",
    "            print(f\"Converged at iteration {i+1}\")\n",
    "            break\n",
    "        if np.any(np.abs(x) > 1e6): # Crude divergence check\n",
    "            print(f\"Diverged at iteration {i+1}\")\n",
    "            break\n",
    "    return np.array(path)\n",
    "\n",
    "# --- Parameters ---\n",
    "start_x = np.array([10.0, 1.0])   # Start pointt\n",
    "learning_rate_eta = 0.5 \n",
    "num_iterations = 50\n",
    "\n",
    "\n",
    "path_preconditioned = preconditioned_gradient_descent(\n",
    "    grad_f,\n",
    "    diag_hessian_abs_f,\n",
    "    start_x,\n",
    "    learning_rate_eta,\n",
    "    num_iterations\n",
    ")\n",
    "draw_function(path_preconditioned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f26e41e-5847-4251-a027-7b726067b493",
   "metadata": {},
   "source": [
    "Với tốc độ học $\\eta=0.5$ ta thấy sau lần lặp đầu tiên giá trị của $x_1, x_2$ đã giảm 1 nửa do \n",
    "- $x_1^{\\text{new}} = x_1^{\\text{old}} (1 - \\eta)=x_1^{\\text{old}} (1 - 0.5)$ \n",
    "- $x_2^{\\text{new}} = x_2^{\\text{old}} (1 - \\eta)=x_2^{\\text{old}} (1 - 0.5)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3826da86-828d-4a54-bfa7-ab2de1d89b54",
   "metadata": {},
   "source": [
    "### Áp dụng thuật toán trên cho một số hàm mục tiêu (lồi hoặc không). Điều gì xảy ra nếu bạn xoay tọa độ 45 độ?\n",
    "#### 1. Elliptic Paraboloid:\n",
    "\n",
    "$$\n",
    "f(x_1, x_2) = x_1^2 + 100x_2^2\n",
    "$$\n",
    "\n",
    "- $\\text{diag}_H^{\\text{abs}} = [2,\\ 200]$ (hằng số)\n",
    "- **Kỳ vọng**: Hội tụ nhanh và trực tiếp (1 bước nếu $\\eta = 1$)\n",
    "#### 2. Circular Paraboloid:\n",
    "\n",
    "$$\n",
    "f(x_1, x_2) = x_1^2 + x_2^2\n",
    "$$\n",
    "\n",
    "- $\\text{diag}_H^{\\text{abs}} = [2,\\ 2]$ (hằng số)\n",
    "- **Kỳ vọng**: Hội tụ nhanh và trực tiếp (1 bước nếu $\\eta = 1$).  \n",
    "#### 3. Hàm Rosenbrock (Không lồi):\n",
    "\n",
    "$$\n",
    "f(x_1, x_2) = (1 - x_1)^2 + 100(x_2 - x_1^2)^2\n",
    "$$\n",
    "\n",
    "- $\\frac{\\partial^2 f}{\\partial x_1^2} = 2 - 400(x_2 - x_1^2) + 1200x_1^2$\n",
    "- $\\frac{\\partial^2 f}{\\partial x_2^2} = 200$\n",
    "\n",
    "- $\\text{diag}_H^{\\text{abs}} = [|2 - 400(x_2 - x_1^2) + 1200x_1^2|,\\ 200]$  *($H_{11}$ có thể âm!)*\n",
    "\n",
    "- **Kỳ vọng**: Thành phần $H_{11}$ rất phức tạp và phụ thuộc vào $x_1, x_2$.  \n",
    "\n",
    "#### 4. Hàm không lồi đơn giản (Hai điểm cực tiểu):\n",
    "\n",
    "$$\n",
    "f(x_1, x_2) = x_1^4 - 2x_1^2 + x_2^2\n",
    "$$\n",
    "\n",
    "- Cực tiểu tại $(\\pm1,\\ 0)$, điểm yên tại $(0,\\ 0)$\n",
    "- $\\frac{\\partial^2 f}{\\partial x_1^2} = 12x_1^2 - 4$\n",
    "- $\\frac{\\partial^2 f}{\\partial x_2^2} = 2$\n",
    "- $\\text{diag}_H^{\\text{abs}} = [|12x_1^2 - 4|,\\ 2]$  *( $H_{11}$ có thể âm hoặc bằng 0)*\n",
    "- **Kỳ vọng**: Thuật toán sẽ hội tụ đến một cực tiểu tùy theo điểm khởi đầu.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4167b94e-1736-47e2-860b-d03890feca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Helper: Generic Optimization and Plotting ---\n",
    "def run_optimizer(\n",
    "    optimizer_func,\n",
    "    f_obj,\n",
    "    grad_f,\n",
    "    diag_hess_abs_f, # Specific to preconditioned GD\n",
    "    start_point,\n",
    "    learning_rate_eta,\n",
    "    iterations,\n",
    "    title_prefix=\"\",\n",
    "    S_param=None # For functions that use S\n",
    "):\n",
    "    if S_param is not None: # If the function needs S, curry it\n",
    "        obj_func_to_plot = lambda x1, x2: f_obj(x1, x2, S_param)\n",
    "    else:\n",
    "        obj_func_to_plot = f_obj\n",
    "\n",
    "    path = optimizer_func(\n",
    "        grad_f,\n",
    "        diag_hess_abs_f, # Pass this\n",
    "        start_point,\n",
    "        learning_rate_eta,\n",
    "        iterations,\n",
    "        S_param # Pass S if needed for grad/hessian\n",
    "    )\n",
    "\n",
    "    print(f\"{title_prefix} - Starting at: {path[0]}\")\n",
    "    print(f\"{title_prefix} - Ending at after {len(path)-1} iterations: {path[-1]}\")\n",
    "\n",
    "    # Visualization\n",
    "    # Adjust plot ranges based on path and known features of the function\n",
    "    x_min_plot = min(path[:, 0].min() - 1, -2.5 if \"Rosenbrock\" in title_prefix else -3)\n",
    "    x_max_plot = max(path[:, 0].max() + 1, 2.5 if \"Rosenbrock\" in title_prefix else 3)\n",
    "    y_min_plot = min(path[:, 1].min() - 1, -1.5 if \"Rosenbrock\" in title_prefix else -3)\n",
    "    y_max_plot = max(path[:, 1].max() + 1, 3.5 if \"Rosenbrock\" in title_prefix else 3)\n",
    "\n",
    "    x1_vals = np.linspace(x_min_plot, x_max_plot, 200)\n",
    "    x2_vals = np.linspace(y_min_plot, y_max_plot, 200)\n",
    "    X1, X2 = np.meshgrid(x1_vals, x2_vals)\n",
    "    Z = obj_func_to_plot(X1, X2)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    levels = np.logspace(np.log10(max(Z.min(), 0.01)), np.log10(Z.max() if Z.max() > 0 else 1), 30) if Z.min() < Z.max() else 15\n",
    "    try:\n",
    "        contour = plt.contour(X1, X2, Z, levels=levels, cmap='viridis')\n",
    "        plt.colorbar(contour, label='f(x₁, x₂)')\n",
    "    except Exception as e:\n",
    "        print(f\"Contour plot error for {title_prefix}: {e}\")\n",
    "        plt.contour(X1, X2, Z, cmap='viridis') # Fallback\n",
    "\n",
    "\n",
    "    plt.plot(path[:, 0], path[:, 1], 'g-o', markersize=3, linewidth=1, label=f'Preconditioned GD (η={learning_rate_eta})')\n",
    "    plt.scatter(path[0, 0], path[0, 1], color='blue', s=100, label='Start', zorder=4)\n",
    "    # Add known minima if applicable\n",
    "    if \"Ill-Conditioned\" in title_prefix or \"Well-Conditioned\" in title_prefix:\n",
    "        plt.scatter(0, 0, color='black', marker='*', s=150, label='Minimum (0,0)', zorder=5)\n",
    "    elif \"Rosenbrock\" in title_prefix:\n",
    "        plt.scatter(1, 1, color='black', marker='*', s=150, label='Minimum (1,1)', zorder=5)\n",
    "    elif \"Two Minima\" in title_prefix:\n",
    "        plt.scatter([1, -1], [0, 0], color='black', marker='*', s=150, label='Minima (±1,0)', zorder=5)\n",
    "\n",
    "\n",
    "    plt.title(title_prefix)\n",
    "    plt.xlabel('x₁')\n",
    "    plt.ylabel('x₂')\n",
    "    plt.legend()\n",
    "    plt.axis('equal' if \"Ill-Conditioned\" in title_prefix or \"Well-Conditioned\" in title_prefix else 'tight')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    return path \n",
    "    \n",
    "\n",
    "# --- Diagonal Preconditioned Gradient Descent (from previous example) ---\n",
    "def preconditioned_gradient_descent(\n",
    "    grad_f, diag_hess_abs_f, start_point, learning_rate_eta, iterations, S_param=None\n",
    "):\n",
    "    x = np.array(start_point, dtype=float)\n",
    "    path = [x.copy()]\n",
    "    epsilon_hess = 1e-8 # For numerical stability if diag_H is zero\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # Pass S if the gradient/Hessian functions need it\n",
    "        current_grad = grad_f(x[0], x[1], S_param) if S_param is not None else grad_f(x[0], x[1])\n",
    "        current_diag_H_abs = diag_hess_abs_f(x[0], x[1], S_param) if S_param is not None else diag_hess_abs_f(x[0], x[1])\n",
    "\n",
    "        # Ensure diagonal elements are not zero (add epsilon)\n",
    "        preconditioner = np.maximum(current_diag_H_abs, epsilon_hess)\n",
    "        preconditioned_grad = current_grad / preconditioner\n",
    "\n",
    "        x = x - learning_rate_eta * preconditioned_grad\n",
    "        path.append(x.copy())\n",
    "\n",
    "        if np.linalg.norm(current_grad) < 1e-7:\n",
    "            # print(f\"Converged at iteration {i+1}\")\n",
    "            break\n",
    "        if np.any(np.abs(x) > 1e7): # Divergence check\n",
    "            print(f\"Diverged at iteration {i+1}\")\n",
    "            break\n",
    "    return np.array(path)\n",
    "\n",
    "# --- Function Definitions ---\n",
    "\n",
    "# 1. Ill-Conditioned Convex (Elliptical Paraboloid)\n",
    "S_ill = 100\n",
    "def f_ill(x1, x2, S=S_ill): return x1**2 + S * x2**2\n",
    "def grad_f_ill(x1, x2, S=S_ill): return np.array([2 * x1, 2 * S * x2])\n",
    "def diag_hess_abs_f_ill(x1, x2, S=S_ill): return np.array([abs(2.0), abs(2.0 * S)])\n",
    "\n",
    "# 2. Well-Conditioned Convex (Circular Paraboloid)\n",
    "def f_well(x1, x2): return x1**2 + x2**2\n",
    "def grad_f_well(x1, x2): return np.array([2 * x1, 2 * x2])\n",
    "def diag_hess_abs_f_well(x1, x2): return np.array([abs(2.0), abs(2.0)])\n",
    "\n",
    "# 3. Rosenbrock Function (Non-Convex)\n",
    "def f_rosen(x1, x2): return (1 - x1)**2 + 100 * (x2 - x1**2)**2\n",
    "def grad_f_rosen(x1, x2):\n",
    "    g1 = -2 * (1 - x1) - 400 * x1 * (x2 - x1**2)\n",
    "    g2 = 200 * (x2 - x1**2)\n",
    "    return np.array([g1, g2])\n",
    "def diag_hess_abs_f_rosen(x1, x2):\n",
    "    h11 = 2 - 400 * (x2 - x1**2) + 1200 * x1**2 # Corrected from 800 to 1200\n",
    "    h22 = 200.0\n",
    "    return np.array([abs(h11), abs(h22)])\n",
    "\n",
    "# 4. Simple Non-Convex (Two Minima)\n",
    "def f_two_min(x1, x2): return x1**4 - 2*x1**2 + x2**2\n",
    "def grad_f_two_min(x1, x2): return np.array([4*x1**3 - 4*x1, 2*x2])\n",
    "def diag_hess_abs_f_two_min(x1, x2):\n",
    "    h11 = 12*x1**2 - 4\n",
    "    h22 = 2.0\n",
    "    return np.array([abs(h11), abs(h22)])\n",
    "\n",
    "\n",
    "# --- Run Experiments ---\n",
    "eta = 0.5 # A reasonably robust learning rate for this preconditioned method\n",
    "# For quadratics, eta=1 is often optimal, but 0.5 is safer for non-quadratics\n",
    "iters = 200\n",
    "\n",
    "print(\"--- 1. Ill-Conditioned Elliptical Paraboloid ---\")\n",
    "run_optimizer(preconditioned_gradient_descent, f_ill, grad_f_ill, diag_hess_abs_f_ill,\n",
    "              [10.0, 1.0], 1.0, 50, \"Ill-Conditioned Convex\", S_param=S_ill) # eta=1 is good here\n",
    "\n",
    "print(\"\\n--- 2. Well-Conditioned Circular Paraboloid ---\")\n",
    "run_optimizer(preconditioned_gradient_descent, f_well, grad_f_well, diag_hess_abs_f_well,\n",
    "              [10.0, 1.0], 1.0, 50, \"Well-Conditioned Convex\") # eta=1 is good here\n",
    "\n",
    "print(\"\\n--- 3. Rosenbrock Function ---\")\n",
    "# Rosenbrock needs smaller eta and more iterations\n",
    "run_optimizer(preconditioned_gradient_descent, f_rosen, grad_f_rosen, diag_hess_abs_f_rosen,\n",
    "              [-1.5, 1.5], 0.1, 500, \"Rosenbrock (Non-Convex)\") # Try smaller eta\n",
    "\n",
    "print(\"\\n--- 4. Two Minima Function ---\")\n",
    "run_optimizer(preconditioned_gradient_descent, f_two_min, grad_f_two_min, diag_hess_abs_f_two_min,\n",
    "              [0.5, 0.5], eta, iters, \"Two Minima (Start near saddle)\")\n",
    "run_optimizer(preconditioned_gradient_descent, f_two_min, grad_f_two_min, diag_hess_abs_f_two_min,\n",
    "              [2.0, 0.5], eta, iters, \"Two Minima (Start near x1=1 min)\")\n",
    "run_optimizer(preconditioned_gradient_descent, f_two_min, grad_f_two_min, diag_hess_abs_f_two_min,\n",
    "              [-2.0, -0.5], eta, iters, \"Two Minima (Start near x1=-1 min)\")\n",
    "\n",
    "S_rot = 100 # Use the same S as in the ill-conditioned example\n",
    "\n",
    "# Rotated function f_rot(u1, u2)\n",
    "def f_rotated(u1, u2, S=S_rot):\n",
    "    return 0.5 * ((1+S)*u1**2 + (1+S)*u2**2 + 2*(S-1)*u1*u2)\n",
    "\n",
    "def grad_f_rotated(u1, u2, S=S_rot):\n",
    "    g_u1 = (1+S)*u1 + (S-1)*u2\n",
    "    g_u2 = (S-1)*u1 + (1+S)*u2\n",
    "    return np.array([g_u1, g_u2])\n",
    "\n",
    "def diag_hess_abs_f_rotated(u1, u2, S=S_rot):\n",
    "    # Diagonal elements of H_rot are both (1+S)\n",
    "    h_diag = 1.0 + S\n",
    "    return np.array([abs(h_diag), abs(h_diag)])\n",
    "\n",
    "print(\"\\n--- 5. Rotated Ill-Conditioned Function (45 degrees) ---\")\n",
    "# Start point in the rotated coordinate system\n",
    "# If original start was (10,1), rotated start could be approx (10/√2 + 1/√2, -10/√2 + 1/√2)\n",
    "# Or just pick a challenging start like [10.0, 1.0] in u1, u2 space\n",
    "rotated_start = [7.0, -7.0] # Example start in u1, u2 space\n",
    "\n",
    "# Let's compare with standard GD as well for this one\n",
    "def standard_gradient_descent(grad_f, start_point, learning_rate_eta, iterations, S_param=None):\n",
    "    x = np.array(start_point, dtype=float)\n",
    "    path = [x.copy()]\n",
    "    for i in range(iterations):\n",
    "        current_grad = grad_f(x[0], x[1], S_param) if S_param is not None else grad_f(x[0], x[1])\n",
    "        x = x - learning_rate_eta * current_grad\n",
    "        path.append(x.copy())\n",
    "        if np.linalg.norm(current_grad) < 1e-7: break\n",
    "        if np.any(np.abs(x) > 1e7): print(\"Std GD Diverged\"); break\n",
    "    return np.array(path)\n",
    "\n",
    "eta_rotated = 0.005 # Need a smaller eta for the rotated version (both methods)\n",
    "iters_rotated = 300\n",
    "\n",
    "path_prec_rot = run_optimizer(preconditioned_gradient_descent, f_rotated, grad_f_rotated, diag_hess_abs_f_rotated,\n",
    "                  rotated_start, eta_rotated, iters_rotated, \"Rotated Ill-Conditioned (Preconditioned GD)\", S_param=S_rot)\n",
    "\n",
    "print(\"\\nComparing with Standard GD on Rotated function:\")\n",
    "path_std_gd_rot = standard_gradient_descent(grad_f_rotated, rotated_start, eta_rotated, iters_rotated, S_param=S_rot)\n",
    "\n",
    "# Visualization for comparison\n",
    "plt.figure(figsize=(10, 7))\n",
    "x1_vals_rot = np.linspace(min(path_prec_rot[:,0].min(), path_std_gd_rot[:,0].min()) -1, max(path_prec_rot[:,0].max(), path_std_gd_rot[:,0].max()) +1, 200)\n",
    "x2_vals_rot = np.linspace(min(path_prec_rot[:,1].min(), path_std_gd_rot[:,1].min()) -1, max(path_prec_rot[:,1].max(), path_std_gd_rot[:,1].max()) +1, 200)\n",
    "X1_rot, X2_rot = np.meshgrid(x1_vals_rot, x2_vals_rot)\n",
    "Z_rot = f_rotated(X1_rot, X2_rot, S_rot)\n",
    "\n",
    "levels_rot = np.logspace(np.log10(max(Z_rot.min(),0.01)), np.log10(Z_rot.max() if Z_rot.max() > 0 else 1), 30) if Z_rot.min() < Z_rot.max() else 15\n",
    "contour_rot = plt.contour(X1_rot, X2_rot, Z_rot, levels=levels_rot, cmap='viridis')\n",
    "plt.colorbar(contour_rot, label='f_rot(u₁, u₂)')\n",
    "\n",
    "plt.plot(path_prec_rot[:, 0], path_prec_rot[:, 1], 'g-o', markersize=3, linewidth=1, label=f'Preconditioned GD (η={eta_rotated})')\n",
    "plt.plot(path_std_gd_rot[:, 0], path_std_gd_rot[:, 1], 'm--x', markersize=3, linewidth=1, label=f'Standard GD (η={eta_rotated})')\n",
    "\n",
    "plt.scatter(0, 0, color='black', marker='*', s=150, label='Minimum (0,0)', zorder=5) # Minimum is still at origin\n",
    "plt.scatter(rotated_start[0], rotated_start[1], color='blue', s=100, label='Start', zorder=4)\n",
    "plt.title(f'Comparison on Rotated f(x₁,x₂) = x₁² + {S_rot}x₂²')\n",
    "plt.xlabel('u₁ (rotated coord)')\n",
    "plt.ylabel('u₂ (rotated coord)')\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc75a3-99ed-42e7-b104-3fa855c178d1",
   "metadata": {},
   "source": [
    "#### Vấn đề: Ảnh hưởng của phép quay đến cấu trúc Hessian\n",
    "\n",
    "Khi quay một hàm như:$f(x_1, x_2) = x_1^2 + 100x_2^2$ một góc 45 độ, hàm mới (với tọa độ gọi là $u_1, u_2$) sẽ có các **thành phần ngoài đường chéo** mà giá trị của chúng lớn hơn giá trị của thành phần trên đường chéo trong ma trận Hessian.\n",
    "\n",
    "Các **trục chính** của các đường đồng mức hình elip **sẽ không còn thẳng hàng** với các trục $u_1$ và $u_2$ nữa.\n",
    "\n",
    "Điều này có nghĩa là hình dạng của bài toán bị \"nghiêng\", làm cho các phương pháp như Gradient Descent hay tiền điều kiện chéo dựa trên các phần tử đường chéo **mất hiệu quả** rõ rệt.\n",
    "\n",
    "#### Hàm gốc (tọa độ $x_1, x_2$):\n",
    "\n",
    "Giả sử ta có hàm $f(x_1, x_2) = x_1^2 + Sx_2^2$. Hessian $H = \\begin{bmatrix} H_{11} & 0 \\\\ 0 & H_{22} \\end{bmatrix}$\n",
    "\n",
    "Là ma trận chéo. Bộ tiền điều kiện chéo (diagonal preconditioner) hoạt động tốt vì:$M_{\\text{diag}} = [|H_{11}|, |H_{22}|]$ xác định chính xác các tỉ lệ thay đổi theo từng hướng khác nhau này và chuẩn hóa chúng.\n",
    "\n",
    "#### Hàm sau khi quay (tọa độ $u_1, u_2$):\n",
    "\n",
    "Phép biến đổi quay 45 độ:$x_1 = \\frac{u_1 - u_2}{\\sqrt{2}}, \\quad x_2 = \\frac{u_1 + u_2}{\\sqrt{2}}$\n",
    "Thay vào hàm: $f(x_1, x_2) = x_1^2 + Sx_2^2$\n",
    "\n",
    "Ta được hàm sau khi quay:$f_{\\text{rot}}(u_1, u_2) = \\left( \\frac{u_1 - u_2}{\\sqrt{2}} \\right)^2 + S \\left( \\frac{u_1 + u_2}{\\sqrt{2}} \\right)^2$. \n",
    "\n",
    "Rút gọn: \n",
    "$f_{\\text{rot}}(u_1, u_2) = \\frac{1}{2}(u_1^2 - 2u_1u_2 + u_2^2) + \\frac{S}{2}(u_1^2 + 2u_1u_2 + u_2^2)\n",
    "= \\frac{1}{2}(1 + S)u_1^2 + \\frac{1}{2}(1 + S)u_2^2 + (S - 1)u_1u_2$\n",
    "\n",
    "---\n",
    "\n",
    "#### Ma trận Hessian sau khi quay:\n",
    "\n",
    "$$\n",
    "H_{\\text{rot}} =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial^2 f}{\\partial u_1^2} & \\frac{\\partial^2 f}{\\partial u_1 \\partial u_2} \\\\\n",
    "\\frac{\\partial^2 f}{\\partial u_2 \\partial u_1} & \\frac{\\partial^2 f}{\\partial u_2^2}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 + S & S - 1 \\\\\n",
    "S - 1 & 1 + S\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### Ảnh hưởng đến tiền điều kiện chéo:\n",
    "\n",
    "Bộ tiền điều kiện chỉ dùng phần tử chéo của Hessian:\n",
    "\n",
    "$$\n",
    "\\text{diag}(H_{\\text{rot}}) = [|1 + S|,\\ |1 + S|]\n",
    "$$\n",
    "\n",
    "Nó **bỏ qua hoàn toàn** phần tử ngoài đường chéo $(S - 1)$, đây là thành phần quan trọng khi $S$ lớn.\n",
    "\n",
    "Ví dụ, nếu $S = 100$ thì $S - 1 = 99$ — cho thấy mối tương quan mạnh giữa $u_1$ và $u_2$ mà tiền điều kiện chéo không nắm bắt được. Điều này khiến dẫn tới:\n",
    "- Hiệu suất của tiền điều kiện chéo sẽ **giảm sút đáng kể**.\n",
    "- Thuật toán sẽ **dao động** trở lại như Gradient Descent thông thường.\n",
    "- Tốc độ hội tụ sẽ chậm lại do vấn đề tỷ lệ co giãn không còn nằm theo trục tọa độ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0500338e-f41f-4614-a493-e90e0ef4f602",
   "metadata": {},
   "source": [
    "# 03. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08ed53f-736b-4850-af0a-a118197e6354",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "import d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a436f423-afc9-4927-9865-400be8d7f102",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9796f1-a271-441e-afb5-005b72be94b6",
   "metadata": {},
   "source": [
    "Trong học sâu (deep learning), hàm mục tiêu thường là trung bình của các hàm mất mát (loss function) cho từng mẫu trong tập dữ liệu huấn luyện.\n",
    "\n",
    "Giả sử có một tập huấn luyện gồm $n$ mẫu, gọi $f_i(\\mathbf{x})$ là hàm mất mát tương ứng với mẫu huấn luyện thứ $i$, trong đó $\\mathbf{x}$ là vector tham số.\n",
    "Khi đó, ta có hàm mục tiêu:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) = \\frac{1}{n} \\sum_{i = 1}^n f_i(\\mathbf{x}).\n",
    "$$\n",
    "\n",
    "Gradient của hàm mục tiêu tại $\\mathbf{x}$ được tính bằng:\n",
    "\n",
    "$$\n",
    "\\nabla f(\\mathbf{x}) = \\frac{1}{n} \\sum_{i = 1}^n \\nabla f_i(\\mathbf{x}).\n",
    "$$\n",
    "\n",
    "Nếu sử dụng phương pháp **Gradient Descent**, chi phí tính toán cho mỗi vòng lặp cập nhật tham số sẽ là $\\mathcal{O}(n)$, tức là **tăng tuyến tính** theo $n$. Do đó, khi tập dữ liệu huấn luyện **càng lớn** thì **chi phí** cho mỗi bước lặp của gradient descent **càng cao**.\n",
    "\n",
    "Phương pháp **Stochastic Gradient Descent (SGD)** giúp giảm chi phí tính toán ở mỗi bước lặp. Ở mỗi bước của SGD, ta chọn **ngẫu nhiên một mẫu** $i \\in \\{1, \\ldots, n\\}$ từ tập dữ liệu, và tính gradient $\\nabla f_i(\\mathbf{x})$ để cập nhật tham số $\\mathbf{x}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} \\leftarrow \\mathbf{x} - \\eta \\nabla f_i(\\mathbf{x}),\n",
    "$$\n",
    "\n",
    "trong đó $\\eta$ là tốc độ học (learning rate). Ta thấy rằng chi phí tính toán cho mỗi bước lặp giảm từ $\\mathcal{O}(n)$ (của gradient descent) xuống còn hằng số $\\mathcal{O}(1)$.\n",
    "\n",
    "Ngoài ra, cần nhấn mạnh rằng gradient ngẫu nhiên $\\nabla f_i(\\mathbf{x})$ là một ước lượng không chệch (unbiased estimate) của gradient đầy đủ $\\nabla f(\\mathbf{x})$ vì:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_i \\nabla f_i(\\mathbf{x}) = \\frac{1}{n} \\sum_{i = 1}^n \\nabla f_i(\\mathbf{x}) = \\nabla f(\\mathbf{x}).\n",
    "$$\n",
    "\n",
    "Điều này có nghĩa là, nhìn chung, gradient ngẫu nhiên là một ước lượng tốt cho gradient thực sự.\n",
    "\n",
    "Bây giờ, chúng ta sẽ so sánh nó với gradient descent bằng cách thêm nhiễu ngẫu nhiên có kỳ vọng bằng 0 và phương sai bằng 1 vào gradient để mô phỏng stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef6152-b278-4f7c-8eae-df2f70e032a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x1, x2):  # Objective function\n",
    "    return x1 ** 2 + 2 * x2 ** 2\n",
    "\n",
    "def f_grad(x1, x2):  # Gradient of the objective function\n",
    "    return 2 * x1, 4 * x2\n",
    "\n",
    "def sgd(x1, x2, s1, s2, f_grad):\n",
    "    g1, g2 = f_grad(x1, x2)\n",
    "    # Simulate noisy gradient\n",
    "    g1 += torch.normal(0.0, 1, (1,)).item()\n",
    "    g2 += torch.normal(0.0, 1, (1,)).item()\n",
    "    eta_t = eta * lr()\n",
    "    return (x1 - eta_t * g1, x2 - eta_t * g2, 0, 0)\n",
    "\n",
    "def constant_lr():\n",
    "    return 1\n",
    "\n",
    "eta = 0.1\n",
    "lr = constant_lr  # Constant learning rate\n",
    "d2l.show_trace_2d(f, d2l.train_2d(sgd, steps=50, f_grad=f_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda0443f-6eb0-4665-b99e-2dc924a66a22",
   "metadata": {},
   "source": [
    "Như chúng ta có thể thấy, quỹ đạo của các biến trong phương pháp stochastic gradient descent nhiễu hơn nhiều so với quỹ đạo quan sát được trong gradient descent. Điều này là do bản chất ngẫu nhiên của gradient. Cụ thể, ngay cả khi chúng ta đã tiến gần đến điểm cực tiểu, ta vẫn bị ảnh hưởng bởi sự bất định của gradient tức thời $\\eta \\nabla f_i(\\mathbf{x})$. Ngay cả sau 50 bước, chất lượng nghiệm vẫn chưa tốt. Thậm chí tệ hơn, nó sẽ không được cải thiện thêm dù có thực hiện thêm nhiều bước nữa.\n",
    "\n",
    "Điều này dẫn đến lựa chọn duy nhất: thay đổi tốc độ học $\\eta$. Tuy nhiên, nếu chọn giá trị quá nhỏ, ta sẽ không đạt được tiến triển đáng kể ban đầu. Ngược lại, nếu chọn quá lớn, ta sẽ không thu được nghiệm tốt, như đã thấy ở trên. Cách duy nhất để giải quyết mâu thuẫn này là giảm tốc độ học một cách *động* khi quá trình tối ưu hóa tiến triển.\n",
    "\n",
    "Đây cũng là lý do vì sao cần thêm một hàm tốc độ học `lr` vào hàm cập nhật `sgd`. Trong ví dụ trên, ta đã đặt hàm `lr` tương ứng là hằng số."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021715d3-2623-4468-84fd-d2cff032b85e",
   "metadata": {},
   "source": [
    "## Dynamic Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec0f72e-cf0c-4e90-8002-58a4e034c858",
   "metadata": {},
   "source": [
    "Thay thế $\\eta$ bằng một tốc độ học phụ thuộc vào thời gian $\\eta(t)$ làm tăng độ phức tạp trong việc kiểm soát sự hội tụ của một thuật toán tối ưu. Cụ thể, chúng ta cần xác định tốc độ giảm của $\\eta$. Nếu giảm quá nhanh, quá trình tối ưu sẽ dừng lại quá sớm. Nếu giảm quá chậm, ta sẽ lãng phí quá nhiều thời gian cho việc tối ưu.\n",
    "\n",
    "Sau đây là một vài chiến lược cơ bản để điều chỉnh $\\eta$ theo thời gian:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\eta(t) & = \\eta_i \\textrm{ nếu } t_i \\leq t \\leq t_{i+1}  && \\textrm{hằng theo từng khoảng (piecewise constant)} \\\\\n",
    "    \\eta(t) & = \\eta_0 \\cdot e^{-\\lambda t} && \\textrm{giảm theo hàm mũ (exponential decay)} \\\\\n",
    "    \\eta(t) & = \\eta_0 \\cdot (\\beta t + 1)^{-\\alpha} && \\textrm{giảm theo đa thức (polynomial decay)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Trong chiến lược *hằng theo từng khoảng*, chúng ta có thể giảm tốc độ học mỗi khi quá trình tối ưu hóa không còn cải thiện. Đây là một chiến lược phổ biến khi huấn luyện các mạng nơ-ron sâu. Ngoài ra, chúng ta có thể giảm mạnh hơn bằng cách *giảm theo hàm mũ*. Tuy nhiên, điều này thường dẫn đến việc dừng tối ưu quá sớm trước khi thuật toán hội tụ.\n",
    "\n",
    "Một lựa chọn phổ biến là *giảm theo đa thức* với $\\alpha = 0.5$. Trong trường hợp tối ưu hóa lồi (convex optimization), có nhiều chứng minh cho thấy tốc độ giảm này hoạt động hiệu quả và ổn định.\n",
    "\n",
    "Hãy cùng xem việc giảm theo hàm mũ trông như thế nào trong thực tế."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed384d7-2972-4be0-846f-c580c1ae5796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_lr():\n",
    "    # Global variable that is defined outside this function and updated inside\n",
    "    global t\n",
    "    t += 1\n",
    "    return math.exp(-0.1 * t)\n",
    "\n",
    "t = 1\n",
    "lr = exponential_lr\n",
    "d2l.show_trace_2d(f, d2l.train_2d(sgd, steps=1000, f_grad=f_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c6af05-4b24-426e-9e56-bb86a728058a",
   "metadata": {},
   "source": [
    "Như dự đoán, phương sai trong các tham số đã giảm đáng kể. Tuy nhiên, điều này phải đánh đổi bằng việc không hội tụ đến nghiệm tối ưu $\\mathbf{x} = (0, 0)$. Ngay cả sau 1000 bước lặp, chúng ta vẫn còn rất xa so với nghiệm tối ưu. Thực tế, thuật toán không hội tụ chút nào.\n",
    "\n",
    "Ngược lại, nếu chúng ta sử dụng phương pháp giảm theo đa thức, trong đó tốc độ học giảm theo nghịch đảo căn bậc hai của số bước, thì khả năng hội tụ được cải thiện rõ rệt chỉ sau 50 bước lặp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd05c250-d44b-40ff-8896-0dbc4c198aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_lr():\n",
    "    # Global variable that is defined outside this function and updated inside\n",
    "    global t\n",
    "    t += 1\n",
    "    return (1 + 0.1 * t) ** (-0.5)\n",
    "\n",
    "t = 1\n",
    "lr = polynomial_lr\n",
    "d2l.show_trace_2d(f, d2l.train_2d(sgd, steps=50, f_grad=f_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c143ea-bc8c-452b-b616-1a04c7b6cc93",
   "metadata": {},
   "source": [
    "Có rất nhiều cách khác nhau để thiết lập tốc độ học. Ví dụ, ta có thể bắt đầu với một tốc độ học nhỏ, sau đó tăng nhanh rồi lại giảm dần, tuy nhiên giảm chậm hơn. Thậm chí, ta có thể xen kẽ giữa tốc độ học nhỏ và lớn. Có rất nhiều chiến lược điều chỉnh tốc độ học như vậy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52573c3-24bf-4bd1-b96c-4bcb8d3a85d9",
   "metadata": {},
   "source": [
    "## Convergence Analysis for Convex Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a44124-9f84-4832-bc85-6402bcfd64ac",
   "metadata": {},
   "source": [
    "Trong phần này, chúng ta sẽ phân tích hội tụ của phương pháp stochastic gradient descent (SGD) đối với hàm mục tiêu lồi tùy chọn.\n",
    "\n",
    "Giả sử hàm mục tiêu $f(\\boldsymbol{\\xi}, \\mathbf{x})$ là lồi theo $\\mathbf{x}$ với mọi mẫu $\\boldsymbol{\\xi}$. Cụ thể, ta xét công thức cập nhật của SGD:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t+1} = \\mathbf{x}_{t} - \\eta_t \\partial_\\mathbf{x} f(\\boldsymbol{\\xi}_t, \\mathbf{x}),\n",
    "$$\n",
    "\n",
    "trong đó $f(\\boldsymbol{\\xi}_t, \\mathbf{x})$ là hàm mục tiêu tương ứng với mẫu huấn luyện $\\boldsymbol{\\xi}_t$ được lấy ngẫu nhiên tại bước $t$, và $\\mathbf{x}$ là tham số mô hình. Gọi:\n",
    "\n",
    "$$\n",
    "R(\\mathbf{x}) = E_{\\boldsymbol{\\xi}}[f(\\boldsymbol{\\xi}, \\mathbf{x})]\n",
    "$$\n",
    "\n",
    "là rủi ro kỳ vọng, và $R^*$ là giá trị tối thiểu của nó theo $\\mathbf{x}$. Gọi $\\mathbf{x}^*$ là điểm tối ưu (giả định tồn tại trong miền xác định của $\\mathbf{x}$). Khi đó ta có thể theo dõi khoảng cách giữa tham số hiện tại $\\mathbf{x}_t$ tại thời điểm $t$ và điểm tối ưu $\\mathbf{x}^*$ để xem liệu có cải thiện theo thời gian không:\n",
    "\n",
    "$$\\begin{aligned}    &\\|\\mathbf{x}_{t+1} - \\mathbf{x}^*\\|^2 \\\\ =& \\|\\mathbf{x}_{t} - \\eta_t \\partial_\\mathbf{x} f(\\boldsymbol{\\xi}_t, \\mathbf{x}) - \\mathbf{x}^*\\|^2 \\\\    =& \\|\\mathbf{x}_{t} - \\mathbf{x}^*\\|^2 + \\eta_t^2 \\|\\partial_\\mathbf{x} f(\\boldsymbol{\\xi}_t, \\mathbf{x})\\|^2 - 2 \\eta_t    \\left\\langle \\mathbf{x}_t - \\mathbf{x}^*, \\partial_\\mathbf{x} f(\\boldsymbol{\\xi}_t, \\mathbf{x})\\right\\rangle. \\end{aligned} \\tag{1} $$\n",
    "\n",
    "Giả sử chuẩn $\\ell_2$ của gradient ngẫu nhiên bị chặn bởi một hằng số $L$, ta có:\n",
    "\n",
    "$$\n",
    "\\eta_t^2 \\|\\partial_\\mathbf{x} f(\\boldsymbol{\\xi}_t, \\mathbf{x})\\|^2 \\leq \\eta_t^2 L^2. \\tag{2}\n",
    "$$\n",
    "\n",
    "Chúng ta quan tâm chủ yếu đến việc, trung bình, khoảng cách giữa $\\mathbf{x}_t$ và $\\mathbf{x}^*$ thay đổi như thế nào. Trên thực tế, khoảng cách này có thể tăng hoặc giảm, tùy thuộc vào mẫu $\\boldsymbol{\\xi}_t$ mà ta gặp phải. Do đó, ta cần chặn tích vô hướng.\n",
    "\n",
    "Với mọi hàm lồi $f$, ta có [(first-order condition)](https://machinelearningcoban.com/2017/03/12/convexity/#-first-order-condition):\n",
    "\n",
    "$$\n",
    "f(\\mathbf{y}) \\geq f(\\mathbf{x}) + \\langle f'(\\mathbf{x}), \\mathbf{y} - \\mathbf{x} \\rangle.\n",
    "$$\n",
    "\n",
    "Áp dụng với $\\mathbf{x}_t$ và $\\mathbf{x}^*$, ta được:\n",
    "<!-- $$\\begin{aligned}\n",
    " f(\\boldsymbol{\\xi}_t, \\mathbf{x}^*) &\\geq f(\\boldsymbol{\\xi}_t, \\mathbf{x}_t) + \\left\\langle \\mathbf{x}^* - \\mathbf{x}_t, \\partial_{\\mathbf{x}} f(\\boldsymbol{\\xi}_t, \\mathbf{x}_t) \\right\\rangle\\\\ \\left\\langle \\mathbf{x}^* - \\mathbf{x}_t, \\partial_{\\mathbf{x}} f(\\boldsymbol{\\xi}_t, \\mathbf{x}_t) \\right\\rangle &\\leq f(\\boldsymbol{\\xi}_t, \\mathbf{x}^*) - f(\\boldsymbol{\\xi}_t, \\mathbf{x}_t)\\\\ - \\left\\langle \\mathbf{x}_t - \\mathbf{x}^*, \\partial_{\\mathbf{x}} f(\\boldsymbol{\\xi}_t, \\mathbf{x}_t) \\right\\rangle &\\leq f(\\boldsymbol{\\xi}_t, \\mathbf{x}^*) - f(\\boldsymbol{\\xi}_t, \\mathbf{x}_t) \\label{eq:bat_dang_thuc_first_order_condition} \\tag{2}\n",
    "\\end{aligned}$$ -->\n",
    "$$ f(\\boldsymbol{\\xi}_t, \\mathbf{x}^*) \\geq f(\\boldsymbol{\\xi}_t, \\mathbf{x}_t) + \\left\\langle \\mathbf{x}^* - \\mathbf{x}_t, \\partial_{\\mathbf{x}} f(\\boldsymbol{\\xi}_t, \\mathbf{x}_t) \\right\\rangle $$\n",
    "$$ \\left\\langle \\mathbf{x}^* - \\mathbf{x}_t, \\partial_{\\mathbf{x}} f(\\boldsymbol{\\xi}_t, \\mathbf{x}_t) \\right\\rangle \\leq f(\\boldsymbol{\\xi}_t, \\mathbf{x}^*) - f(\\boldsymbol{\\xi}_t, \\mathbf{x}_t) $$\n",
    "$$ - \\left\\langle \\mathbf{x}_t - \\mathbf{x}^*, \\partial_{\\mathbf{x}} f(\\boldsymbol{\\xi}_t, \\mathbf{x}_t) \\right\\rangle \\leq f(\\boldsymbol{\\xi}_t, \\mathbf{x}^*) - f(\\boldsymbol{\\xi}_t, \\mathbf{x}_t) \\tag{3} $$\n",
    "Thay hai bất đẳng thức $(2)$ và $(3)$ vào biểu thức $(1)$, ta thu được:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\|\\mathbf{x}_{t+1} - \\mathbf{x}^*\\|^2 &\\leq \\|\\mathbf{x}_{t} - \\mathbf{x}^*\\|^2 + \\eta_t^2 L^2 - 2 \\eta_t (f(\\boldsymbol{\\xi}_t, \\mathbf{x}^*) - f(\\boldsymbol{\\xi}_t, \\mathbf{x}_t))\\\\\n",
    "\\|\\mathbf{x}_{t} - \\mathbf{x}^*\\|^2 - \\|\\mathbf{x}_{t+1} - \\mathbf{x}^*\\|^2 &\\geq 2 \\eta_t (f(\\boldsymbol{\\xi}_t, \\mathbf{x}_t) - f(\\boldsymbol{\\xi}_t, \\mathbf{x}^*)) - \\eta_t^2 L^2.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Điều này có nghĩa là ta đang tiến gần đến điểm tối ưu miễn là sự khác biệt giữa giá trị mất mát (loss) hiện tại và giá trị mất mát tối ưu lớn hơn $\\eta_t L^2 / 2$. Do sự khác biệt này sẽ tiến dần về 0 nên tốc độ học $\\eta_t$ cũng cần *giảm dần*.\n",
    "\n",
    "Tiếp theo, lấy kỳ vọng của bất đẳng thức trên:\n",
    "\n",
    "$$\n",
    "E\\left[\\|\\mathbf{x}_{t} - \\mathbf{x}^*\\|^2\\right] - E\\left[\\|\\mathbf{x}_{t+1} - \\mathbf{x}^*\\|^2\\right] \\geq 2 \\eta_t [E[R(\\mathbf{x}_t)] - R^*] -  \\eta_t^2 L^2.\n",
    "$$\n",
    "\n",
    "Tổng các bất đẳng thức này với $t = 1, \\ldots, T$, và bỏ đi phần âm, ta được:\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{x}_1 - \\mathbf{x}^*\\|^2 \\geq 2 \\left (\\sum_{t=1}^T   \\eta_t \\right) [E[R(\\mathbf{x}_t)] - R^*] - L^2 \\sum_{t=1}^T \\eta_t^2.\n",
    "$$\n",
    "\n",
    "Do $\\mathbf{x}_1$ là giá trị đã biết nên ta bỏ kỳ vọng. Định nghĩa:\n",
    "\n",
    "$$\n",
    "\\bar{\\mathbf{x}} := \\frac{\\sum_{t=1}^T \\eta_t \\mathbf{x}_t}{\\sum_{t=1}^T \\eta_t}.\n",
    "$$\n",
    "\n",
    "Ta có:\n",
    "\n",
    "$$\n",
    "E\\left(\\frac{\\sum_{t=1}^T \\eta_t R(\\mathbf{x}_t)}{\\sum_{t=1}^T \\eta_t}\\right) = \\frac{\\sum_{t=1}^T \\eta_t E[R(\\mathbf{x}_t)]}{\\sum_{t=1}^T \\eta_t} = E[R(\\mathbf{x}_t)].\n",
    "$$\n",
    "\n",
    "Do bất đẳng thức Jensen và tính lồi của $R$, ta có:\n",
    "\n",
    "$$\n",
    "E[R(\\mathbf{x}_t)] \\geq E[R(\\bar{\\mathbf{x}})],\n",
    "\\Rightarrow \\sum_{t=1}^T \\eta_t E[R(\\mathbf{x}_t)] \\geq \\sum_{t=1}^T \\eta_t  E\\left[R(\\bar{\\mathbf{x}})\\right].\n",
    "$$\n",
    "\n",
    "Thay vào bất đẳng thức trên, ta được:\n",
    "\n",
    "$$\n",
    "\\left[E[R(\\bar{\\mathbf{x}})]\\right] - R^* \\leq \\frac{r^2 + L^2 \\sum_{t=1}^T \\eta_t^2}{2 \\sum_{t=1}^T \\eta_t},\n",
    "$$\n",
    "\n",
    "với $r^2 := \\|\\mathbf{x}_1 - \\mathbf{x}^*\\|^2$ là độ chênh lệch giữa điểm khởi đầu và điểm tối ưu. Tóm lại, tốc độ hội tụ phụ thuộc vào việc gradient ngẫu nhiên được chặn như thế nào ($L$) và điểm bắt đầu cách xa tối ưu bao nhiêu ($r$).\n",
    "\n",
    "Khi $r, L$, và $T$ đã biết, ta có thể chọn tốc độ học $\\eta = r/(L \\sqrt{T})$. Khi đó, ta có chặn trên là $rL/\\sqrt{T}$, tức ta hội tụ với tốc độ $\\mathcal{O}(1/\\sqrt{T})$ đến nghiệm tối ưu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64582163-40de-4db8-8aad-65148ef8e17e",
   "metadata": {},
   "source": [
    "## Stochastic Gradients and Finite Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d321623a-710c-43c7-999e-01b02362994b",
   "metadata": {},
   "source": [
    "Cho đến giờ, chúng ta đã nói về **stochastic gradient descent (SGD)** một cách khá đơn giản và sơ lược. Chúng ta giả định rằng ta lấy các mẫu $x_i$, thường đi kèm với nhãn $y_i$, từ một phân phối nào đó $p(x, y)$ và sử dụng chúng để cập nhật các tham số của mô hình theo một cách nào đó. Cụ thể hơn, với một tập dữ liệu hữu hạn, ta đã lập luận rằng phân phối rời rạc $p(x, y) = \\frac{1}{n} \\sum_{i=1}^n \\delta_{x_i}(x) \\delta_{y_i}(y)$\n",
    "với một số hàm $\\delta_{x_i}$ và $\\delta_{y_i}$\n",
    "cho phép ta thực hiện SGD trên phân phối đó.\n",
    "\n",
    "Tuy nhiên, thực tế không hoàn toàn như vậy. Trong các ví dụ minh họa đơn giản ở phần này, ta đơn giản chỉ thêm nhiễu vào gradient không ngẫu nhiên, tức là ta giả vờ như đang có các cặp $(x_i, y_i)$. Điều này là hợp lý trong ngữ cảnh ở đây (xem bài tập để hiểu chi tiết hơn). Điều đáng lo ngại hơn là trong các phần trước, rõ ràng ta không làm như vậy. Thay vào đó, ta **duyệt qua tất cả các mẫu huấn luyện đúng một lần**. Để thấy tại sao cách làm này tốt hơn, hãy xét tình huống ngược lại: giả sử ta chọn ngẫu nhiên $n$ quan sát từ phân phối rời rạc **có hoàn lại**. Xác suất để chọn một phần tử $i$ bất kỳ là $1/n$. Do đó, xác suất để **chọn được ít nhất một lần** là:\n",
    "\n",
    "$P(\\textrm{chọn~} i) = 1 - P(\\textrm{không chọn~} i) = 1 - (1-1/n)^n \\approx 1-e^{-1} \\approx 0.63.$\n",
    "\n",
    "Lập luận tương tự cho thấy xác suất chọn một mẫu **chính xác một lần duy nhất** là:\n",
    "\n",
    "${n \\choose 1} \\frac{1}{n} \\left(1-\\frac{1}{n}\\right)^{n-1} = \\frac{n}{n-1} \\left(1-\\frac{1}{n}\\right)^{n} \\approx e^{-1} \\approx 0.37.$\n",
    "\n",
    "Việc lấy mẫu **có hoàn lại** làm tăng phương sai và giảm hiệu quả sử dụng dữ liệu so với lấy mẫu **không hoàn lại**. Do đó, trong thực tế, ta thường dùng cách lấy mẫu **không hoàn lại** (và đây cũng là cách được mặc định sử dụng xuyên suốt trong cuốn sách này). Cuối cùng, lưu ý rằng nếu duyệt lại tập huấn luyện nhiều lần thì mỗi lần như vậy sẽ duyệt qua tập dữ liệu theo **một thứ tự ngẫu nhiên khác nhau**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f04a1e-302e-4752-8383-44cbb2d74af9",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a4dae-2fac-4779-bf48-a861dd649eee",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2640f78-8dea-40aa-a8c9-344c16727f34",
   "metadata": {},
   "source": [
    "Experiment with different learning rate schedules for stochastic gradient descent and with different numbers of iterations. In particular, plot the distance from the optimal solution $(0, 0)$ as a function of the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd588328-307f-43da-b70b-edc7c6b98b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(x1, x2, s1, s2, f_grad):\n",
    "    dist_to_optimum.append(d2l.np.linalg.norm([x1, x2]).item())\n",
    "    g1, g2 = f_grad(x1, x2)\n",
    "    # Simulate noisy gradient\n",
    "    g1 += torch.normal(0.0, 1, (1,)).item()\n",
    "    g2 += torch.normal(0.0, 1, (1,)).item()\n",
    "    eta_t = eta * lr()\n",
    "    return (x1 - eta_t * g1, x2 - eta_t * g2, 0, 0)\n",
    "\n",
    "# CONSTANT LEARNING RATE\n",
    "dist_to_optimum = []\n",
    "eta = 0.1\n",
    "lr = constant_lr  # Constant learning rate\n",
    "d2l.train_2d(sgd, steps=50, f_grad=f_grad)\n",
    "\n",
    "# Plotting\n",
    "d2l.plt.figure(figsize=(8, 5))\n",
    "d2l.plt.plot(dist_to_optimum, marker='o', linestyle='-', color='blue', label='Distance to Optimum')\n",
    "d2l.plt.xlabel('Iteration')\n",
    "d2l.plt.ylabel('Distance')\n",
    "d2l.plt.title('Constant learning rate: Convergence to Optimum')\n",
    "d2l.plt.ylim(0, 6)\n",
    "d2l.plt.grid(True)\n",
    "d2l.plt.legend()\n",
    "d2l.plt.tight_layout()\n",
    "d2l.plt.show()\n",
    "\n",
    "# EXPONENTIAL LEARNING RATE\n",
    "dist_to_optimum = []\n",
    "t = 1\n",
    "lr = exponential_lr\n",
    "d2l.train_2d(sgd, steps=50, f_grad=f_grad)\n",
    "\n",
    "# Plotting\n",
    "d2l.plt.figure(figsize=(8, 5))\n",
    "d2l.plt.plot(dist_to_optimum, marker='o', linestyle='-', color='blue', label='Distance to Optimum')\n",
    "d2l.plt.xlabel('Iteration')\n",
    "d2l.plt.ylabel('Distance')\n",
    "d2l.plt.title('Exponential learning rate: Convergence to Optimum')\n",
    "d2l.plt.ylim(0, 6)\n",
    "d2l.plt.grid(True)\n",
    "d2l.plt.legend()\n",
    "d2l.plt.tight_layout()\n",
    "d2l.plt.show()\n",
    "\n",
    "# POLYNOMIAL LEARNING RATE\n",
    "dist_to_optimum = []\n",
    "t = 1\n",
    "lr = polynomial_lr\n",
    "d2l.train_2d(sgd, steps=50, f_grad=f_grad)\n",
    "\n",
    "# Plotting\n",
    "d2l.plt.figure(figsize=(8, 5))\n",
    "d2l.plt.plot(dist_to_optimum, marker='o', linestyle='-', color='blue', label='Distance to Optimum')\n",
    "d2l.plt.xlabel('Iteration')\n",
    "d2l.plt.ylabel('Distance')\n",
    "d2l.plt.title('Polynomial learning rate: Convergence to Optimum')\n",
    "d2l.plt.ylim(0, 6)\n",
    "d2l.plt.grid(True)\n",
    "d2l.plt.legend()\n",
    "d2l.plt.tight_layout()\n",
    "d2l.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7094e35d-8ebe-4bf6-8ef3-022eac747065",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313de73f-acf8-4922-aeeb-573c181baece",
   "metadata": {},
   "source": [
    "Prove that for the function $f(x_1, x_2) = x_1^2 + 2 x_2^2$ adding normal noise to the gradient is equivalent to minimizing a loss function $f(\\mathbf{x}, \\mathbf{w}) = (x_1 - w_1)^2 + 2 (x_2 - w_2)^2$ where $\\mathbf{x}$ is drawn from a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581b45d",
   "metadata": {},
   "source": [
    "Ta có gradient của hàm $f(x_1,x_2)$:\n",
    "$$ \\nabla f(x_1, x_2) = \\begin{bmatrix} 2x_1 \\\\ 4x_2 \\end{bmatrix} \\tag{1} $$\n",
    "\n",
    "gradient sau khi được thêm nhiễu:\n",
    "$$\\tilde{\\nabla} f(x) = \\nabla f(x) + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I)$$\n",
    "\n",
    "Thưc hiện lấy gradient của hàm $f(x,w)$:\n",
    "\n",
    "Ta có \n",
    "$$\n",
    "\\nabla_{\\mathbf{w}} L(\\mathbf{w}) = \\begin{bmatrix} \\frac{\\partial}{\\partial w_1} (x_1 - w_1)^2 \\\\ \\frac{\\partial}{\\partial w_2} 2(x_2 - w_2)^2 \\end{bmatrix}\n",
    "=  \\begin{bmatrix} -2(x_1 - w_1) \\\\ -4(x_2 - w_2) \\end{bmatrix} \n",
    "$$\n",
    "\n",
    "Thực hiên lấy kỳ vọng của công thức trên ta có:\n",
    "$$ \\nabla_{\\mathbf{w}} L(\\mathbf{w}) = \\mathbb{E} \\left[ \\begin{bmatrix} -2(x_1 - w_1) \\\\ -4(x_2 - w_2) \\end{bmatrix} \\right] $$ \n",
    "\n",
    "Tương đương \n",
    "$$ \\begin{bmatrix} -2(\\mathbb{E} \\left[x_1\\right] - w_1) \\\\ -4(\\mathbb{E} \\left[x_2\\right] - w_2) \\end{bmatrix} $$ \n",
    "\n",
    "Vì $x$ có phân phối chuẩn $\\mathbf{x} \\sim \\mathcal{N}(0, I)$ và x1 và x2 là hai giá trị ngẫu nhiên nên $\\mathbb{E} \\left[x_1\\right] =  \\left[x_2\\right] = 0$:\n",
    "$$ \\nabla_{\\mathbf{w}} L(\\mathbf{w}) = \\begin{bmatrix} 2(w_1) \\\\ 4( w_2) \\end{bmatrix} \\tag{2} $$ \n",
    "Từ $(1)$ và $(2)$ có thể thấy hàm $f(x_1, x_2)$ = $x_1^2 + x_2^2$ có thêm nhiễu vào gradient có thể tương đương với gradient của hàm $f(x,w) = (x_1-w_1)^2 +2(x_2-w_2)^2$ dùng để cập nhật tham số và tìm điểm cực tiểu của hàm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ec09cc-7b25-45b2-9fd9-5ffbc2b62e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for f(x1,x2) \n",
    "def f1(x1,x2):\n",
    "    return x1**2 + 2*x2**2\n",
    "\n",
    "# Define gradient of f(x1,x2)\n",
    "def f1_grad(x1,x2):\n",
    "    return 2*x1, 4*x2 \n",
    "\n",
    "# Define gradient of f(x,w)\n",
    "def f2(x,w):\n",
    "    return (x[0] - w[0])**2 + 2*(x[1] - w[1])**2\n",
    "\n",
    "# Define gradient of f(x,w)\n",
    "def f2_grad(x,w):\n",
    "    return -2*(x[0] - w[0]), -4*(x[1] - w[1])\n",
    "\n",
    "g_f1= []\n",
    "# Gradient computing and weight updating for f(x1,x2)\n",
    "def sgd_f1(x1, x2, s1, s2, f1_grad):\n",
    "    g1, g2 = f1_grad(x1, x2)\n",
    "    # Simulate noisy gradient\n",
    "    g1 += torch.normal(0.0, 1, (1,)).item() #Add normal noise\n",
    "    g2 += torch.normal(0.0, 1, (1,)).item() #Add normal noise\n",
    "    g_f1.append(torch.tensor([g1,g2]))\n",
    "    eta_t = eta * lr()\n",
    "    return (x1 - eta_t * g1, x2 - eta_t * g2, 0, 0)\n",
    "\n",
    "noise_std = 1.0\n",
    "g_f2= []\n",
    "x_sample = []\n",
    "# Gradient computing and weight updating for f(x,w)\n",
    "def sgd_f2(x1, x2, s1, s2, f2_grad):\n",
    "    x= torch.randn(2)\n",
    "    x_sample.append(x)\n",
    "    w = torch.tensor([x1,x2])\n",
    "    g1, g2 = f2_grad(x, w)\n",
    "    g_f2.append(torch.tensor([g1,g2]))\n",
    "    eta_t = eta * lr()\n",
    "    return (x1 - eta_t * g1, x2 - eta_t * g2, 0, 0)\n",
    "\n",
    "\n",
    "eta = 0.1\n",
    "lr = polynomial_lr  # Constant learning rate\n",
    "result_f1 = d2l.train_2d(sgd_f1, steps=1000, f_grad=f1_grad)\n",
    "result_f2 = d2l.train_2d(sgd_f2, steps=1000, f_grad=f2_grad)\n",
    "print(\"Average gradient for f(x1,x2) when adding noise gradient:\", torch.stack(g_f1).mean(dim=0))\n",
    "print(\"Average gradient for f(x,w)\",torch.stack(g_f2).mean(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1d6095-b7eb-493b-bc3f-da9466804e06",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5fbfab-42b4-40d7-9f32-02c4b51cf49c",
   "metadata": {},
   "source": [
    "Compare convergence of stochastic gradient descent when you sample from $\\{(x_1, y_1), \\ldots, (x_n, y_n)\\}$ with replacement and when you sample without replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349cfd0f",
   "metadata": {},
   "source": [
    "Ta có bất đẳng thức đánh giá về tốc độ hội tụ từ phần 12.4.3: \n",
    "$$\n",
    "\\left[E[R(\\bar{\\mathbf{x}})]\\right] - R^* \\leq \\frac{r^2 + L^2 \\sum_{t=1}^T \\eta_t^2}{2 \\sum_{t=1}^T \\eta_t},\n",
    "$$\n",
    "\n",
    "Với việc lấy mẫu có Hoàn Lại:\n",
    "Với tốc độ học cố định $\\eta = \\frac{r}{L\\sqrt{T}}$:\n",
    "$$\\sum_{t=1}^{T} \\eta_t = T \\cdot \\frac{r}{L\\sqrt{T}} = \\frac{rT}{L\\sqrt{T}} = \\frac{r\\sqrt{T}}{L}$$\n",
    "\n",
    "$$\\sum_{t=1}^{T} \\eta_t^2 = T \\cdot \\left(\\frac{r}{L\\sqrt{T}}\\right)^2 = T \\cdot \\frac{r^2}{L^2T} = \\frac{r^2}{L^2}$$\n",
    "Thay vào biểu thức giới hạn ban đầu:\n",
    "$$[E[R(\\bar{x})]] - R^* \\leq \\frac{r^2 + L^2 \\cdot \\frac{r^2}{L^2}}{2 \\cdot \\frac{r\\sqrt{T}}{L}} = \\frac{r^2 + r^2}{2 \\cdot \\frac{r\\sqrt{T}}{L}} = \\frac{2r^2}{\\frac{2r\\sqrt{T}}{L}} = \\frac{rL}{\\sqrt{T}}$$\n",
    "Điều này cho chúng ta tốc độ hội tụ rõ ràng $O\\left(\\frac{rL}{\\sqrt{T}}\\right)$ đối với phương pháp lấy mẫu có hoàn lại.\n",
    "\n",
    "Với việc lấy mẫu không hoàn lại với $\\eta = r/(L \\sqrt{T})$: \n",
    "\n",
    "Chúng ta tính toán hệ số giảm phương sai:\n",
    "+ Với $\\frac{n-1}{n}$ được xem là phần nhiễu ảnh hưởng đến tốc độ hội tụ giữa các bước vì khi lấy mẫu không thay thế, các mẫu khác nhau phụ thuộc vào nhau (sau khi chọn một điểm, khả năng chọn lại giảm còn $n-1$ trong tổng $n$ => các mẫu không còn độc lập với nhau )\n",
    "\n",
    "$$[E[R(\\bar{x})]] - R^* \\leq \\frac{r^2 + L^2 \\cdot \\frac{n-1}{n} \\cdot \\frac{r^2}{L^2}}{2 \\cdot \\frac{r\\sqrt{T}}{L}}$$ \n",
    "\n",
    "$$= \\frac{r^2 + r^2 \\cdot \\frac{n-1}{n}}{2 \\cdot \\frac{r\\sqrt{T}}{L}}$$\n",
    "\n",
    "$$= \\frac{r^2 \\cdot \\left(1 + \\frac{n-1}{n}\\right)}{2 \\cdot \\frac{r\\sqrt{T}}{L}}$$\n",
    "\n",
    "$$= \\frac{r^2 \\cdot \\frac{2n-1}{n}}{2 \\cdot \\frac{r\\sqrt{T}}{L}}$$\n",
    "\n",
    "$$= \\frac{rL}{\\sqrt{T}} \\cdot \\frac{2n-1}{2n}$$\n",
    "\n",
    "Với $n$ lớn, $\\frac{2n-1}{2n} \\approx \\frac{2n}{2n} - \\frac{1}{2n} = 1 - \\frac{1}{2n}$, vì vậy chúng ta có:\n",
    "\n",
    "$$[E[R(\\bar{x})]] - R^* \\leq \\frac{rL}{\\sqrt{T}} \\cdot \\left(1 - \\frac{1}{2n}\\right)$$\n",
    "\n",
    "Vậy ta có:\n",
    "\n",
    "+ **Lấy mẫu có hoàn lại**: $[E[R(\\bar{x})]] - R^* \\leq \\frac{rL}{\\sqrt{T}}$\n",
    "\n",
    "+ **Lấy mẫu không hoàn lại**: $[E[R(\\bar{x})]] - R^* \\leq \\frac{rL}{\\sqrt{T}} \\cdot \\left(1 - \\frac{1}{2n}\\right)$\n",
    "\n",
    "=> **Tốc độ hội tụ của phương pháp lấy mẫu không hoàn lại cải thiện theo hệ số không đổi xấp xỉ $\\left(1 - \\frac{1}{2n}\\right)$ so với phương pháp lấy mẫu có hoàn lại**\n",
    "\n",
    "Hệ số cải thiện $(1 - \\frac{1}{2n})$ phụ thuộc vào kích thước tập dữ liệu $n$:\n",
    "- Với $n$ nhỏ, mức cải thiện đáng kể hơn\n",
    "- Khi $n$ tăng lên, mức cải thiện tiệm cận đến một hệ số không đổi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a51711f-ebf6-443d-9e46-f21da08a9e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def show_trace_2d_custom(x_subsample, results, color, label):\n",
    "    \"\"\"Show the trace of 2D variables during optimization.\n",
    "\n",
    "    Defined in :numref:`subsec_gd-learningrate`\"\"\"\n",
    "    d2l.set_figsize()\n",
    "    d2l.plt.plot(*zip(*results), '-o', color=color, label=label)\n",
    "    x1, x2 = d2l.meshgrid(d2l.arange(-5.5, 1.0, 0.1),\n",
    "                          d2l.arange(-3.0, 1.0, 0.1), indexing='ij')\n",
    "    w = [x1,x2]\n",
    "    d2l.plt.contour(x1, x2, f_ex3(x_subsample, w), colors='#1f77b4')\n",
    "    d2l.plt.xlabel('x1')\n",
    "    d2l.plt.ylabel('x2')\n",
    "    d2l.plt.legend()\n",
    "\n",
    "x_sample = torch.randn(200,2)\n",
    "x_choices = [x_sample[0]]\n",
    "x_subsample=[x_sample[0]]\n",
    "eta = 0.01\n",
    "t = 1\n",
    "\n",
    "# Define gradient of f(x,w)\n",
    "def f_ex3(x,w):\n",
    "    return (x[0] - w[0])**2 + 2*(x[1] - w[1])**2\n",
    "\n",
    "# Define gradient of f(x,w)\n",
    "def f_ex3_grad(x,w):\n",
    "    return -2*(x[0] - w[0]), -4*(x[1] - w[1])\n",
    "\n",
    "\n",
    "def sgd_replacement(x1, x2, s1, s2, f2_grad):\n",
    "    dist_to_optimum.append(d2l.np.linalg.norm([x1, x2]).item())\n",
    "    x= random.choice(x_sample)\n",
    "    x_choices.append(x)\n",
    "    w = torch.tensor([x1,x2])\n",
    "    g1, g2 = f2_grad(x, w)\n",
    "    eta_t = eta * lr()\n",
    "    return (x1 - eta_t * g1, x2 - eta_t * g2, 0, 0)\n",
    "\n",
    "i=0\n",
    "def sgd_without_replacement(x1, x2, s1, s2, f2_grad):\n",
    "    global i \n",
    "    i += 1\n",
    "    x = x_sample[i]\n",
    "    x_subsample.append(x)\n",
    "    dist_to_optimum.append(d2l.np.linalg.norm([x1, x2]).item())\n",
    "    w = torch.tensor([x1,x2])\n",
    "    g1, g2 = f2_grad(x, w)\n",
    "    eta_t = eta * lr()\n",
    "    return (x1 - eta_t * g1, x2 - eta_t * g2, 0, 0)\n",
    "\n",
    "\n",
    "# show_trace_2d_custom(x_subsample[-1], d2l.train_2d(sgd_without_replacement, steps=999, f_grad=f_ex3_grad),\"#0000ff\", \"Without replacement\")\n",
    "# show_trace_2d_custom(x_choices[-1], d2l.train_2d(sgd_replacement, steps=999, f_grad=f_ex3_grad),\"#ff7f0e\",\"With replacement\")\n",
    "dist_to_optimum=[]\n",
    "d2l.train_2d(sgd_without_replacement, steps=199, f_grad=f_ex3_grad)\n",
    "d2l.plt.figure(figsize=(8, 5))\n",
    "d2l.plt.plot(dist_to_optimum, marker='o', linestyle='-', color='blue', label='Distance to Optimum')\n",
    "d2l.plt.xlabel('Iteration')\n",
    "d2l.plt.ylabel('Distance')\n",
    "d2l.plt.title('Without replacement: Convergence to Optimum')\n",
    "d2l.plt.ylim(0, 6)\n",
    "d2l.plt.grid(True)\n",
    "d2l.plt.legend()\n",
    "d2l.plt.tight_layout()\n",
    "d2l.plt.show()\n",
    "\n",
    "dist_to_optimum=[]\n",
    "d2l.train_2d(sgd_replacement, steps=199, f_grad=f_ex3_grad)\n",
    "d2l.plt.figure(figsize=(8, 5))\n",
    "d2l.plt.plot(dist_to_optimum, marker='o', linestyle='-', color='blue', label='Distance to Optimum')\n",
    "d2l.plt.xlabel('Iteration')\n",
    "d2l.plt.ylabel('Distance')\n",
    "d2l.plt.title('With replacement: Convergence to Optimum')\n",
    "d2l.plt.ylim(0, 6)\n",
    "d2l.plt.grid(True)\n",
    "d2l.plt.legend()\n",
    "d2l.plt.tight_layout()\n",
    "d2l.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53da6724-9c69-4023-b80d-b0f0df780b04",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50574902-dfa1-4584-a969-0ed1b94f6c4f",
   "metadata": {},
   "source": [
    "How would you change the stochastic gradient descent solver if some gradient (or rather some coordinate associated with it) was consistently larger than all the other gradients?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb92d31-eb43-4f4a-9e25-2900799e72ab",
   "metadata": {},
   "source": [
    "Trong quá trình tối ưu bằng Stochastic Gradient Descent (SGD), nếu một thành phần (tọa độ) của gradient luôn có giá trị lớn hơn đáng kể so với các thành phần còn lại, điều này có thể khiến việc cập nhật tham số bị lệch, dẫn đến quá trình hội tụ trở nên **kém hiệu quả** hoặc thậm chí **không ổn định**.\n",
    "\n",
    "Để khắc phục vấn đề này, ta có thể áp dụng một trong hai giải pháp sau:\n",
    "\n",
    "1. **Điều chỉnh tốc độ học theo từng tọa độ**:\n",
    "   Giảm tốc độ học (learning rate) cho các tọa độ có gradient lớn hơn nhằm hạn chế việc cập nhật quá mạnh ở các chiều đó, giúp quá trình tối ưu trở nên cân bằng và ổn định hơn.\n",
    "1. **Gradient clipping** (cắt gradient):\n",
    "   Giới hạn độ lớn tối đa của gradient, bằng cách cắt ngắn (rescale) vector gradient nếu nó vượt quá một ngưỡng cho trước. Điều này giúp tránh việc các gradient cực lớn gây ra những bước nhảy quá lớn trong quá trình cập nhật tham số."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83f472e-1196-48cc-9c97-40f816648189",
   "metadata": {},
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c54a65c-0bd3-4557-922b-24d5dc869c37",
   "metadata": {},
   "source": [
    "Assume that $f(x) = x^2 (1 + \\sin x)$. How many local minima does $f$ have? Can you change $f$ in such a way that to minimize it one needs to evaluate all the local minima?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac0c079-49d0-4dbd-b109-2abbb1291797",
   "metadata": {},
   "source": [
    "Miền xác định của $f(x)$ là $\\mathbb{R}$.\n",
    "\n",
    "Ta có:\n",
    "$$\n",
    "f'(x) = 2x(1 + \\sin x) + x^2 \\cos x\n",
    "$$\n",
    "$f'(x) = 0$:\n",
    "$$\n",
    "2x(1 + \\sin x) + x^2 \\cos x = 0\n",
    "$$\n",
    "Ta biến đổi thành:\n",
    "$$\n",
    "x [2(1 + \\sin x) + x \\cos x] = 0\n",
    "$$\n",
    "\n",
    "Vậy các điểm tới hạn xảy ra khi:\n",
    "- $x = 0$, hoặc\n",
    "- $2(1 + \\sin x) + x \\cos x = 0$\n",
    "  \n",
    "Ở phương trình thứ hai, ta thấy rằng:\n",
    "- $\\sin x$, $\\cos x$ dao động giữa $[-1,1]$\n",
    "- Khi $|x| \\to \\infty$, biên độ của $x \\cos x$ tăng lên\n",
    "\n",
    "Điều này cho thấy phương trình $ 2(1 + \\sin x) + x \\cos x = 0 $ có **vô số nghiệm**, do bản chất dao động của $ \\sin x $, $ \\cos x $.\n",
    "\n",
    "Nhiều nghiệm trong số đó là cực tiểu địa phương (trên đồ thị, có ít nhất một cực tiểu trong mỗi khoảng $ [2\\pi n, 2\\pi(n+1)] $).\n",
    "\n",
    "Vậy hàm $ f(x) $ có **vô số cực tiểu địa phương**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309cd8a2-96e3-41aa-8e2e-19db846d3cfc",
   "metadata": {},
   "source": [
    "# 04. Minibatch Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462c5e57-966a-43b7-bd5a-9758081390fe",
   "metadata": {},
   "source": [
    "Trong học sâu, việc tối ưu hóa các tham số của mô hình là một bước quan trọng để đạt được hiệu suất tốt nhất. Có nhiều phương pháp tối ưu hóa khác nhau, trong đó Gradient Descent (GD) và Stochastic Gradient Descent (SGD) là hai phương pháp phổ biến. Tuy nhiên, cả hai đều có những hạn chế riêng. Minibatch Stochastic Gradient Descent (Minibatch SGD) được xem là một giải pháp cân bằng giữa hai phương pháp này, mang lại hiệu quả cả về mặt tính toán và thống kê."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c5374c-173b-45b0-8528-a4211cefcff8",
   "metadata": {},
   "source": [
    "## Vectorization and Caches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c71c36e",
   "metadata": {},
   "source": [
    "Trọng tâm của quyết định sử dụng minibatches là hiệu quả tính toán. Điều này dễ hiểu nhất khi xem xét song song với nhiều GPU và nhiều máy chủ. Trong trường hợp này, chúng ta cần gửi ít nhất một hình ảnh cho mỗi GPU. Với 8 GPU trên mỗi máy chủ và 16 máy chủ, ta có minibatch kích thước 128. \n",
    "\n",
    "Vấn đề trở nên nhạy cảm hơn đối với GPU đơn hay ngay cả CPU đơn. Các thiết bị này có nhiều loại bộ nhớ, thường là nhiều loại đơn vị tính toán và hạn chế băng thông khác nhau giữa chúng. Ví dụ, CPU có một số lượng nhỏ các thanh ghi và sau đó là L1, L2 và trong một số trường hợp thậm chí bộ nhớ cache L3 (được chia sẻ giữa các lõi bộ xử lý khác nhau). Các bộ nhớ đệm này có kích thước và độ trễ ngày càng tăng (đồng thời chúng giảm băng thông). Nó đủ để nói, bộ xử lý có khả năng thực hiện nhiều hoạt động hơn so với những gì giao diện bộ nhớ chính có thể cung cấp. \n",
    "\n",
    "* CPU 2GHz với 16 lõi và vectorization AVX-512 có thể xử lý lên đến $2 \\cdot 10^9 \\cdot 16 \\cdot 32 = 10^{12}$ byte mỗi giây. Khả năng của GPU dễ dàng vượt quá con số này theo hệ số 100. Mặt khác, một bộ xử lý máy chủ tầm trung có thể không có nhiều hơn 100 Gb/s băng thông, tức là, ít hơn một phần mười những gì sẽ được yêu cầu để giữ cho bộ xử lý ăn. Vấn đề còn tồi tệ hơn khi ta xét đến việc không phải khả năng truy cập bộ nhớ nào cũng như nhau: đầu tiên, giao diện bộ nhớ thường rộng 64 bit hoặc rộng hơn (ví dụ, trên GPU lên đến 384 bit), do đó việc đọc một byte duy nhất vẫn sẽ phải chịu chi phí giống như truy cập một khoảng bộ nhớ rộng hơn.\n",
    "* Tổng chi phí cho lần truy cập đầu tiên là khá lớn, trong khi truy cập liên tiếp thường hao tổn ít. Có rất nhiều điều cần lưu ý, ví dụ như lưu trữ đệm khi ta có nhiều điểm truy cập cuối, chiplet và các cấu trúc khác...\n",
    "\n",
    "Cách để giảm bớt những hạn chế này là sử dụng một hệ thống phân cấp của bộ nhớ cache CPU thực sự đủ nhanh để cung cấp cho bộ xử lý dữ liệu. Đây là *động lực* đằng sau việc sử dụng batch trong học sâu. ĐĐể đơn giản, xét phép nhân hai ma trận $\\mathbf{A} = \\mathbf{B}\\mathbf{C}$. Để tính $\\mathbf{A}$ ta có khá nhiều lựa chọn, ví dụ như: \n",
    "\n",
    "1. Ta có thể tính $\\mathbf{A}_{ij} = \\mathbf{B}_{i,:} \\mathbf{C}_{:,j}^\\top$, tức là tính từng phần tử bằng tích vô hướng.\n",
    "1. Ta có thể tính $\\mathbf{A}_{:,j} = \\mathbf{B} \\mathbf{C}_{:,j}^\\top$, ttức là tính theo từng cột. Tương tự, ta có thể tính $\\mathbf{A}$ theo từng hàng $\\mathbf{A}_{i,:}$.\n",
    "1. Ta đơn giản có thể tính $\\mathbf{A} = \\mathbf{B} \\mathbf{C}$.\n",
    "1. Ta có thể chia $\\mathbf{B}$ và $\\mathbf{C}$ thành các ma trận khối nhỏ hơn và tính toán $\\mathbf{A}$ theo từng khối một.\n",
    "\n",
    "Nếu sử dụng cách đầu tiên, ta cần sao chép một vector cột và một vector hàng vào CPU cho mỗi lần tính phần tử $\\mathbf{A}_{ij}$. Tệ hơn nữa, do các phần tử của ma trận được lưu thành một dãy liên tục dưới bộ nhớ, ta buộc phải truy cập nhiều vùng nhớ rời rạc khi đọc một trong hai vector từ bộ nhớ. Cách thứ hai tốt hơn nhiều. Theo cách này, ta có thể giữ vector cột $\\mathbf{C}_{:,j}$ trong vùng nhớ đệm của CPU trong khi ta tiếp tục quét qua $\\mathbf{B}$. Cách này chỉ cần nửa băng thông cần thiết của bộ nhớ, do đó truy cập nhanh hơn. Đương nhiên cách thứ ba là tốt nhất. Đáng tiếc rằng đa số ma trận quá lớn để có thể đưa vào vùng nhớ đệm (dù sao đây cũng chính là điều ta đang thảo luận). Cách thứ tư là một phương pháp thay thế khá tốt: đưa các khối của ma trận vào vùng nhớ đệm và thực hiện phép nhân cục bộ. Các thư viện đã được tối ưu sẽ thực hiện việc này giúp chúng ta. Hãy xem xét hiệu suất của từng phương pháp trong thực tế. \n",
    "\n",
    "Ngoài hiệu suất tính toán, chi phí tính toán phát sinh đến từ Python và framework học sâu cũng đáng cân nhắc. Mỗi lần ta thực hiện một câu lệnh, bộ thông dịch Python gửi một câu lệnh đến MXNet để chèn câu lệnh đó vào đồ thị tính toán và thực thi nó theo đúng lịnh trình. Chi phí đó có thể khá bất lợi. Nói ngắn gọn, nên áp dụng vector hóa (và ma trận) bất cứ khi nào có thể."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f54e8-d696-42e4-bab6-a8b5aa1a32b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import d2l\n",
    "\n",
    "A = torch.zeros(512, 512)\n",
    "B = torch.randn(512, 512)\n",
    "C = torch.randn(512, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de3788f",
   "metadata": {},
   "source": [
    "Vì chúng ta sẽ thường xuyên đo thời gian chạy trong phần còn lại của báo cáo, hãy định nghĩa một bộ đếm thời gian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8e95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    \"\"\"Record multiple running times.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer and record the time in a list.\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"Return the average time.\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"Return the sum of time.\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"Return the accumulated time.\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()\n",
    "\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ecd54f",
   "metadata": {},
   "source": [
    "Gán từng phần tử đơn giản là lặp qua tất cả các hàng và cột của $\\mathbf{B}$ và $\\mathbf{C}$ tương ứng để gán giá trị cho $\\mathbf{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c00df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute A = BC one element at a time\n",
    "timer.start()\n",
    "for i in range(512):\n",
    "    for j in range(512):\n",
    "        A[i, j] = torch.dot(B[i, :], C[:, j])\n",
    "timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85adbf56",
   "metadata": {},
   "source": [
    "Một chiến lược nhanh hơn là thực hiện gán theo cột."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f6efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute A = BC one column at a time\n",
    "timer.start()\n",
    "for j in range(512):\n",
    "    A[:, j] = torch.mv(B, C[:, j])\n",
    "timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c9312",
   "metadata": {},
   "source": [
    "Cuối cùng, phương pháp hiệu quả nhất là thực hiện toàn bộ phép toán trong một khối duy nhất.\n",
    "Lưu ý rằng việc nhân hai ma trận $\\mathbf{B} \\in \\mathbb{R}^{m \\times n}$ và $\\mathbf{C} \\in \\mathbb{R}^{n \\times p}$ cần khoảng $2mnp$ phép toán dấu phẩy động,\n",
    "khi phép nhân và cộng vô hướng được tính là hai phép toán riêng biệt (mặc dù trên thực tế thường được gộp lại).\n",
    "Do đó, việc nhân hai ma trận kích thước $512 \\times 512$ cần khoảng $0.27$ tỷ phép toán dấu phẩy động.\n",
    "Bây giờ, hãy cùng xem tốc độ tương ứng của các phép toán này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f66219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute A = BC in one go\n",
    "timer.start()\n",
    "A = torch.mm(B, C)\n",
    "timer.stop()\n",
    "\n",
    "gigaflops = [0.27 / i for i in timer.times]\n",
    "print(f'performance in Gigaflops: element {gigaflops[0]:.3f}, '\n",
    "      f'column {gigaflops[1]:.3f}, full {gigaflops[2]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3843f26-b110-4f3b-a324-32eb903d710a",
   "metadata": {},
   "source": [
    "## Minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a8f643",
   "metadata": {},
   "source": [
    "Ở các phần trước ta đọc dữ liệu theo *minibatches* thay vì từng điểm dữ liệu đơn lẻ để cập nhật các tham số. Ta có thể giải thích ngắn gọn mục đích như sau. Xử lý từng điểm dữ liệu đơn lẻ đòi hỏi phải thực hiện rất nhiều phép nhân ma trận với vector (hay thậm chí vector với vector). Cách này khá tốn kém và đồng thời phải chịu thêm chi phí khá lớn đến từ các framework học sâu bên dưới. Vấn đề này xảy ra ở cả lúc đánh giá một mạng với dữ liệu mới và khi tính toán gradient để cập nhật các tham số. Tức là vấn đề xảy ra mỗi khi ta thực hiện $\\mathbf{w} \\leftarrow \\mathbf{w} - \\eta_t \\mathbf{g}_t$  trong đó \n",
    "\n",
    "$$\\mathbf{g}_t = \\partial_{\\mathbf{w}} f(\\mathbf{x}_{t}, \\mathbf{w})$$\n",
    "\n",
    "Ta có thể tăng hiệu suất *tính toán* của phép tính này bằng cách áp dụng nó trên mỗi minibatch dữ liệu. Tức là ta thay thế gradient $\\mathbf{g}_t$ trên một điểm dữ liệu đơn lẻ bằng gradient trên một batch nhỏ. \n",
    "\n",
    "$$\\mathbf{g}_t = \\partial_{\\mathbf{w}} \\frac{1}{|\\mathcal{B}_t|} \\sum_{i \\in \\mathcal{B}_t} f(\\mathbf{x}_{i}, \\mathbf{w})$$\n",
    "\n",
    "Hãy thử xem phương pháp trên tác động thế nào đến các tính chất thống kê của $\\mathbf{g}_t$: vì cả $\\mathbf{x}_t$ và tất cả các phần tử trong minibatch $\\mathcal{B}_t$ được lấy ra từ tập huấn luyện với xác suất như nhau, kỳ vọng của gradient là không đổi. Mặt khác, phương sai giảm một cách đáng kể. Do gradient của minibatch là trung bình của $b := |\\mathcal{B}_t|$ gradient độc lập, độ lệch chuẩn của nó giảm đi theo hệ số $b^{-\\frac{1}{2}}$. Đây là một điều tốt, cách cập nhật này có độ tin cậy gần bằng việc lấy gradient trên toàn bộ tập dữ liệu.\n",
    "\n",
    "Từ ý trên, ta sẽ nhanh chóng cho rằng chọn minibatch $\\mathcal{B}_t$ lớn luôn là tốt nhất. Tiếc rằng đến một mức độ nào đó, độ lệch chuẩn sẽ giảm không đáng kể so với chi phí tính toán tăng tuyến tính. Do đó trong thực tế, ta sẽ chọn kích thước minibatch đủ lớn để hiệu suất tính toán cao trong khi vẫn đủ để đưa vào bộ nhớ của GPU. Để minh hoạ quá trình lưu trữ này, hãy xem đoạn mã nguồn dưới đây. Trong đó ta vẫn thực hiện phép nhân ma trận với ma trận, tuy nhiên lần này ta tách thành từng minibatch 64 cột."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51db8c-7f3b-4ca1-8a10-419d99dfe483",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.start()\n",
    "for j in range(0, 512, 64):\n",
    "    A[:, j:j+64] = torch.mm(B, C[:, j:j+64])\n",
    "timer.stop()\n",
    "print(f'performance in Gigaflops: block {0.27 / timer.times[3]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ad56f",
   "metadata": {},
   "source": [
    "Có thể thấy quá trình tính toán trên minibatch về cơ bản có hiệu suất gần bằng thực hiện trên toàn ma trận. Tuy nhiên, cần lưu ý rằng Trong ví dụ trước đó ta sử dụng một loại điều chuẩn phụ thuộc chặt chẽ vào phương sai của minibatch. khi tăng kích thước minibatch, phương sai giảm xuống và cùng với đó là lợi ích của việc thêm nhiễu (noise-injection) cũng giảm theo do phương pháp chuẩn hóa theo batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76883d6-a469-4153-91d7-931be6f011fd",
   "metadata": {},
   "source": [
    "## Reading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba4801",
   "metadata": {},
   "source": [
    "Chúng ta hãy xem cách minibatches được tạo ra hiệu quả từ dữ liệu. Sau đây chúng tôi sử dụng một tập dữ liệu do NASA phát triển để kiểm tra mức độ tiếng ồn do cánh máy bay tạo ra trong điều kiện khí động học cụ thể [noise from different aircraft](https://archive.ics.uci.edu/ml/datasets/Airfoil+Self-Noise) để so sánh các thuật toán tối ưu hóa này. Để thuận tiện, chúng tôi chỉ sử dụng các ví dụ $1,500$ đầu tiên. Dữ liệu được làm trắng để xử lý trước, tức là, chúng tôi loại bỏ trung bình và giải thích phương sai thành $1$ cho mỗi tọa độ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393d525e-e0e8-4d44-96de-5be729da4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['airfoil'] = (d2l.DATA_URL + 'airfoil_self_noise.dat',\n",
    "                           '76e5be1548fd8222e5074cf0faae75edff8cf93f')\n",
    "\n",
    "#@save\n",
    "def get_data_ch11(batch_size=10, n=1500):\n",
    "    data = np.genfromtxt(d2l.download('airfoil'),\n",
    "                         dtype=np.float32, delimiter='\\t')\n",
    "    data = torch.from_numpy((data - data.mean(axis=0)) / data.std(axis=0))\n",
    "    data_iter = d2l.load_array((data[:n, :-1], data[:n, -1]),\n",
    "                               batch_size, is_train=True)\n",
    "    return data_iter, data.shape[1] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ac24e8-5c1d-4ecb-bd87-a888caabd119",
   "metadata": {},
   "source": [
    "## Implementation from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7debfd6d",
   "metadata": {},
   "source": [
    "Ta sẽ sử dụng mô hình Hồi quy Tuyến tính với lần lượt các thuật toán tối ưu GD, SGD và SGD theo minibatch để so sánh độ hiệu quả."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1039bbab",
   "metadata": {},
   "source": [
    "### Nhắc lại về Hồi quy Tuyến tính"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ac641",
   "metadata": {},
   "source": [
    "#### Định nghĩa\n",
    "Hồi quy Tuyến tính (Linear Regression) là một phương pháp học máy cơ bản thuộc nhóm học có giám sát (Supervised learning). Phương pháp này bao gồm 2 yếu tố là Hồi quy và Tuyến tính. Phép Hồi quy phân tích mối quan hệ giữa một hoặc nhiều biến đầu vào (biến độc lập) và một biến đầu ra (biến phụ thuộc). Trong khi đó, phép Tuyến tính chỉ mối quan hệ tổ hợp tuyến tính của các biến đầu vào mà không có sự xuất hiện của các hàm lũy thừa hay phi tuyến như sin, log, relu, ... Như vậy, Hồi quy Tuyến tính là phương pháp học máy và thống kê giúp mô hình hóa mối quan hệ **tuyến tính** giữa một hoặc nhiều biến đầu vào (biến độc lập) và một biến đầu ra (biến phụ thuộc), từ đó giúp dự đoán giá trị của biến phụ thuộc dựa trên giá trị của các biến độc lập."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dd40a3",
   "metadata": {},
   "source": [
    "#### Mô hình Tuyến tính\n",
    "Mô hình Hồi quy Tuyến tính cho `d` đặc trưng (biến đầu vào) có dạng:\n",
    "$$\n",
    "y = \\omega_1*x_1 + \\omega_2*x_2 + ... + \\omega_d*x_d + b\n",
    "$$\n",
    "Thu thập toàn bộ các đặc trưng vào một vector $\\mathbf{x}$ và toàn bộ các trọng số vào một vector $\\mathbf{w}$, ta có thể biểu diễn mô hình dưới dạng tích vô hướng của 2 vector:\n",
    "$$\n",
    "y = \\mathbf{w}^T*\\mathbf{x}\n",
    "$$\n",
    "Trong đó:\n",
    "- $\\mathbf{x}$: vector đặc trưng đầu vào, $\\mathbf{x} \\in R^d$ (input features)\n",
    "- $\\mathbf{w}$: vector trọng số (weights) cần huấn luyện\n",
    "- $b$: độ lệch (bias)\n",
    "- $y$: giá trị đầu ra (output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58ed6f3",
   "metadata": {},
   "source": [
    "#### Hàm mất mát\n",
    "Để đánh giá mức độ khớp giữa mô hình được xây dựng và dữ liệu, ta sử dụng hàm mất mát. Hàm mất mát định lượng khoảng cách giữa giá trị thực $y$ và giá trị dự đoán $\\hat{y}$ của mục tiêu. Độ mất mát thường là một số không âm và có giá trị càng nhỏ càng tốt. Khi các dự đoán hoàn hảo, chúng sẽ có độ mất mát sẽ bằng **0**. Hàm mất mát thông dụng nhất trong các bài toán hồi quy là hàm tổng bình phương các lỗi - Mean Squared Error (MSE):\n",
    "$$\n",
    "L_i = \\frac{1}{2} MSE(y_i, \\hat{y}_i) = \\frac{1}{2} E[(y_i - \\hat{y}_i)^2] = \\frac{1}{2} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "Hằng số **1/2** không tạo ra sự khác biệt thực sự nào nhưng sẽ giúp thuận tiện hơn về mặt ký hiệu: nó sẽ được triệt tiêu khi lấy đạo hàm của hàm mất mát.\n",
    "\n",
    "Lưu ý rằng khi hiệu giữa giá trị thực $y_i$ và giá trị ước lượng $\\hat{y}_i$ lớn, giá trị hàm mất mát sẽ tăng rất lớn cho sự phụ thuộc bậc 2. Để đo chất lượng của mô hình trên toàn bộ tập dữ liệu, ta đơn thuần lấy trung bình (hay tương đương là lấy tổng) các giá trị mất mát của từng mẫu trong tập huấn luyện.\n",
    "$$\n",
    "L = \\frac{1}{n} \\sum_{i=1}^{n} L_i = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{2} (y_i - \\hat{y}_i)^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7494f2ea",
   "metadata": {},
   "source": [
    "#### Mục tiêu\n",
    "Khi huấn luyện mô hình, ta muốn tìm các tham số $\\mathbf{w}^*$ và $b^*$ sao cho tổng độ mất mát trên toàn bộ các mẫu huấn luyện được cực tiểu hóa:\n",
    "$$\n",
    "\\mathbf{w}^*, b^* = \\underset{\\mathbf{w}, b}{\\text{argmin}}\\:L(\\mathbf{w}, b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8e56b",
   "metadata": {},
   "source": [
    "Kỹ thuật chính để tối ưu hóa mô hình này, cũng như các mô hình học sâu khác, bao gồm việc giảm thiểu lỗi qua các vòng lặp bằng cách cập nhật tham số theo hướng làm giảm gần hàm mát mát. Với các hàm mất mát mặt lồi, giá trị mất mát cuối cùng sẽ hội tụ về giá trị nhỏ nhất. Tuy điều tương tự không thể áp dụng cho các mặt không lồi, ít nhất thuật toán sẽ dẫn tới một cực tiểu (hy vọng là tốt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a88f397",
   "metadata": {},
   "source": [
    "Đơn giản nhất ta có thể kể đến là việc tính đạo hàm của hàm mất mát, tức trung bình của các giá trị mất mát được tính trên mỗi mẫu của tập dữ liệu. Cuối cùng, gradient này được nhân với tốc độ học $\\eta > 0$, lấy trung bình trên kích thước tập dữ liệu và kết quả này được trừ đi từ các giá trị tham số hiện tại. Đây là chính phương pháp Gradient Descent (GD). Trên thực tế, điều này có thể cực kỳ chậm: chúng ta phải duyệt qua toàn bộ tập dữ liệu trước khi thực hiện một lần cập nhật duy nhất, ngay cả khi có bước cập nhật có thể rất mạnh mẽ. Tệ hơn nữa, nếu có nhiều dữ liệu trùng lặp trong tập dữ liệu huấn luyện, lợi ích của việc cập nhật toàn bộ sẽ bị hạn chế.\n",
    "\n",
    "Việc cập nhật có thể được biểu diễn bằng công thức dưới đây:\n",
    "$$\n",
    "(\\mathbf{w}, b) \\leftarrow (\\mathbf{w}, b) - \\frac{\\eta}{|\\boldsymbol{N}|} \\sum_{i \\in \\boldsymbol{N}} \\partial_{(\\mathbf{w}, b)}L_i(\\mathbf{w}, b)\n",
    "$$\n",
    "hay,\n",
    "$$\n",
    "\\mathbf{w} \\leftarrow \\mathbf{w} - \\frac{\\eta}{|\\boldsymbol{N}|} \\sum_{i \\in \\boldsymbol{N}} \\partial_\\mathbf{w} L_i(\\mathbf{w}, b)\n",
    "$$\n",
    "$$\n",
    "b \\leftarrow b - \\frac{\\eta}{|\\boldsymbol{N}|} \\sum_{i \\in \\boldsymbol{N}} \\partial_{b} L_i(\\mathbf{w}, b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a521b87",
   "metadata": {},
   "source": [
    "Một cách khác hoàn toàn là chỉ xem xét một mẫu dữ liệu duy nhất tại một thời điểm và thực hiện các bước cập nhật dựa trên từng quan sát tại một thời điểm. Đây là chính phương pháp Stochastic Gradient Descent (SGD). Có thể coi đây là một chiến lược hiệu quả, ngay cả đối với các tập dữ liệu lớn. Tuy nhiên, SGD có những nhược điểm, cả về mặt tính toán và thống kê. Một vấn đề phát sinh từ thực tế là bộ xử lý nhân và cộng số nhanh hơn nhiều so với việc di chuyển dữ liệu từ bộ nhớ chính đến bộ đệm bộ xử lý. Thực hiện phép nhân ma trận-vectơ hiệu quả hơn tới một cấp độ so với số lượng phép toán vecto-vectơ tương ứng. Điều này có nghĩa là có thể mất nhiều thời gian hơn để xử lý một mẫu tại một thời điểm so với toàn bộ mẫu. Một vấn đề thứ hai là một số lớp, chẳng hạn như batch normalization yêu cầu có nhiều hơn một mẫu dữ liệu tại một thời điểm.\n",
    "\n",
    "Việc cập nhật có thể được biểu diễn bằng công thức dưới đây:\n",
    "$$\n",
    "(\\mathbf{w}, b) \\leftarrow (\\mathbf{w}, b) - \\eta*\\partial_{(\\mathbf{w}, b)}L(\\mathbf{w}, b)\n",
    "$$\n",
    "hay,\n",
    "$$\n",
    "\\mathbf{w} \\leftarrow \\mathbf{w} - \\eta*\\partial_\\mathbf{w} L(\\mathbf{w}, b)\n",
    "$$\n",
    "$$\n",
    "b \\leftarrow b - \\eta*\\partial_{b} L(\\mathbf{w}, b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6930b5c7",
   "metadata": {},
   "source": [
    "Giải pháp cho cả hai vấn đề là chọn một chiến lược trung gian: thay vì lấy toàn bộ mẫu dữ liệu hoặc chỉ một tại một thời điểm, chúng ta lấy một số lượng nhỏ. Lựa chọn cụ thể về kích thước của số lượng nói trên phụ thuộc vào nhiều yếu tố, chẳng hạn như lượng bộ nhớ, số lượng bộ tăng tốc, lựa chọn lớp và tổng kích thước tập dữ liệu. Mặc dù vậy, một số từ 32 đến 256, tốt nhất là bội số của một lũy thừa lớn của 2 là một khởi đầu tốt. Đây chính là phương pháp biến thể Stochastic Gradient Descent theo minibatch (Minibatch SGD). Ở vòng lặp `t`, ta lấy ngẫu nhiên một số mẫu gọi là $B_t$ sao cho kích thước là |$B$|. Sau đó, chúng ta tính đạo hàm của hàm mất mát trên minibatch đó theo các tham số của mô hình. Cuối cùng, gradient này được nhân với tốc độ học  $\\eta > 0$, lấy trung bình trên kích thước minibatch và kết quả này được trừ đi từ các giá trị tham số hiện tại.\n",
    "\n",
    "Việc cập nhật có thể được biểu diễn bằng công thức dưới đây:\n",
    "$$\n",
    "(\\mathbf{w}, b) \\leftarrow (\\mathbf{w}, b) - \\frac{\\eta}{|\\boldsymbol{B}|} \\sum_{i \\in \\boldsymbol{B_t}} \\partial_{(\\mathbf{w}, b)}L_i(\\mathbf{w}, b)\n",
    "$$\n",
    "hay,\n",
    "$$\n",
    "\\mathbf{w} \\leftarrow \\mathbf{w} - \\frac{\\eta}{|\\boldsymbol{B}|} \\sum_{i \\in \\boldsymbol{B_t}} \\partial_\\mathbf{w} L_i(\\mathbf{w}, b)\n",
    "$$\n",
    "$$\n",
    "b \\leftarrow b - \\frac{\\eta}{|\\boldsymbol{B}N|} \\sum_{i \\in \\boldsymbol{B_t}} \\partial_{b} L_i(\\mathbf{w}, b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc10fcb",
   "metadata": {},
   "source": [
    "### Ứng dụng các Thuật toán tối ưu cho Hồi quy Tuyến tính"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe8a89",
   "metadata": {},
   "source": [
    "Để thuận tiện, hàm lập trình GD, SGD và SGD theo minibatch sẽ có danh sách tham số giống nhau. Cụ thể, chúng ta thêm trạng thái đầu vào biến `states` và đặt siêu tham số trong biến `hyperparams`. Bên cạnh đó, chúng ta sẽ tính giá trị mất mát trung bình của từng minibatch trong hàm huấn luyện, từ đó không cần phải chia gradient cho kích thước batch trong thuật toán tối ưu nữa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c54e9-817f-4b0a-aaab-16cbd82c6f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, states, hyperparams):\n",
    "    for p in params:\n",
    "        p.data.sub_(hyperparams['lr'] * p.grad)\n",
    "        p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c36b5",
   "metadata": {},
   "source": [
    "**Giải thích**\n",
    "\n",
    "Hàm `sgd` sẽ duyệt qua các tham số `p` trong `params` của mô hình, trong bài toán Hồi quy Tuyến tính sẽ là vector trọng số $\\mathbf{w}$ và $b$ và cập nhật theo quy tắc:\n",
    "$$\n",
    "p := p - \\eta*\\Delta_pL\n",
    "$$\n",
    "Trong đó:\n",
    "- `p`: tham số\n",
    "- `p.grad`: đạo hàm của hàm mất mát theo p\n",
    "- `hyperparams['lr']` hay $\\eta$: tốc độ học (learning rate)\n",
    "Sau đó, thực hiện reset gradient ở bước cuối trong mỗi vòng lặp để tránh tích lũy gradient từ nhiều batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3fcbde",
   "metadata": {},
   "source": [
    "Tiếp theo, chúng ta hiện thực một hàm huấn luyện tổng quát, sử dụng được cho tất cả các thuật toán tối ưu. Hàm sẽ khởi tạo một mô hình Hồi quy Tuyến tính và có thể được sử dụng để huấn luyện mô hình với GD, SGD và SGD theo minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa49aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def train_ch11(trainer_fn, states, hyperparams, data_iter,\n",
    "               feature_dim, num_epochs=2):\n",
    "    # Initialization\n",
    "    w = torch.normal(mean=0.0, std=0.01, size=(feature_dim, 1),\n",
    "                     requires_grad=True)\n",
    "    b = torch.zeros((1), requires_grad=True)\n",
    "    net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss\n",
    "    # Train\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                            xlim=[0, num_epochs], ylim=[0.22, 0.35])\n",
    "    n, timer = 0, d2l.Timer()\n",
    "    for _ in range(num_epochs):\n",
    "        for X, y in data_iter:\n",
    "            l = loss(net(X), y).mean()\n",
    "            l.backward()\n",
    "            trainer_fn([w, b], states, hyperparams)\n",
    "            n += X.shape[0]\n",
    "            if n % 200 == 0:\n",
    "                timer.stop()\n",
    "                animator.add(n/X.shape[0]/len(data_iter),\n",
    "                             (d2l.evaluate_loss(net, data_iter, loss),))\n",
    "                timer.start()\n",
    "    print(f'loss: {animator.Y[0][-1]:.3f}, {timer.sum()/num_epochs:.3f} sec/epoch')\n",
    "    return timer.cumsum(), animator.Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35df4c87",
   "metadata": {},
   "source": [
    "**Giải thích**\n",
    "\n",
    "Hàm `train_ch11` sẽ khởi tạo các giá trị cần cho mô hình Hồi quy Tuyến tính và thực hiện huấn luyện.\n",
    "\n",
    "Tham số đầu vào:\n",
    "- `trainer_fn`: hàm cập nhật tham số mô hình (GD, SGD, ...)\n",
    "- `states`: các trạng thái cần thiết cho `trainer_fn`\n",
    "- `hyperparams`: các siêu tham số như `lr`, `beta`\n",
    "- `feature_dim`: số lượng đặc trưng (hoặc số chiều biến đầu vào)\n",
    "- `num_epochs`: số vòng lặp huấn luyện\n",
    "\n",
    "**Bước 1: Khởi tạo mô hình**\n",
    "Đầu tiên, khởi tạo 2 vector trọng số $\\mathbf{w}$ và bias $b$ đều yêu cầu gradient, trong đó:\n",
    "- $\\mathbf{w}$ tuân theo phân phối chuẩn với $\\mu$ = 0.0 và $\\sigma$ = 0.01, có kích thước `feature_dim` x 1 \n",
    "- $b$ = 0\n",
    "\n",
    "Tiếp theo, khởi tạo `net` với `loss`, lần lượt là mô hình Hồi quy tuyến tính có dạng $y = \\boldsymbol{X}*\\mathbf{w} + b$ và hàm mất mát theo MSE\n",
    "\n",
    "**Bước 2: Khởi tạo tiến trình vẽ hàm mất mát và bộ đếm thời gian**\n",
    "- `animator`: thực thể để biểu diễn hàm mất mát dưới dạng đồ thị theo thời gian\n",
    "- `n`: tổng số mẫu đã xử lý\n",
    "- `timer`: để đo thời gian chạy từng epoch\n",
    "\n",
    "**Bước 3: Huấn luyện mô hình**\n",
    "Lần lượt duyệt qua từng batch:\n",
    "1. Tính giá trị hàm mất mát: `l = loss(net(X), y).mean()` tương ứng việc lấy trung bình giá trị MSE cho toàn bộ các điểm dữ liệu trong batch\n",
    "2. Thực hiện lan truyền ngược để tính GD: `l.backward()`\n",
    "3. Cập nhật tham số: `trainer_fn` được gọi với `[w, b]`, `states` và `hyperparams`\n",
    "4. Reset gradient descent nằm trong `trainer_fn`.\n",
    "\n",
    "Vẽ hàm mất mát với mỗi 200 mẫu\n",
    "\n",
    "**Bước 4: In kết quả**\n",
    "In giá trị hàm mất mát cuối cùng và thời gian trung bình mỗi epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2defb",
   "metadata": {},
   "source": [
    "Tiếp theo, ta tạo một hàm đầu vào để thực hiện toàn quá trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b18b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sgd(lr, batch_size, num_epochs=2):\n",
    "    data_iter, feature_dim = get_data_ch11(batch_size)\n",
    "    return train_ch11(sgd, None, {'lr': lr}, data_iter, feature_dim, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbd1340",
   "metadata": {},
   "source": [
    "**Giải thích**\n",
    "Hàm `train_sgd` thực hiện việc đọc dữ liệu, khởi tạo các tham số và huấn luyện mô hình.\n",
    "\n",
    "Tham số đầu vào:\n",
    "- `lr`: siêu tham số tốc độ học (learning rate)\n",
    "- `batch_size`: kích thước của batch\n",
    "- `num_epochs`: số vòng lặp huấn luyện\n",
    "\n",
    "Dữ liệu được trả về theo từng batch từ hàm `get_data_ch11` sẽ được dùng để huấn luyện trong hàm `train_ch11`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77e4cd",
   "metadata": {},
   "source": [
    "#### Thực nghiệm với GD\n",
    "Hãy cùng quan sát quá trình tối ưu của thuật toán Gradient Descent (GD) theo toàn bộ batch. Ta có thể sử dụng toàn bộ batch bằng cách thiết lập kích thước minibatch bằng tổng số mẫu (trong trường hợp này là 1500). Kết quả là các tham số mô hình chỉ được cập nhật một lần duy nhất trong mỗi epoch. Có thể thấy không có tiến triển nào đáng kể. Trong ví dụ, việc tối ưu bị ngừng trệ sau 6 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036e4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_res = train_sgd(1, 1500, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d45e29",
   "metadata": {},
   "source": [
    "**Giải thích**\n",
    "\n",
    "Ở đây ta thực nghiệm huấn luyện mô hình với GD, sử dụng $\\eta = 1$, số lượng epoch = 10 và thiết lập tham số `batch_size` = 1500 (= kích thước của tập dữ liệu), tức là với mỗi epoch hàm mất mát sẽ được tính và thực hiện cập nhật $(\\mathbf{w}, b)$ chỉ 1 lần duy nhất"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a8619e",
   "metadata": {},
   "source": [
    "#### Thực nghiệm với SGD\n",
    "\n",
    "Khi kích thước của batch bằng 1, chúng ta sử dụng thuật toán SGD để tối ưu. Để đơn giản hóa việc hiện thực, chúng ta cố định tốc độ học (learning rate) bằng một hằng số (có giá trị nhỏ). Trong SGD, các tham số mô hình được cập nhật bất cứ khi nào có một mẫu huấn luyện được xử lý. Trong trường hợp này, sẽ có 1500 lần cập nhật trong mỗi epoch. Có thể thấy, sự suy giảm giá trị của hàm mục tiêu chậm lại sau một epoch. Mặc dù cả hai thuật toán cùng xử lý 1500 mẫu trong một epoch, SGD tốn thời gian hơn GD trong thí nghiệm trên. Điều này là do SGD cập nhật các tham số thường xuyên hơn và kém hiệu quả khi xử lý đơn lẻ từng mẫu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0322383",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_res = train_sgd(0.005, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e4962",
   "metadata": {},
   "source": [
    "**Giải thích**\n",
    "\n",
    "Ở đây ta thực nghiệm huấn luyện mô hình với SGD, sử dụng $\\eta = 0.005$, số lượng epoch = 2 (theo mặc định) và thiết lập tham số `batch_size` = 1, tức là với mỗi epoch hàm mất mát sẽ được tính và thực hiện cập nhật $(\\mathbf{w}, b)$ với mỗi điểm dữ liệu trong tập."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2255f2",
   "metadata": {},
   "source": [
    "#### Thực nghiệm với SGD theo minibatch\n",
    "\n",
    "Cuối cùng, khi kích thước của batch bằng 100, chúng ta sử dụng thuật toán SGD theo minibatch để tối ưu. Thời gian cần thiết cho mỗi epoch ngắn hơn thời gian tương ứng của SGD và GD theo toàn bộ batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3291ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini1_res = train_sgd(.4, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea9943",
   "metadata": {},
   "source": [
    "**Giải thích**\n",
    "\n",
    "Ở đây ta thực nghiệm huấn luyện mô hình với SGD theo minibatch có kích thước = 100, sử dụng $\\eta = 0.4$, số lượng epoch = 2 (theo mặc định), tức là với mỗi epoch hàm mất mát sẽ được tính và thực hiện cập nhật $(\\mathbf{w}, b)$ tương ứng là $\\frac{1500}{100} = 15$ lần"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc24d1",
   "metadata": {},
   "source": [
    "Giảm kích thước của batch bằng 10, thời gian cho mỗi epoch tăng vì thực thi tính toán trên mỗi batch kém hiệu quả hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe23a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini2_res = train_sgd(.05, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cff3d1a",
   "metadata": {},
   "source": [
    "**Giải thích**\n",
    "\n",
    "Ở đây ta thực nghiệm huấn luyện mô hình với SGD theo minibatch có kích thước = 10, sử dụng $\\eta = 0.05$, số lượng epoch = 2 (theo mặc định), tức là với mỗi epoch hàm mất mát sẽ được tính và thực hiện cập nhật $(\\mathbf{w}, b)$ tương ứng là $\\frac{1500}{10} = 150$ lần"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04560786",
   "metadata": {},
   "source": [
    "Cuối cùng, chúng ta so sánh tương quan thời gian và giá trị hàm mấy mát trong bốn thí nghiệm trên. Có thể thấy, dù hội tụ nhanh hơn GD về số mẫu được xử lý, SGD tốn nhiều thời gian hơn để đạt được cùng giá trị mất mát như GD vì thuật toán này tính gradient descent trên từng mẫu một. Thuật toán SGD theo minibatch có thể cân bằng giữa tốc độ hội tụ và hiệu quả tính toán. Với kích thước minibatch bằng 10, thuật toán này hiệu quả hơn SGD; và với kích thước minibatch bằng 100, thời gian chạy của thuật toán này thậm chí nhanh hơn cả GD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8473cb",
   "metadata": {},
   "source": [
    "### Tóm tắt\n",
    "\n",
    "| Tiêu chí                             | Gradient Descent (GD)            | Stochastic Gradient Descent (SGD) | Minibatch SGD                    |\n",
    "| ------------------------------------ | -------------------------------- | --------------------------------- | --------------------------------- |\n",
    "| **Kích thước dữ liệu dùng mỗi bước** | Toàn bộ tập dữ liệu              | 1 mẫu dữ liệu                     | Một nhóm nhỏ (batch)              |\n",
    "| **Tần suất cập nhật tham số**        | 1 lần / epoch                    | N lần / epoch (với N = số mẫu)    | N/B lần / epoch (B = batch size)  |\n",
    "| **Tốc độ tính toán mỗi bước**        | Chậm (phải quét toàn bộ dữ liệu) | Rất nhanh                         | Trung bình                        |\n",
    "| **Độ ổn định gradient**              | Ổn định, ít dao động             | Dao động mạnh, nhiễu nhiều        | Dao động vừa phải                 |\n",
    "| **Khả năng hội tụ**                  | Chậm nhưng mượt                  | Nhanh ban đầu, có thể dao động    | Cân bằng giữa tốc độ và ổn định   |\n",
    "| **Khả năng thoát local minima**      | Thấp                             | Cao (nhờ nhiễu)                   | Tương đối tốt                     |\n",
    "| **Yêu cầu bộ nhớ (RAM)**             | Cao (vì xử lý toàn bộ data)      | Rất thấp                          | Vừa phải                          |\n",
    "| **Ứng dụng thực tế**                 | Hiếm dùng với dữ liệu lớn        | Dùng nhiều cho online learning    | Phổ biến nhất trong deep learning |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523c5892-76e4-4f5c-b72c-bff4fc4ec739",
   "metadata": {},
   "source": [
    "## Concise Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b29ea5",
   "metadata": {},
   "source": [
    "Trong Gluon, chúng ta có thể sử dụng lớp `Trainer` để gọi các thuật toán tối ưu. Cách này được sử dụng để có thể hiện thực một hàm huấn luyện tổng quát. Chúng ta sẽ sử dụng hàm này xuyên suốt các phần tiếp theo của chương."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8af60-a69d-40dc-9f2e-5583557c622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def train_concise_ch11(trainer_fn, hyperparams, data_iter, num_epochs=4):\n",
    "    # Initialization\n",
    "    net = nn.Sequential(nn.Linear(5, 1))\n",
    "    def init_weights(module):\n",
    "        if type(module) == nn.Linear:\n",
    "            torch.nn.init.normal_(module.weight, std=0.01)\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    optimizer = trainer_fn(net.parameters(), **hyperparams)\n",
    "    loss = nn.MSELoss(reduction='none')\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                            xlim=[0, num_epochs], ylim=[0.22, 0.35])\n",
    "    n, timer = 0, d2l.Timer()\n",
    "    for _ in range(num_epochs):\n",
    "        for X, y in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            out = net(X)\n",
    "            y = y.reshape(out.shape)\n",
    "            l = loss(out, y)\n",
    "            l.mean().backward()\n",
    "            optimizer.step()\n",
    "            n += X.shape[0]\n",
    "            if n % 200 == 0:\n",
    "                timer.stop()\n",
    "                # `MSELoss` computes squared error without the 1/2 factor\n",
    "                animator.add(n/X.shape[0]/len(data_iter),\n",
    "                             (d2l.evaluate_loss(net, data_iter, loss) / 2,))\n",
    "                timer.start()\n",
    "    print(f'loss: {animator.Y[0][-1]:.3f}, {timer.sum()/num_epochs:.3f} sec/epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter, _ = get_data_ch11(10)\n",
    "trainer = torch.optim.SGD\n",
    "train_concise_ch11(trainer, {'lr': 0.01}, data_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565256bc-8212-46d3-b07c-b4b31fa3f62e",
   "metadata": {},
   "source": [
    "## Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fadbff6-3a56-4bb7-af84-59a5cf724da1",
   "metadata": {},
   "source": [
    "### Exercise 1.\n",
    "Sửa đổi kích thước batch và tốc độ học, quan sát tốc độ suy giảm giá trị của hàm mục tiêu và thời gian cho mỗi epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7007be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thử nghiệm với các giá trị khác nhau của tốc độ học và kích thước batch\n",
    "# Tốc độ học lớn hơn và kích thước batch nhỏ hơn\n",
    "experiment_1 = train_sgd(lr=0.1, batch_size=5, num_epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3295ee-b93c-4dbb-883d-2a78fc17b058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tốc độ học nhỏ hơn và kích thước batch lớn hơn\n",
    "experiment_2 = train_sgd(lr=0.01, batch_size=50, num_epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326251fb-1f59-411a-8935-17e674dc5cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tốc độ học trung bình và kích thước batch trung bình\n",
    "experiment_3 = train_sgd(lr=0.05, batch_size=20, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b8ca3",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "1. **Tốc độ học lớn hơn và kích thước batch nhỏ hơn**:\n",
    "    - Với tốc độ học lớn và kích thước batch nhỏ, mô hình có thể hội tụ nhanh hơn nhưng dễ gặp phải dao động lớn trong quá trình tối ưu hóa do phương sai cao của gradient.\n",
    "\n",
    "2. **Tốc độ học nhỏ hơn và kích thước batch lớn hơn**:\n",
    "    - Với tốc độ học nhỏ và kích thước batch lớn, mô hình hội tụ ổn định hơn nhưng tốc độ hội tụ có thể chậm hơn do các bước cập nhật nhỏ.\n",
    "\n",
    "3. **Tốc độ học trung bình và kích thước batch trung bình**:\n",
    "    - Với tốc độ học và kích thước batch trung bình, mô hình đạt được sự cân bằng giữa tốc độ hội tụ và độ ổn định, thường mang lại kết quả tốt nhất.\n",
    "\n",
    "Kích thước batch và tốc độ học là các siêu tham số quan trọng, cần được điều chỉnh phù hợp với bài toán cụ thể để đạt hiệu quả tối ưu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79b73c7",
   "metadata": {},
   "source": [
    "### Exercise 2.\n",
    "Đọc thêm tài liệu MXNet và sử dụng hàm set_learning_rate của lớp Trainer để giảm tốc độ học của SGD theo minibatch bằng 1/10 giá trị trước đó sau mỗi epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5851407d-6c0c-4c2a-b844-7f7a35382b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, nd\n",
    "\n",
    "# Define a simple model\n",
    "net = gluon.nn.Sequential()\n",
    "net.add(gluon.nn.Dense(10))\n",
    "net.initialize(mx.init.Xavier())\n",
    "\n",
    "# Initialize Trainer with SGD optimizer\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1})\n",
    "\n",
    "# Simulate training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    # Reduce learning rate by a factor of 10 after each epoch\n",
    "    new_lr = trainer.learning_rate * 0.1\n",
    "    trainer.set_learning_rate(new_lr)\n",
    "    print(f'Epoch {epoch+1}: Learning rate = {new_lr}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165aee7c",
   "metadata": {},
   "source": [
    "### Exercise 3.\n",
    "Hãy so sánh SGD theo minibatch sử dụng một biến thể lấy mẫu có hoàn lại từ tập huấn luyện. Điều gì sẽ xảy ra?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a503c84",
   "metadata": {},
   "source": [
    "Khi huấn luyện mô hình sử dụng phương pháp SGD theo minibatch thông thường, ta có:\n",
    "- Cách hoạt động:\n",
    "    + Với mỗi vòng lặp huấn luyện, tập dữ liệu sẽ được chia nhỏ thành các minibatch.\n",
    "    + Mỗi minibatch chứa các mẫu dữ liệu độc nhất cho đến khi vòng lặp được hoàn thành.\n",
    "    + Mỗi điểm dữ liệu chỉ được dùng 1 lần mỗi vòng lặp.\n",
    "- Đặc điểm:\n",
    "    + Ước lượng gradient hiệu quả: phương sai cho mỗi minibatch tương đối nhỏ.\n",
    "    + Hội tụ nhanh và mượt mà hơn.\n",
    "    + Đảm bảo các mẫu đều được xem xét mỗi vòng lặp huấn luyện.\n",
    "\n",
    "So sánh với biến thể minibatch cho phép lấy mẫu hoàn lại từ tập dữ liệu, ta có:\n",
    "- Cách hoạt động:\n",
    "    + Với mỗi vòng lặp huấn luyện, các minibatch sẽ được tạo ra bằng cách lấy ngẫu nhiên từ tập dữ liệu.\n",
    "    + Một vài mẫu sẽ được chọn nhiều lần, một vài mẫu thì không bao giờ được chọn.\n",
    "    + Không đảm bảo rằng tất cả các điểm dữ liệu được dùng 1 lần mỗi vòng lặp.\n",
    "- Đặc điểm:\n",
    "    + Ước lượng gradient kém hiệu quả: có nhiều nhiễu do bị trùng hoặc thiếu một phần mẫu.\n",
    "    + Hội tụ chậm hoặc kém ổn định\n",
    "    + Thiếu tính khái quát hóa do bị overfit với các mẫu dữ liệu được lựa chọn nhiều và underfit với các mẫu dữ liệu không được lựa chọn. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8bad3",
   "metadata": {},
   "source": [
    "### Exercise 4.\n",
    "Một ác thần đã sao chép tập dữ liệu của bạn mà không nói cho bạn biết (cụ thể, mỗi quan sát bị lặp lại hai lần và kích thước tập dữ liệu tăng gấp đôi so với ban đầu). Cách hoạt động của các thuật toán hạ gradient, SGD và SGD theo minibatch sẽ thay đổi như thế nào?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f1d7f",
   "metadata": {},
   "source": [
    "Nếu tập dữ liệu bị lặp lại, ta đang có kích thước của mẫu quan sát tăng lên nhưng không có thêm thông tin mới. Điều này ảnh hưởng khác nhau đến các phương pháp tối ưu theo các cách khác nhau:\n",
    "1. Gradient Descent (GD) - Sử dụng toàn bộ mẫu dữ liệu\n",
    "- Gradient Descent sử dụng toàn bộ mẫu dữ liệu, nên sẽ làm tăng giá trị hàm mất mát và độ dốc theo tỉ lệ thuận. Tuy nhiên, hướng của gradient sẽ không đổi, do ta chỉ cộng các thành phần lặp lại.\n",
    "- Ảnh hưởng:\n",
    "    + Hướng của gradient được giữ nguyên, nhưng được tăng lên.\n",
    "    + Tốc độ học cần phải được điều chỉnh để duy trì được độ ổn định.\n",
    "    + Chi phí tính toán tăng lên (lâu hơn mỗi vòng lặp nhưng không có thêm thông tin gì)\n",
    "2. Stochastic Gradient Descent (SGD) – Sử dụng 1 mẫu\n",
    "- Mỗi mẫu sẽ có khả năng cao hơn được chọn nhiều lần, nhưng không có sự thay đổi về chất lượng gradient và tính đa dạng của tập dữ liệu\n",
    "- Ảnh hưởng:\n",
    "    + Không có sự khác biệt cơ bản về quá trình huấn luyện.\n",
    "    + Phương sai không đổi.\n",
    "    + Hội tụ chậm hơn do trùng lặp dữ liệu.\n",
    "3. Minibatch Stochastic Gradient Descent (Minibatch SGD) - Sử dụng tập con\n",
    "- Các minibatch sẽ chứa nhiều mẫu trùng lặp hơn giữa các vòng lặp huấn luyện.\n",
    "- Tốc độ học có thể chậm lại do liên tục thấy các mẫu trùng lặp\n",
    "- Ảnh hưởng:\n",
    "    + Hướng của gradient được giữ nguyên, nhưng tính khái quát lâu được cải thiện.\n",
    "    + Có thể tốn các vòng lặp để huấn luyện các mẫu trùng lặp."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
