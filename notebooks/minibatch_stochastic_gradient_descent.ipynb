{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "309cd8a2-96e3-41aa-8e2e-19db846d3cfc",
   "metadata": {},
   "source": [
    "# Minibatch Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462c5e57-966a-43b7-bd5a-9758081390fe",
   "metadata": {},
   "source": [
    "Trong học sâu, việc tối ưu hóa các tham số của mô hình là một bước quan trọng để đạt được hiệu suất tốt nhất. Có nhiều phương pháp tối ưu hóa khác nhau, trong đó Gradient Descent (GD) và Stochastic Gradient Descent (SGD) là hai phương pháp phổ biến. Tuy nhiên, cả hai đều có những hạn chế riêng. Minibatch Stochastic Gradient Descent (Minibatch SGD) được xem là một giải pháp cân bằng giữa hai phương pháp này, mang lại hiệu quả cả về mặt tính toán và thống kê."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c5374c-173b-45b0-8528-a4211cefcff8",
   "metadata": {},
   "source": [
    "## Vectorization and Caches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c71c36e",
   "metadata": {},
   "source": [
    "Trọng tâm của quyết định sử dụng minibatches là hiệu quả tính toán. Điều này dễ hiểu nhất khi xem xét song song với nhiều GPU và nhiều máy chủ. Trong trường hợp này, chúng ta cần gửi ít nhất một hình ảnh cho mỗi GPU. Với 8 GPU trên mỗi máy chủ và 16 máy chủ, ta có minibatch kích thước 128. \n",
    "\n",
    "Vấn đề trở nên nhạy cảm hơn đối với GPU đơn hay ngay cả CPU đơn. Các thiết bị này có nhiều loại bộ nhớ, thường là nhiều loại đơn vị tính toán và hạn chế băng thông khác nhau giữa chúng. Ví dụ, CPU có một số lượng nhỏ các thanh ghi và sau đó là L1, L2 và trong một số trường hợp thậm chí bộ nhớ cache L3 (được chia sẻ giữa các lõi bộ xử lý khác nhau). Các bộ nhớ đệm này có kích thước và độ trễ ngày càng tăng (đồng thời chúng giảm băng thông). Nó đủ để nói, bộ xử lý có khả năng thực hiện nhiều hoạt động hơn so với những gì giao diện bộ nhớ chính có thể cung cấp. \n",
    "\n",
    "* CPU 2GHz với 16 lõi và vectorization AVX-512 có thể xử lý lên đến $2 \\cdot 10^9 \\cdot 16 \\cdot 32 = 10^{12}$ byte mỗi giây. Khả năng của GPU dễ dàng vượt quá con số này theo hệ số 100. Mặt khác, một bộ xử lý máy chủ tầm trung có thể không có nhiều hơn 100 Gb/s băng thông, tức là, ít hơn một phần mười những gì sẽ được yêu cầu để giữ cho bộ xử lý ăn. Vấn đề còn tồi tệ hơn khi ta xét đến việc không phải khả năng truy cập bộ nhớ nào cũng như nhau: đầu tiên, giao diện bộ nhớ thường rộng 64 bit hoặc rộng hơn (ví dụ, trên GPU lên đến 384 bit), do đó việc đọc một byte duy nhất vẫn sẽ phải chịu chi phí giống như truy cập một khoảng bộ nhớ rộng hơn.\n",
    "* Tổng chi phí cho lần truy cập đầu tiên là khá lớn, trong khi truy cập liên tiếp thường hao tổn ít. Có rất nhiều điều cần lưu ý, ví dụ như lưu trữ đệm khi ta có nhiều điểm truy cập cuối, chiplet và các cấu trúc khác...\n",
    "\n",
    "Cách để giảm bớt những hạn chế này là sử dụng một hệ thống phân cấp của bộ nhớ cache CPU thực sự đủ nhanh để cung cấp cho bộ xử lý dữ liệu. Đây là *động lực* đằng sau việc sử dụng batch trong học sâu. ĐĐể đơn giản, xét phép nhân hai ma trận $\\mathbf{A} = \\mathbf{B}\\mathbf{C}$. Để tính $\\mathbf{A}$ ta có khá nhiều lựa chọn, ví dụ như: \n",
    "\n",
    "1. Ta có thể tính $\\mathbf{A}_{ij} = \\mathbf{B}_{i,:} \\mathbf{C}_{:,j}^\\top$, tức là tính từng phần tử bằng tích vô hướng.\n",
    "1. Ta có thể tính $\\mathbf{A}_{:,j} = \\mathbf{B} \\mathbf{C}_{:,j}^\\top$, ttức là tính theo từng cột. Tương tự, ta có thể tính $\\mathbf{A}$ theo từng hàng $\\mathbf{A}_{i,:}$.\n",
    "1. Ta đơn giản có thể tính $\\mathbf{A} = \\mathbf{B} \\mathbf{C}$.\n",
    "1. Ta có thể chia $\\mathbf{B}$ và $\\mathbf{C}$ thành các ma trận khối nhỏ hơn và tính toán $\\mathbf{A}$ theo từng khối một.\n",
    "\n",
    "Nếu sử dụng cách đầu tiên, ta cần sao chép một vector cột và một vector hàng vào CPU cho mỗi lần tính phần tử $\\mathbf{A}_{ij}$. Tệ hơn nữa, do các phần tử của ma trận được lưu thành một dãy liên tục dưới bộ nhớ, ta buộc phải truy cập nhiều vùng nhớ rời rạc khi đọc một trong hai vector từ bộ nhớ. Cách thứ hai tốt hơn nhiều. Theo cách này, ta có thể giữ vector cột $\\mathbf{C}_{:,j}$ trong vùng nhớ đệm của CPU trong khi ta tiếp tục quét qua $\\mathbf{B}$. Cách này chỉ cần nửa băng thông cần thiết của bộ nhớ, do đó truy cập nhanh hơn. Đương nhiên cách thứ ba là tốt nhất. Đáng tiếc rằng đa số ma trận quá lớn để có thể đưa vào vùng nhớ đệm (dù sao đây cũng chính là điều ta đang thảo luận). Cách thứ tư là một phương pháp thay thế khá tốt: đưa các khối của ma trận vào vùng nhớ đệm và thực hiện phép nhân cục bộ. Các thư viện đã được tối ưu sẽ thực hiện việc này giúp chúng ta. Hãy xem xét hiệu suất của từng phương pháp trong thực tế. \n",
    "\n",
    "Ngoài hiệu suất tính toán, chi phí tính toán phát sinh đến từ Python và framework học sâu cũng đáng cân nhắc. Mỗi lần ta thực hiện một câu lệnh, bộ thông dịch Python gửi một câu lệnh đến MXNet để chèn câu lệnh đó vào đồ thị tính toán và thực thi nó theo đúng lịnh trình. Chi phí đó có thể khá bất lợi. Nói ngắn gọn, nên áp dụng vector hóa (và ma trận) bất cứ khi nào có thể."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "502f54e8-d696-42e4-bab6-a8b5aa1a32b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import d2l\n",
    "\n",
    "A = torch.zeros(512, 512)\n",
    "B = torch.randn(512, 512)\n",
    "C = torch.randn(512, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de3788f",
   "metadata": {},
   "source": [
    "Vì chúng ta sẽ thường xuyên đo thời gian chạy trong phần còn lại của báo cáo, hãy định nghĩa một bộ đếm thời gian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b8e95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    \"\"\"Record multiple running times.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer and record the time in a list.\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"Return the average time.\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"Return the sum of time.\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"Return the accumulated time.\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()\n",
    "\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ecd54f",
   "metadata": {},
   "source": [
    "Gán từng phần tử đơn giản là lặp qua tất cả các hàng và cột của $\\mathbf{B}$ và $\\mathbf{C}$ tương ứng để gán giá trị cho $\\mathbf{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c00df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute A = BC one element at a time\n",
    "timer.start()\n",
    "for i in range(512):\n",
    "    for j in range(512):\n",
    "        A[i, j] = torch.dot(B[i, :], C[:, j])\n",
    "timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85adbf56",
   "metadata": {},
   "source": [
    "Một chiến lược nhanh hơn là thực hiện gán theo cột."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f6efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute A = BC one column at a time\n",
    "timer.start()\n",
    "for j in range(512):\n",
    "    A[:, j] = torch.mv(B, C[:, j])\n",
    "timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c9312",
   "metadata": {},
   "source": [
    "Cuối cùng, phương pháp hiệu quả nhất là thực hiện toàn bộ phép toán trong một khối duy nhất.\n",
    "Lưu ý rằng việc nhân hai ma trận $\\mathbf{B} \\in \\mathbb{R}^{m \\times n}$ và $\\mathbf{C} \\in \\mathbb{R}^{n \\times p}$ cần khoảng $2mnp$ phép toán dấu phẩy động,\n",
    "khi phép nhân và cộng vô hướng được tính là hai phép toán riêng biệt (mặc dù trên thực tế thường được gộp lại).\n",
    "Do đó, việc nhân hai ma trận kích thước $512 \\times 512$ cần khoảng $0.27$ tỷ phép toán dấu phẩy động.\n",
    "Bây giờ, hãy cùng xem tốc độ tương ứng của các phép toán này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f66219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute A = BC in one go\n",
    "timer.start()\n",
    "A = torch.mm(B, C)\n",
    "timer.stop()\n",
    "\n",
    "gigaflops = [0.27 / i for i in timer.times]\n",
    "print(f'performance in Gigaflops: element {gigaflops[0]:.3f}, '\n",
    "      f'column {gigaflops[1]:.3f}, full {gigaflops[2]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3843f26-b110-4f3b-a324-32eb903d710a",
   "metadata": {},
   "source": [
    "## Minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a8f643",
   "metadata": {},
   "source": [
    "Ở các phần trước ta đọc dữ liệu theo *minibatches* thay vì từng điểm dữ liệu đơn lẻ để cập nhật các tham số. Ta có thể giải thích ngắn gọn mục đích như sau. Xử lý từng điểm dữ liệu đơn lẻ đòi hỏi phải thực hiện rất nhiều phép nhân ma trận với vector (hay thậm chí vector với vector). Cách này khá tốn kém và đồng thời phải chịu thêm chi phí khá lớn đến từ các framework học sâu bên dưới. Vấn đề này xảy ra ở cả lúc đánh giá một mạng với dữ liệu mới và khi tính toán gradient để cập nhật các tham số. Tức là vấn đề xảy ra mỗi khi ta thực hiện $\\mathbf{w} \\leftarrow \\mathbf{w} - \\eta_t \\mathbf{g}_t$  trong đó \n",
    "\n",
    "$$\\mathbf{g}_t = \\partial_{\\mathbf{w}} f(\\mathbf{x}_{t}, \\mathbf{w})$$\n",
    "\n",
    "Ta có thể tăng hiệu suất *tính toán* của phép tính này bằng cách áp dụng nó trên mỗi minibatch dữ liệu. Tức là ta thay thế gradient $\\mathbf{g}_t$ trên một điểm dữ liệu đơn lẻ bằng gradient trên một batch nhỏ. \n",
    "\n",
    "$$\\mathbf{g}_t = \\partial_{\\mathbf{w}} \\frac{1}{|\\mathcal{B}_t|} \\sum_{i \\in \\mathcal{B}_t} f(\\mathbf{x}_{i}, \\mathbf{w})$$\n",
    "\n",
    "Hãy thử xem phương pháp trên tác động thế nào đến các tính chất thống kê của $\\mathbf{g}_t$: vì cả $\\mathbf{x}_t$ và tất cả các phần tử trong minibatch $\\mathcal{B}_t$ được lấy ra từ tập huấn luyện với xác suất như nhau, kỳ vọng của gradient là không đổi. Mặt khác, phương sai giảm một cách đáng kể. Do gradient của minibatch là trung bình của $b := |\\mathcal{B}_t|$ gradient độc lập, độ lệch chuẩn của nó giảm đi theo hệ số $b^{-\\frac{1}{2}}$. Đây là một điều tốt, cách cập nhật này có độ tin cậy gần bằng việc lấy gradient trên toàn bộ tập dữ liệu.\n",
    "\n",
    "Từ ý trên, ta sẽ nhanh chóng cho rằng chọn minibatch $\\mathcal{B}_t$ lớn luôn là tốt nhất. Tiếc rằng đến một mức độ nào đó, độ lệch chuẩn sẽ giảm không đáng kể so với chi phí tính toán tăng tuyến tính. Do đó trong thực tế, ta sẽ chọn kích thước minibatch đủ lớn để hiệu suất tính toán cao trong khi vẫn đủ để đưa vào bộ nhớ của GPU. Để minh hoạ quá trình lưu trữ này, hãy xem đoạn mã nguồn dưới đây. Trong đó ta vẫn thực hiện phép nhân ma trận với ma trận, tuy nhiên lần này ta tách thành từng minibatch 64 cột."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51db8c-7f3b-4ca1-8a10-419d99dfe483",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.start()\n",
    "for j in range(0, 512, 64):\n",
    "    A[:, j:j+64] = torch.mm(B, C[:, j:j+64])\n",
    "timer.stop()\n",
    "print(f'performance in Gigaflops: block {0.27 / timer.times[3]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ad56f",
   "metadata": {},
   "source": [
    "Có thể thấy quá trình tính toán trên minibatch về cơ bản có hiệu suất gần bằng thực hiện trên toàn ma trận. Tuy nhiên, cần lưu ý rằng Trong ví dụ trước đó ta sử dụng một loại điều chuẩn phụ thuộc chặt chẽ vào phương sai của minibatch. khi tăng kích thước minibatch, phương sai giảm xuống và cùng với đó là lợi ích của việc thêm nhiễu (noise-injection) cũng giảm theo do phương pháp chuẩn hóa theo batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76883d6-a469-4153-91d7-931be6f011fd",
   "metadata": {},
   "source": [
    "## Reading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba4801",
   "metadata": {},
   "source": [
    "Chúng ta hãy xem cách minibatches được tạo ra hiệu quả từ dữ liệu. Sau đây chúng tôi sử dụng một tập dữ liệu do NASA phát triển để kiểm tra cánh [noise from different aircraft](https://archive.ics.uci.edu/ml/datasets/Airfoil+Self-Noise) để so sánh các thuật toán tối ưu hóa này. Để thuận tiện, chúng tôi chỉ sử dụng các ví dụ $1,500$ đầu tiên. Dữ liệu được làm trắng để xử lý trước, tức là, chúng tôi loại bỏ trung bình và giải thích phương sai thành $1$ cho mỗi tọa độ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "393d525e-e0e8-4d44-96de-5be729da4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['airfoil'] = (d2l.DATA_URL + 'airfoil_self_noise.dat',\n",
    "                           '76e5be1548fd8222e5074cf0faae75edff8cf93f')\n",
    "\n",
    "#@save\n",
    "def get_data_ch11(batch_size=10, n=1500):\n",
    "    data = np.genfromtxt(d2l.download('airfoil'),\n",
    "                         dtype=np.float32, delimiter='\\t')\n",
    "    data = torch.from_numpy((data - data.mean(axis=0)) / data.std(axis=0))\n",
    "    data_iter = d2l.load_array((data[:n, :-1], data[:n, -1]),\n",
    "                               batch_size, is_train=True)\n",
    "    return data_iter, data.shape[1] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ac24e8-5c1d-4ecb-bd87-a888caabd119",
   "metadata": {},
   "source": [
    "## Hiện thực từ đầu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7debfd6d",
   "metadata": {},
   "source": [
    "Để so sánh hiệu năng giữa 3 thuật toán tối ưu là GD, SGD và SGD theo minibatch, ta sẽ sử dụng mô hình Hồi quy Tuyến tính"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1039bbab",
   "metadata": {},
   "source": [
    "### Nhắc lại về Hồi quy Tuyến tính"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ac641",
   "metadata": {},
   "source": [
    "#### Định nghĩa\n",
    "Hồi quy Tuyến tính (Linear Regression) là một phương pháp học máy cơ bản thuộc nhóm học có giám sát (Supervised learning). Phương pháp này bao gồm 2 yếu tố là Hồi quy và Tuyến tính. Phép Hồi quy phân tích mối quan hệ giữa một hoặc nhiều biến đầu vào (biến độc lập) và một biến đầu ra (biến phụ thuộc). Trong khi đó, phép Tuyến tính chỉ mối quan hệ tổ hợp tuyến tính của các biến đầu vào mà không có sự xuất hiện của các hàm lũy thừa hay phi tuyến như sin, log, relu, ... Như vậy, Hồi quy Tuyến tính là phương pháp học máy và thống kê giúp mô hình hóa mối quan hệ **tuyến tính** giữa một hoặc nhiều biến đầu vào (biến độc lập) và một biến đầu ra (biến phụ thuộc), từ đó giúp dự đoán giá trị của biến phụ thuộc dựa trên giá trị của các biến độc lập."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dd40a3",
   "metadata": {},
   "source": [
    "#### Mô hình Tuyến tính\n",
    "Mô hình Hồi quy Tuyến tính cho `d` đặc trưng (biến đầu vào) có dạng:\n",
    "$$\n",
    "y = \\omega_1*x_1 + \\omega_2*x_2 + ... + \\omega_d*x_d + b\n",
    "$$\n",
    "Thu thập toàn bộ các đặc trưng vào một vector $\\mathbf{x}$ và toàn bộ các trọng số vào một vector $\\boldsymbol{\\omega}$, ta có thể biểu diễn mô hình dưới dạng tích vô hướng của 2 vector:\n",
    "$$\n",
    "y = \\boldsymbol{\\omega}^T*\\mathbf{x}\n",
    "$$\n",
    "Trong đó:\n",
    "- $\\mathbf{x}$: vector đặc trưng đầu vào, $\\mathbf{x} \\in R^d$ (input features)\n",
    "- $\\boldsymbol{\\omega}$: vector trọng số (weights) cần huấn luyện\n",
    "- $b$: độ lệch (bias)\n",
    "- $y$: giá trị đầu ra (output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58ed6f3",
   "metadata": {},
   "source": [
    "#### Hàm mất mát\n",
    "Để đánh giá mức độ khớp giữa mô hình được xây dựng và dữ liệu, ta sử dụng hàm mất mát. Hàm mất mát định lượng khoảng cách giữa giá trị thực $y$ và giá trị dự đoán $\\hat{y}$ của mục tiêu. Độ mất mát thường là một số không âm và có giá trị càng nhỏ càng tốt. Khi các dự đoán hoàn hảo, chúng sẽ có độ mất mát sẽ bằng **0**. Hàm mất mát thông dụng nhất trong các bài toán hồi quy là hàm tổng bình phương các lỗi - Mean Squared Error (MSE):\n",
    "$$\n",
    "L_i = \\frac{1}{2} MSE(y_i, \\hat{y}_i) = \\frac{1}{2} E[(y_i - \\hat{y}_i)^2] = \\frac{1}{2} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "Hằng số **1/2** không tạo ra sự khác biệt thực sự nào nhưng sẽ giúp ký hiệu thuận tiện hơn:nó sẽ được triệt tiêu khi lấy đạo hàm của hàm mất mát.\n",
    "\n",
    "Lưu ý rằng khi hiệu giữa giá trị thực $y_i$ và giá trị ước lượng $\\hat{y}_i$ lớn, giá trị hàm mất mát sẽ tăng rất lớn cho sự phụ thuộc bậc 2. Để đo chất lượng của mô hình trên toàn bộ tập dữ liệu, ta đơn thuần lấy trung bình (hay tương đương là lấy tổng) các giá trị mất mát của từng mẫu trong tập huấn luyện.\n",
    "$$\n",
    "L = \\frac{1}{n} \\sum_{i=1}^{n} L_i = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{1}{2} (y_i - \\hat{y}_i)^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7494f2ea",
   "metadata": {},
   "source": [
    "#### Mục tiêu\n",
    "Khi huấn luyện mô hình, ta muốn tìm các tham số $\\boldsymbol{\\omega}^*$ và $b^*$ sao cho tổng độ mất mát trên toàn bộ các mẫu huấn luyện được cực tiểu hóa:\n",
    "$$\n",
    "\\boldsymbol{\\omega}^*, b^* = \\underset{\\boldsymbol{\\omega}, b}{\\text{argmin}}\\:L(\\boldsymbol{\\omega}, b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8e56b",
   "metadata": {},
   "source": [
    "Kỹ thuật chính để tối ưu hóa mô hình này, cũng như các mô hình học sâu khác, bao gồm việc giảm thiểu lỗi qua các vòng lặp bằng cách cập nhật tham số theo hướng làm giảm gần hàm mát mát. Với các hàm mất mát mặt lồi, giá trị mất mát cuối cùng sẽ hội tụ về giá trị nhỏ nhất. Tuy điều tương tự không thể áp dụng cho các mặt không lồi, ít nhất thuật toán sẽ dẫn tới một cực tiểu (hy vọng là tốt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bf946f",
   "metadata": {},
   "source": [
    "Đơn giản nhất ta có thể kể đến là việc tính đạo hàm của hàm mất mát, tức trung bình của các giá trị mất mát được tính trên mỗi mẫu của tập dữ liệu. Cuối cùng, gradient này được nhân với tốc độ học $\\eta > 0$ và kết quả này được trừ đi từ các giá trị tham số hiện tại. Đây là chính phương pháp Gradient Descent (GD).\n",
    "\n",
    "Việc cập nhật có thể được biểu diễn bằng công thức dưới đây:\n",
    "$$\n",
    "(\\boldsymbol{\\omega}, b) \\leftarrow (\\boldsymbol{\\omega}, b) - \\frac{\\eta}{|\\boldsymbol{N}|} \\sum_{i \\in \\boldsymbol{N}} \\partial_{(\\boldsymbol{\\omega}, b)}L_i(\\boldsymbol{\\omega}, b)\n",
    "$$\n",
    "hay,\n",
    "$$\n",
    "\\boldsymbol{\\omega} \\leftarrow \\boldsymbol{\\omega} - \\frac{\\eta}{|\\boldsymbol{N}|} \\sum_{i \\in \\boldsymbol{N}} \\partial_(\\boldsymbol{\\omega}) L_i(\\boldsymbol{\\omega}, b)\n",
    "$$\n",
    "$$\n",
    "b \\leftarrow b - \\frac{\\eta}{|\\boldsymbol{N}|} \\sum_{i \\in \\boldsymbol{N}} \\partial_{b} L_i(\\boldsymbol{\\omega}, b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6930b5c7",
   "metadata": {},
   "source": [
    "Việc cập nhật này cho từng mẫu dữ liệu có thể cực kì chậm. Nếu chúng ta chỉ muốn lấy một minibatch ngẫu nhiên các mẫu mỗi khi ta cần tính bước cập nhật, phương pháp biến thể này là Stochastic Gradient Descent (SGD). Trong mỗi vòng lặp, đầu tiên chúng ta lấy ngẫu nhiên một minibatch $\\boldsymbol{B}$ dữ liệu huấn luyện với kích thước cố định. Sau đó, chúng ta tính đạo hàm của hàm mất mát trên minibatch đó theo các tham số của mô hình. Cuối cùng, gradient này được nhân với tốc độ học  $\\eta > 0$ và kết quả này được trừ đi từ các giá trị tham số hiện tại.\n",
    "\n",
    "Việc cập nhật có thể được biểu diễn bằng công thức dưới đây:\n",
    "$$\n",
    "(\\boldsymbol{\\omega}, b) \\leftarrow (\\boldsymbol{\\omega}, b) - \\frac{\\eta}{|\\boldsymbol{B}|} \\sum_{i \\in \\boldsymbol{B}} \\partial_{(\\boldsymbol{\\omega}, b)}L_i(\\boldsymbol{\\omega}, b)\n",
    "$$\n",
    "hay,\n",
    "$$\n",
    "\\boldsymbol{\\omega} \\leftarrow \\boldsymbol{\\omega} - \\frac{\\eta}{|\\boldsymbol{B}|} \\sum_{i \\in \\boldsymbol{B}} \\partial_(\\boldsymbol{\\omega}) L_i(\\boldsymbol{\\omega}, b)\n",
    "$$\n",
    "$$\n",
    "b \\leftarrow b - \\frac{\\eta}{|\\boldsymbol{B}N|} \\sum_{i \\in \\boldsymbol{B}} \\partial_{b} L_i(\\boldsymbol{\\omega}, b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc10fcb",
   "metadata": {},
   "source": [
    "### Ứng dụng các Thuật toán tối ưu cho Hồi quy Tuyến tính"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe8a89",
   "metadata": {},
   "source": [
    "Để thuận tiện, hàm lập trình GD, SGD và SGD theo minibatch sẽ có danh sách tham số giống nhau. Cụ thể, chúng ta thêm trạng thái đầu vào biến `states` và đặt siêu tham số trong biến `hyperparams`. Bên cạnh đó, chúng ta sẽ tính giá trị mất mát trung bình của từng minibatch trong hàm huấn luyện, từ đó không cần phải chia gradient cho kích thước batch trong thuật toán tối ưu nữa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b1c54e9-817f-4b0a-aaab-16cbd82c6f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, states, hyperparams):\n",
    "    for p in params:\n",
    "        p.data.sub_(hyperparams['lr'] * p.grad)\n",
    "        p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c36b5",
   "metadata": {},
   "source": [
    "**Giải thích**\n",
    "\n",
    "Hàm `sgd` sẽ duyệt qua các tham số `p` trong `params` của mô hình, trong bài toán Hồi quy Tuyến tính sẽ là vector trọng số $\\boldsymbol{\\omega}$ và $b$ và cập nhật theo quy tắc:\n",
    "$$\n",
    "p := p - \\eta*\\Delta_pL\n",
    "$$\n",
    "Trong đó:\n",
    "- `p`: tham số\n",
    "- `p.grad`: đạo hàm của hàm mất mát theo p\n",
    "- `hyperparams['lr']` hay $\\eta$: tốc độ học (learning rate)\n",
    "Sau đó, thực hiện reset gradient ở bước cuối trong mỗi vòng lặp để tránh tích lũy gradient từ nhiều batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3fcbde",
   "metadata": {},
   "source": [
    "Tiếp theo, chúng ta hiện thực một hàm huấn luyện tổng quát, sử dụng được cho tất cả các thuật toán tối ưu. Hàm sẽ khởi tạo một mô hình Hồi quy Tuyến tính và có thể được sử dụng để huấn luyện mô hình với GD, SGD và SGD theo minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffa49aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def train_ch11(trainer_fn, states, hyperparams, data_iter,\n",
    "               feature_dim, num_epochs=2):\n",
    "    # Initialization\n",
    "    w = torch.normal(mean=0.0, std=0.01, size=(feature_dim, 1),\n",
    "                     requires_grad=True)\n",
    "    b = torch.zeros((1), requires_grad=True)\n",
    "    net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss\n",
    "    # Train\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                            xlim=[0, num_epochs], ylim=[0.22, 0.35])\n",
    "    n, timer = 0, d2l.Timer()\n",
    "    for _ in range(num_epochs):\n",
    "        for X, y in data_iter:\n",
    "            l = loss(net(X), y).mean()\n",
    "            l.backward()\n",
    "            trainer_fn([w, b], states, hyperparams)\n",
    "            n += X.shape[0]\n",
    "            if n % 200 == 0:\n",
    "                timer.stop()\n",
    "                animator.add(n/X.shape[0]/len(data_iter),\n",
    "                             (d2l.evaluate_loss(net, data_iter, loss),))\n",
    "                timer.start()\n",
    "    print(f'loss: {animator.Y[0][-1]:.3f}, {timer.sum()/num_epochs:.3f} sec/epoch')\n",
    "    return timer.cumsum(), animator.Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35df4c87",
   "metadata": {},
   "source": [
    "**Giải thích**\n",
    "\n",
    "Hàm `train_ch11` sẽ khởi tạo các giá trị cần cho mô hình Hồi quy Tuyến tính và thực hiện huấn luyện.\n",
    "\n",
    "Tham số đầu vào:\n",
    "- `trainer_fn`: hàm cập nhật tham số mô hình (GD, SGD, ...)\n",
    "- `states`: các trạng thái cần thiết cho `trainer_fn`\n",
    "- `hyperparams`: các siêu tham số như `lr`, `beta`\n",
    "- `feature_dim`: số lượng đặc trưng (hoặc số chiều biến đầu vào)\n",
    "- `num_epochs`: số vòng lặp huấn luyện\n",
    "\n",
    "**Bước 1: Khởi tạo mô hình**\n",
    "Đầu tiên, khởi tạo 2 vector trọng số $\\boldsymbol{\\omega}$ và bias $b$ đều yêu cầu gradient, trong đó:\n",
    "- $\\boldsymbol{\\omega}$ tuân theo phân phối chuẩn với $\\mu$ = 0.0 và $\\sigma$ = 0.01, có kích thước `feature_dim` x 1 \n",
    "- $b$ = 0\n",
    "\n",
    "Tiếp theo, khởi tạo `net` với `loss`, lần lượt là mô hình Hồi quy tuyến tính có dạng $y = \\boldsymbol{X}*\\boldsymbol{\\omega} + b$ và hàm mất mát theo MSE\n",
    "\n",
    "**Bước 2: Khởi tạo tiến trình vẽ hàm mất mát và bộ đếm thời gian**\n",
    "- `animator`: thực thể để biểu diễn hàm mất mát dưới dạng đồ thị theo thời gian\n",
    "- `n`: tổng số mẫu đã xử lý\n",
    "- `timer`: để đo thời gian chạy từng epoch\n",
    "\n",
    "**Bước 3: Huấn luyện mô hình**\n",
    "Lần lượt duyệt qua từng batch:\n",
    "1. Tính giá trị hàm mất mát: `l = loss(net(X), y).mean()` tương ứng việc lấy trung bình giá trị MSE cho toàn bộ các điểm dữ liệu trong batch\n",
    "2. Thực hiện lan truyền ngược để tính GD: `l.backward()`\n",
    "3. Cập nhật tham số: `trainer_fn` được gọi với `[w, b]`, `states` và `hyperparams`\n",
    "4. Reset gradient descent nằm trong `trainer_fn`.\n",
    "\n",
    "Vẽ hàm mất mát với mỗi 200 mẫu\n",
    "\n",
    "**Bước 4: In kết quả**\n",
    "In giá trị hàm mất mát cuối cùng và thời gian trung bình mỗi epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2defb",
   "metadata": {},
   "source": [
    "Tiếp theo, ta tạo một hàm đầu vào để thực hiện toàn quá trình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b0b18b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sgd(lr, batch_size, num_epochs=2):\n",
    "    data_iter, feature_dim = get_data_ch11(batch_size)\n",
    "    return train_ch11(sgd, None, {'lr': lr}, data_iter, feature_dim, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbd1340",
   "metadata": {},
   "source": [
    "**Giải thích**\n",
    "Hàm `train_sgd` thực hiện việc đọc dữ liệu, khởi tạo các tham số và huấn luyện mô hình.\n",
    "\n",
    "Tham số đầu vào:\n",
    "- `lr`: siêu tham số tốc độ học (learning rate)\n",
    "- `batch_size`: kích thước của batch\n",
    "- `num_epochs`: số vòng lặp huấn luyện\n",
    "\n",
    "Dữ liệu được trả về theo từng batch từ hàm `get_data_ch11` sẽ được dùng để huấn luyện trong hàm `train_ch11`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77e4cd",
   "metadata": {},
   "source": [
    "#### Thực nghiệm với GD\n",
    "Hãy cùng quan sát quá trình tối ưu của thuật toán Gradient Descent (GD) theo toàn bộ batch. Ta có thể sử dụng toàn bộ batch bằng cách thiết lập kích thước minibatch bằng tổng số mẫu (trong trường hợp này là 1500). Kết quả là các tham số mô hình chỉ được cập nhật một lần duy nhất trong mỗi epoch. Có thể thấy không có tiến triển nào đáng kể. Trong ví dụ, việc tối ưu bị ngừng trệ sau 6 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036e4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_res = train_sgd(1, 1500, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d45e29",
   "metadata": {},
   "source": [
    "**Giải thích**\n",
    "\n",
    "Ở đây ta thực nghiệm huấn luyện mô hình với GD, sử dụng $\\eta = 1$, số lượng epoch = 10 và thiết lập tham số `batch_size` = 1500 (= kích thước của tập dữ liệu), tức là với mỗi epoch hàm mất mát sẽ được tính và thực hiện cập nhật $(\\boldsymbol{\\omega}, b)$ chỉ 1 lần duy nhất"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a8619e",
   "metadata": {},
   "source": [
    "#### Thực nghiệm với SGD\n",
    "\n",
    "Khi kích thước của batch bằng 1, chúng ta sử dụng thuật toán SGD để tối ưu. Để đơn giản hóa việc hiện thực, chúng ta cố định tốc độ học (learning rate) bằng một hằng số (có giá trị nhỏ). Trong SGD, các tham số mô hình được cập nhật bất cứ khi nào có một mẫu huấn luyện được xử lý. Trong trường hợp này, sẽ có 1500 lần cập nhật trong mỗi epoch. Có thể thấy, sự suy giảm giá trị của hàm mục tiêu chậm lại sau một epoch. Mặc dù cả hai thuật toán cùng xử lý 1500 mẫu trong một epoch, SGD tốn thời gian hơn GD trong thí nghiệm trên. Điều này là do SGD cập nhật các tham số thường xuyên hơn và kém hiệu quả khi xử lý đơn lẻ từng mẫu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0322383",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_res = train_sgd(0.005, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e4962",
   "metadata": {},
   "source": [
    "**Giải thích**\n",
    "\n",
    "Ở đây ta thực nghiệm huấn luyện mô hình với SGD, sử dụng $\\eta = 0.005$, số lượng epoch = 2 (theo mặc định) và thiết lập tham số `batch_size` = 1, tức là với mỗi epoch hàm mất mát sẽ được tính và thực hiện cập nhật $(\\boldsymbol{\\omega}, b)$ với mỗi điểm dữ liệu trong tập."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2255f2",
   "metadata": {},
   "source": [
    "#### Thực nghiệm với SGD theo minibatch\n",
    "\n",
    "Cuối cùng, khi kích thước của batch bằng 100, chúng ta sử dụng thuật toán SGD theo minibatch để tối ưu. Thời gian cần thiết cho mỗi epoch ngắn hơn thời gian tương ứng của SGD và GD theo toàn bộ batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3291ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini1_res = train_sgd(.4, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea9943",
   "metadata": {},
   "source": [
    "**Giải thích**\n",
    "\n",
    "Ở đây ta thực nghiệm huấn luyện mô hình với SGD theo minibatch có kích thước = 100, sử dụng $\\eta = 0.4$, số lượng epoch = 2 (theo mặc định), tức là với mỗi epoch hàm mất mát sẽ được tính và thực hiện cập nhật $(\\boldsymbol{\\omega}, b)$ tương ứng là $\\frac{1500}{100} = 15$ lần"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc24d1",
   "metadata": {},
   "source": [
    "Giảm kích thước của batch bằng 10, thời gian cho mỗi epoch tăng vì thực thi tính toán trên mỗi batch kém hiệu quả hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe23a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini2_res = train_sgd(.05, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cff3d1a",
   "metadata": {},
   "source": [
    "**Giải thích**\n",
    "\n",
    "Ở đây ta thực nghiệm huấn luyện mô hình với SGD theo minibatch có kích thước = 10, sử dụng $\\eta = 0.05$, số lượng epoch = 2 (theo mặc định), tức là với mỗi epoch hàm mất mát sẽ được tính và thực hiện cập nhật $(\\boldsymbol{\\omega}, b)$ tương ứng là $\\frac{1500}{10} = 150$ lần"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04560786",
   "metadata": {},
   "source": [
    "Cuối cùng, chúng ta so sánh tương quan thời gian và giá trị hàm mấy mát trong bốn thí nghiệm trên. Có thể thấy, dù hội tụ nhanh hơn GD về số mẫu được xử lý, SGD tốn nhiều thời gian hơn để đạt được cùng giá trị mất mát như GD vì thuật toán này tính gradient descent trên từng mẫu một. Thuật toán SGD theo minibatch có thể cân bằng giữa tốc độ hội tụ và hiệu quả tính toán. Với kích thước minibatch bằng 10, thuật toán này hiệu quả hơn SGD; và với kích thước minibatch bằng 100, thời gian chạy của thuật toán này thậm chí nhanh hơn cả GD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523c5892-76e4-4f5c-b72c-bff4fc4ec739",
   "metadata": {},
   "source": [
    "## Hiện thực chính xác"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b29ea5",
   "metadata": {},
   "source": [
    "Trong Gluon, chúng ta có thể sử dụng lớp `Trainer` để gọi các thuật toán tối ưu. Cách này được sử dụng để có thể hiện thực một hàm huấn luyện tổng quát. Chúng ta sẽ sử dụng hàm này xuyên suốt các phần tiếp theo của chương."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17a8af60-a69d-40dc-9f2e-5583557c622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def train_concise_ch11(trainer_fn, hyperparams, data_iter, num_epochs=4):\n",
    "    # Initialization\n",
    "    net = nn.Sequential(nn.Linear(5, 1))\n",
    "    def init_weights(module):\n",
    "        if type(module) == nn.Linear:\n",
    "            torch.nn.init.normal_(module.weight, std=0.01)\n",
    "    net.apply(init_weights)\n",
    "\n",
    "    optimizer = trainer_fn(net.parameters(), **hyperparams)\n",
    "    loss = nn.MSELoss(reduction='none')\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                            xlim=[0, num_epochs], ylim=[0.22, 0.35])\n",
    "    n, timer = 0, d2l.Timer()\n",
    "    for _ in range(num_epochs):\n",
    "        for X, y in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            out = net(X)\n",
    "            y = y.reshape(out.shape)\n",
    "            l = loss(out, y)\n",
    "            l.mean().backward()\n",
    "            optimizer.step()\n",
    "            n += X.shape[0]\n",
    "            if n % 200 == 0:\n",
    "                timer.stop()\n",
    "                # `MSELoss` computes squared error without the 1/2 factor\n",
    "                animator.add(n/X.shape[0]/len(data_iter),\n",
    "                             (d2l.evaluate_loss(net, data_iter, loss) / 2,))\n",
    "                timer.start()\n",
    "    print(f'loss: {animator.Y[0][-1]:.3f}, {timer.sum()/num_epochs:.3f} sec/epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter, _ = get_data_ch11(10)\n",
    "trainer = torch.optim.SGD\n",
    "train_concise_ch11(trainer, {'lr': 0.01}, data_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565256bc-8212-46d3-b07c-b4b31fa3f62e",
   "metadata": {},
   "source": [
    "## Excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fadbff6-3a56-4bb7-af84-59a5cf724da1",
   "metadata": {},
   "source": [
    "### Exercise 1.\n",
    "Sửa đổi kích thước batch và tốc độ học, quan sát tốc độ suy giảm giá trị của hàm mục tiêu và thời gian cho mỗi epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7007be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thử nghiệm với các giá trị khác nhau của tốc độ học và kích thước batch\n",
    "# Tốc độ học lớn hơn và kích thước batch nhỏ hơn\n",
    "experiment_1 = train_sgd(lr=0.1, batch_size=5, num_epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3295ee-b93c-4dbb-883d-2a78fc17b058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tốc độ học nhỏ hơn và kích thước batch lớn hơn\n",
    "experiment_2 = train_sgd(lr=0.01, batch_size=50, num_epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326251fb-1f59-411a-8935-17e674dc5cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tốc độ học trung bình và kích thước batch trung bình\n",
    "experiment_3 = train_sgd(lr=0.05, batch_size=20, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b8ca3",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "1. **Tốc độ học lớn hơn và kích thước batch nhỏ hơn**:\n",
    "    - Với tốc độ học lớn và kích thước batch nhỏ, mô hình có thể hội tụ nhanh hơn nhưng dễ gặp phải dao động lớn trong quá trình tối ưu hóa do phương sai cao của gradient.\n",
    "\n",
    "2. **Tốc độ học nhỏ hơn và kích thước batch lớn hơn**:\n",
    "    - Với tốc độ học nhỏ và kích thước batch lớn, mô hình hội tụ ổn định hơn nhưng tốc độ hội tụ có thể chậm hơn do các bước cập nhật nhỏ.\n",
    "\n",
    "3. **Tốc độ học trung bình và kích thước batch trung bình**:\n",
    "    - Với tốc độ học và kích thước batch trung bình, mô hình đạt được sự cân bằng giữa tốc độ hội tụ và độ ổn định, thường mang lại kết quả tốt nhất.\n",
    "\n",
    "Kích thước batch và tốc độ học là các siêu tham số quan trọng, cần được điều chỉnh phù hợp với bài toán cụ thể để đạt hiệu quả tối ưu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79b73c7",
   "metadata": {},
   "source": [
    "### Exercise 2.\n",
    "Đọc thêm tài liệu MXNet và sử dụng hàm set_learning_rate của lớp Trainer để giảm tốc độ học của SGD theo minibatch bằng 1/10 giá trị trước đó sau mỗi epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5851407d-6c0c-4c2a-b844-7f7a35382b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, nd\n",
    "\n",
    "# Define a simple model\n",
    "net = gluon.nn.Sequential()\n",
    "net.add(gluon.nn.Dense(10))\n",
    "net.initialize(mx.init.Xavier())\n",
    "\n",
    "# Initialize Trainer with SGD optimizer\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1})\n",
    "\n",
    "# Simulate training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    # Reduce learning rate by a factor of 10 after each epoch\n",
    "    new_lr = trainer.learning_rate * 0.1\n",
    "    trainer.set_learning_rate(new_lr)\n",
    "    print(f'Epoch {epoch+1}: Learning rate = {new_lr}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165aee7c",
   "metadata": {},
   "source": [
    "### Exercise 3.\n",
    "Hãy so sánh SGD theo minibatch sử dụng một biến thể lấy mẫu có hoàn lại từ tập huấn luyện. Điều gì sẽ xảy ra?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a503c84",
   "metadata": {},
   "source": [
    "Khi huấn luyện mô hình sử dụng phương pháp SGD theo minibatch thông thường, ta có:\n",
    "- Cách hoạt động:\n",
    "    + Với mỗi vòng lặp huấn luyện, tập dữ liệu sẽ được chia nhỏ thành các minibatch.\n",
    "    + Mỗi minibatch chứa các mẫu dữ liệu độc nhất cho đến khi vòng lặp được hoàn thành.\n",
    "    + Mỗi điểm dữ liệu chỉ được dùng 1 lần mỗi vòng lặp.\n",
    "- Đặc điểm:\n",
    "    + Ước lượng gradient hiệu quả: phương sai cho mỗi minibatch tương đối nhỏ.\n",
    "    + Hội tụ nhanh và mượt mà hơn.\n",
    "    + Đảm bảo các mẫu đều được xem xét mỗi vòng lặp huấn luyện.\n",
    "\n",
    "So sánh với biến thể minibatch cho phép lấy mẫu hoàn lại từ tập dữ liệu, ta có:\n",
    "- Cách hoạt động:\n",
    "    + Với mỗi vòng lặp huấn luyện, các minibatch sẽ được tạo ra bằng cách lấy ngẫu nhiên từ tập dữ liệu.\n",
    "    + Một vài mẫu sẽ được chọn nhiều lần, một vài mẫu thì không bao giờ được chọn.\n",
    "    + Không đảm bảo rằng tất cả các điểm dữ liệu được dùng 1 lần mỗi vòng lặp.\n",
    "- Đặc điểm:\n",
    "    + Ước lượng gradient kém hiệu quả: có nhiều nhiễu do bị trùng hoặc thiếu một phần mẫu.\n",
    "    + Hội tụ chậm hoặc kém ổn định\n",
    "    + Thiếu tính khái quát hóa do bị overfit với các mẫu dữ liệu được lựa chọn nhiều và underfit với các mẫu dữ liệu không được lựa chọn. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8bad3",
   "metadata": {},
   "source": [
    "### Exercise 4.\n",
    "Một ác thần đã sao chép tập dữ liệu của bạn mà không nói cho bạn biết (cụ thể, mỗi quan sát bị lặp lại hai lần và kích thước tập dữ liệu tăng gấp đôi so với ban đầu). Cách hoạt động của các thuật toán hạ gradient, SGD và SGD theo minibatch sẽ thay đổi như thế nào?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f1d7f",
   "metadata": {},
   "source": [
    "Nếu tập dữ liệu bị lặp lại, ta đang có kích thước của mẫu quan sát tăng lên nhưng không có thêm thông tin mới. Điều này ảnh hưởng khác nhau đến các phương pháp tối ưu theo các cách khác nhau:\n",
    "1. Gradient Descent (GD) - Sử dụng toàn bộ mẫu dữ liệu\n",
    "- Gradient Descent sử dụng toàn bộ mẫu dữ liệu, nên sẽ làm tăng giá trị hàm mất mát và độ dốc theo tỉ lệ thuận. Tuy nhiên, hướng của gradient sẽ không đổi, do ta chỉ cộng các thành phần lặp lại.\n",
    "- Ảnh hưởng:\n",
    "    + Hướng của gradient được giữ nguyên, nhưng được tăng lên.\n",
    "    + Tốc độ học cần phải được điều chỉnh để duy trì được độ ổn định.\n",
    "    + Chi phí tính toán tăng lên (lâu hơn mỗi vòng lặp nhưng không có thêm thông tin gì)\n",
    "2. Stochastic Gradient Descent (SGD) – Sử dụng 1 mẫu\n",
    "- Mỗi mẫu sẽ có khả năng cao hơn được chọn nhiều lần, nhưng không có sự thay đổi về chất lượng gradient và tính đa dạng của tập dữ liệu\n",
    "- Ảnh hưởng:\n",
    "    + Không có sự khác biệt cơ bản về quá trình huấn luyện.\n",
    "    + Phương sai không đổi.\n",
    "    + Hội tụ chậm hơn do trùng lặp dữ liệu.\n",
    "3. Minibatch Stochastic Gradient Descent (Minibatch SGD) - Sử dụng tập con\n",
    "- Các minibatch sẽ chứa nhiều mẫu trùng lặp hơn giữa các vòng lặp huấn luyện.\n",
    "- Tốc độ học có thể chậm lại do liên tục thấy các mẫu trùng lặp\n",
    "- Ảnh hưởng:\n",
    "    + Hướng của gradient được giữ nguyên, nhưng tính khái quát lâu được cải thiện.\n",
    "    + Có thể tốn các vòng lặp để huấn luyện các mẫu trùng lặp."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
